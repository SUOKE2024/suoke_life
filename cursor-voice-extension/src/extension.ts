import * as vscode from 'vscode';
import { VoiceRecognitionService } from './services/voiceRecognitionService';
import { VideoInteractionService } from './services/videoInteractionService';
import { AIAssistantService } from './services/aiAssistantService';

let voiceService: VoiceRecognitionService;
let videoService: VideoInteractionService;
let aiService: AIAssistantService;

export function activate(context: vscode.ExtensionContext) {
    console.log('Cursor Voice Interaction æ‰©å±•å·²æ¿€æ´»');

    // åˆå§‹åŒ–æœåŠ¡
    voiceService = new VoiceRecognitionService();
    videoService = new VideoInteractionService();
    aiService = new AIAssistantService();

    // æ³¨å†Œå‘½ä»¤
    const commands = [
        vscode.commands.registerCommand('cursor-voice.startVoiceRecognition', startVoiceRecognition),
        vscode.commands.registerCommand('cursor-voice.stopVoiceRecognition', stopVoiceRecognition),
        vscode.commands.registerCommand('cursor-voice.startVideoInteraction', startVideoInteraction),
        vscode.commands.registerCommand('cursor-voice.toggleVoiceMode', toggleVoiceMode),
    ];

    commands.forEach(command => context.subscriptions.push(command));

    // åˆ›å»ºçŠ¶æ€æ é¡¹
    const statusBarItem = vscode.window.createStatusBarItem(vscode.StatusBarAlignment.Right, 100);
    statusBarItem.text = "ğŸ¤ è¯­éŸ³";
    statusBarItem.command = 'cursor-voice.toggleVoiceMode';
    statusBarItem.tooltip = 'ç‚¹å‡»åˆ‡æ¢è¯­éŸ³æ¨¡å¼';
    statusBarItem.show();
    context.subscriptions.push(statusBarItem);

    // ç›‘å¬é…ç½®å˜åŒ–
    vscode.workspace.onDidChangeConfiguration(event => {
        if (event.affectsConfiguration('cursor-voice')) {
            updateConfiguration();
        }
    });

    updateConfiguration();
}

async function startVoiceRecognition() {
    try {
        await voiceService.startRecognition();
        vscode.window.showInformationMessage('è¯­éŸ³è¯†åˆ«å·²å¼€å§‹');
        
        // ç›‘å¬è¯­éŸ³è¯†åˆ«ç»“æœ
        voiceService.onRecognitionResult(async (text: string) => {
            await handleVoiceCommand(text);
        });
    } catch (error) {
        vscode.window.showErrorMessage(`å¯åŠ¨è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error}`);
    }
}

async function stopVoiceRecognition() {
    try {
        await voiceService.stopRecognition();
        vscode.window.showInformationMessage('è¯­éŸ³è¯†åˆ«å·²åœæ­¢');
    } catch (error) {
        vscode.window.showErrorMessage(`åœæ­¢è¯­éŸ³è¯†åˆ«å¤±è´¥: ${error}`);
    }
}

async function startVideoInteraction() {
    try {
        await videoService.startVideoCapture();
        vscode.window.showInformationMessage('è§†é¢‘äº¤äº’å·²å¼€å§‹');
        
        // ç›‘å¬æ‰‹åŠ¿è¯†åˆ«ç»“æœ
        videoService.onGestureDetected((gesture: string) => {
            handleGestureCommand(gesture);
        });
    } catch (error) {
        vscode.window.showErrorMessage(`å¯åŠ¨è§†é¢‘äº¤äº’å¤±è´¥: ${error}`);
    }
}

async function toggleVoiceMode() {
    if (voiceService.isRecognizing()) {
        await stopVoiceRecognition();
    } else {
        await startVoiceRecognition();
    }
}

async function handleVoiceCommand(text: string) {
    console.log(`æ”¶åˆ°è¯­éŸ³å‘½ä»¤: ${text}`);
    
    try {
        // ä½¿ç”¨ AI åŠ©æ‰‹è§£æè¯­éŸ³å‘½ä»¤
        const command = await aiService.parseVoiceCommand(text);
        await executeCommand(command);
    } catch (error) {
        console.error('å¤„ç†è¯­éŸ³å‘½ä»¤å¤±è´¥:', error);
        vscode.window.showErrorMessage(`å¤„ç†è¯­éŸ³å‘½ä»¤å¤±è´¥: ${error}`);
    }
}

function handleGestureCommand(gesture: string) {
    console.log(`æ£€æµ‹åˆ°æ‰‹åŠ¿: ${gesture}`);
    
    switch (gesture) {
        case 'swipe_left':
            vscode.commands.executeCommand('workbench.action.previousEditor');
            break;
        case 'swipe_right':
            vscode.commands.executeCommand('workbench.action.nextEditor');
            break;
        case 'thumbs_up':
            vscode.commands.executeCommand('editor.action.formatDocument');
            break;
        case 'peace_sign':
            vscode.commands.executeCommand('workbench.action.files.save');
            break;
        default:
            console.log(`æœªè¯†åˆ«çš„æ‰‹åŠ¿: ${gesture}`);
    }
}

async function executeCommand(command: any) {
    switch (command.type) {
        case 'file_operation':
            await handleFileOperation(command);
            break;
        case 'code_generation':
            await handleCodeGeneration(command);
            break;
        case 'navigation':
            await handleNavigation(command);
            break;
        case 'ai_chat':
            await handleAIChat(command);
            break;
        default:
            vscode.window.showWarningMessage(`æœªçŸ¥å‘½ä»¤ç±»å‹: ${command.type}`);
    }
}

async function handleFileOperation(command: any) {
    switch (command.action) {
        case 'open':
            const uri = vscode.Uri.file(command.path);
            await vscode.window.showTextDocument(uri);
            break;
        case 'save':
            await vscode.commands.executeCommand('workbench.action.files.save');
            break;
        case 'new':
            await vscode.commands.executeCommand('workbench.action.files.newUntitledFile');
            break;
    }
}

async function handleCodeGeneration(command: any) {
    const editor = vscode.window.activeTextEditor;
    if (!editor) {
        vscode.window.showWarningMessage('æ²¡æœ‰æ´»åŠ¨çš„ç¼–è¾‘å™¨');
        return;
    }

    try {
        const generatedCode = await aiService.generateCode(command.prompt, editor.document.languageId);
        const position = editor.selection.active;
        await editor.edit(editBuilder => {
            editBuilder.insert(position, generatedCode);
        });
    } catch (error) {
        vscode.window.showErrorMessage(`ä»£ç ç”Ÿæˆå¤±è´¥: ${error}`);
    }
}

async function handleNavigation(command: any) {
    switch (command.action) {
        case 'goto_line':
            await vscode.commands.executeCommand('workbench.action.gotoLine');
            break;
        case 'find':
            await vscode.commands.executeCommand('actions.find');
            break;
        case 'replace':
            await vscode.commands.executeCommand('editor.action.startFindReplaceAction');
            break;
    }
}

async function handleAIChat(command: any) {
    try {
        const response = await aiService.chat(command.message);
        
        // åˆ›å»ºä¸€ä¸ªæ–°çš„è¾“å‡ºé€šé“æ˜¾ç¤º AI å›å¤
        const outputChannel = vscode.window.createOutputChannel('Cursor AI Assistant');
        outputChannel.appendLine(`ç”¨æˆ·: ${command.message}`);
        outputChannel.appendLine(`AI: ${response}`);
        outputChannel.show();
        
        // å¯é€‰ï¼šä½¿ç”¨è¯­éŸ³åˆæˆæ’­æ”¾å›å¤
        if (vscode.workspace.getConfiguration('cursor-voice').get('enableVoiceFeedback')) {
            await voiceService.speak(response);
        }
    } catch (error) {
        vscode.window.showErrorMessage(`AI å¯¹è¯å¤±è´¥: ${error}`);
    }
}

function updateConfiguration() {
    const config = vscode.workspace.getConfiguration('cursor-voice');
    const language = config.get<string>('language', 'zh-CN');
    const apiKey = config.get<string>('apiKey', '');
    const enableVideoGestures = config.get<boolean>('enableVideoGestures', false);

    voiceService.updateConfiguration({ language });
    aiService.updateConfiguration({ apiKey });
    videoService.updateConfiguration({ enableGestures: enableVideoGestures });
}

export function deactivate() {
    if (voiceService) {
        voiceService.dispose();
    }
    if (videoService) {
        videoService.dispose();
    }
    if (aiService) {
        aiService.dispose();
    }
} 