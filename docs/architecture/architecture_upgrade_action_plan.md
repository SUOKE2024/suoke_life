# ç´¢å…‹ç”Ÿæ´»æ¶æ„å‡çº§è¡ŒåŠ¨è®¡åˆ’

## ğŸ“‹ æ‰§è¡Œæ¦‚è¦

åŸºäºç´¢å…‹ç”Ÿæ´»APPç°æœ‰å¾®æœåŠ¡æ¶æ„ä¸go-zero-looklookæ¶æ„çš„å…¨é¢å¯¹æ¯”åˆ†æï¼Œåˆ¶å®šæœ¬è¡ŒåŠ¨è®¡åˆ’ï¼Œæ—¨åœ¨é€šè¿‡æ¸è¿›å¼å‡çº§ç­–ç•¥ï¼Œèåˆä¸¤ç§æ¶æ„çš„ä¼˜åŠ¿ï¼Œæ„å»ºç°ä»£åŒ–çš„å¥åº·ç®¡ç†å¹³å°ã€‚

## ğŸ¯ å‡çº§ç›®æ ‡

### çŸ­æœŸç›®æ ‡ï¼ˆ3ä¸ªæœˆï¼‰
- å®Œå–„æœåŠ¡æ²»ç†èƒ½åŠ›ï¼Œå¼•å…¥ç†”æ–­ã€é™æµæœºåˆ¶
- å»ºç«‹ç»Ÿä¸€çš„APIç½‘å…³å’Œé…ç½®ç®¡ç†
- æå‡ç³»ç»Ÿå¯è§‚æµ‹æ€§ï¼Œå¼•å…¥é“¾è·¯è¿½è¸ª
- ä¼˜åŒ–ç¼“å­˜æ¶æ„ï¼Œæå‡å“åº”æ€§èƒ½

### ä¸­æœŸç›®æ ‡ï¼ˆ6ä¸ªæœˆï¼‰
- å®ç°äº‘åŸç”Ÿéƒ¨ç½²ï¼Œè¿ç§»åˆ°Kubernetes
- å»ºç«‹å®Œæ•´çš„CI/CDæµæ°´çº¿
- å¼•å…¥åˆ†å¸ƒå¼äº‹åŠ¡å¤„ç†æœºåˆ¶
- å®Œå–„ç›‘æ§å‘Šè­¦ä½“ç³»

### é•¿æœŸç›®æ ‡ï¼ˆ12ä¸ªæœˆï¼‰
- æ„å»ºæ··åˆæ¶æ„ï¼ŒPython+GoæŠ€æœ¯æ ˆ
- å®ç°è‡ªåŠ¨æ‰©ç¼©å®¹å’Œæ•…éšœè‡ªæ„ˆ
- å»ºç«‹å¤§æ•°æ®åˆ†æå¹³å°
- è¾¾åˆ°99.99%ç³»ç»Ÿå¯ç”¨æ€§

## ğŸš€ ç¬¬ä¸€é˜¶æ®µï¼šæœåŠ¡æ²»ç†å¢å¼ºï¼ˆæœˆ1-2ï¼‰

### 1.1 APIç½‘å…³ç»Ÿä¸€åŒ–

#### å½“å‰çŠ¶æ€
- ä½¿ç”¨FastAPIè‡ªå»ºç®€å•ç½‘å…³
- ç¼ºä¹ç»Ÿä¸€çš„è·¯ç”±ç®¡ç†
- æ²¡æœ‰é™æµå’Œç†”æ–­æœºåˆ¶

#### ç›®æ ‡çŠ¶æ€
- éƒ¨ç½²é«˜æ€§èƒ½APIç½‘å…³
- ç»Ÿä¸€å…¥å£ç®¡ç†
- å†…ç½®é™æµã€ç†”æ–­ã€è®¤è¯

#### å®æ–½æ­¥éª¤
```bash
# ç¬¬1å‘¨ï¼šç½‘å…³é€‰å‹å’Œéƒ¨ç½²
1. è¯„ä¼°Kongã€Traefikã€Envoyç½‘å…³æ–¹æ¡ˆ
2. éƒ¨ç½²é€‰å®šçš„APIç½‘å…³
3. é…ç½®åŸºç¡€è·¯ç”±è§„åˆ™

# ç¬¬2å‘¨ï¼šåŠŸèƒ½é›†æˆ
1. é›†æˆè®¤è¯ä¸­é—´ä»¶
2. é…ç½®é™æµç­–ç•¥
3. æ·»åŠ ç›‘æ§æŒ‡æ ‡

# ç¬¬3å‘¨ï¼šè¿ç§»å’Œæµ‹è¯•
1. é€æ­¥è¿ç§»ç°æœ‰è·¯ç”±
2. æ€§èƒ½æµ‹è¯•å’Œè°ƒä¼˜
3. ç°åº¦å‘å¸ƒéªŒè¯

# ç¬¬4å‘¨ï¼šä¼˜åŒ–å’Œæ–‡æ¡£
1. ä¼˜åŒ–é…ç½®å‚æ•°
2. ç¼–å†™æ“ä½œæ–‡æ¡£
3. å›¢é˜ŸåŸ¹è®­
```

#### æŠ€æœ¯æ–¹æ¡ˆ
```yaml
# Kongç½‘å…³é…ç½®ç¤ºä¾‹
apiVersion: configuration.konghq.com/v1
kind: KongPlugin
metadata:
  name: rate-limiting
config:
  minute: 100
  hour: 1000
  policy: local
plugin: rate-limiting
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: suoke-life-gateway
  annotations:
    konghq.com/plugins: rate-limiting
spec:
  rules:
  - host: api.suoke.life
    http:
      paths:
      - path: /api/v1/auth
        pathType: Prefix
        backend:
          service:
            name: auth-service
            port:
              number: 50052
```

### 1.2 æœåŠ¡å‘ç°å®Œå–„

#### å®æ–½è®¡åˆ’
```bash
# ç¬¬1å‘¨ï¼šConsulå‡çº§
1. å‡çº§Consulåˆ°æœ€æ–°ç‰ˆæœ¬
2. é…ç½®å¥åº·æ£€æŸ¥æœºåˆ¶
3. æ·»åŠ æœåŠ¡å…ƒæ•°æ®

# ç¬¬2å‘¨ï¼šç›‘æ§é›†æˆ
1. é›†æˆPrometheusç›‘æ§
2. é…ç½®æœåŠ¡çŠ¶æ€å‘Šè­¦
3. å»ºç«‹æœåŠ¡æ‹“æ‰‘å›¾

# ç¬¬3å‘¨ï¼šé«˜å¯ç”¨é…ç½®
1. éƒ¨ç½²Consulé›†ç¾¤
2. é…ç½®æ•°æ®å¤‡ä»½
3. æµ‹è¯•æ•…éšœæ¢å¤

# ç¬¬4å‘¨ï¼šæ–‡æ¡£å’ŒåŸ¹è®­
1. æ›´æ–°æœåŠ¡æ³¨å†Œæµç¨‹
2. ç¼–å†™æ•…éšœå¤„ç†æ‰‹å†Œ
3. å›¢é˜Ÿæ“ä½œåŸ¹è®­
```

### 1.3 é…ç½®ç®¡ç†ç»Ÿä¸€

#### æŠ€æœ¯æ–¹æ¡ˆ
```python
# é…ç½®ç®¡ç†æœåŠ¡
from consul import Consul
import yaml
import os

class ConfigManager:
    def __init__(self, consul_host='localhost', consul_port=8500):
        self.consul = Consul(host=consul_host, port=consul_port)
        self.cache = {}
    
    def get_config(self, service_name: str, config_key: str):
        """è·å–æœåŠ¡é…ç½®"""
        cache_key = f"{service_name}:{config_key}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.cache:
            return self.cache[cache_key]
        
        # ä»Consulè·å–
        index, data = self.consul.kv.get(f"config/{service_name}/{config_key}")
        if data:
            config_value = yaml.safe_load(data['Value'].decode('utf-8'))
            self.cache[cache_key] = config_value
            return config_value
        
        return None
    
    def watch_config(self, service_name: str, callback):
        """ç›‘å¬é…ç½®å˜åŒ–"""
        def config_watcher():
            index = None
            while True:
                index, data = self.consul.kv.get(
                    f"config/{service_name}/", 
                    index=index, 
                    wait='30s'
                )
                if data:
                    callback(data)
        
        import threading
        thread = threading.Thread(target=config_watcher)
        thread.daemon = True
        thread.start()

# ä½¿ç”¨ç¤ºä¾‹
config_manager = ConfigManager()

# è·å–æ•°æ®åº“é…ç½®
db_config = config_manager.get_config('auth-service', 'database')

# ç›‘å¬é…ç½®å˜åŒ–
def on_config_change(config_data):
    print(f"é…ç½®å·²æ›´æ–°: {config_data}")

config_manager.watch_config('auth-service', on_config_change)
```

## ğŸ” ç¬¬äºŒé˜¶æ®µï¼šå¯è§‚æµ‹æ€§æå‡ï¼ˆæœˆ3-4ï¼‰

### 2.1 é“¾è·¯è¿½è¸ªéƒ¨ç½²

#### å®æ–½è®¡åˆ’
```bash
# ç¬¬1å‘¨ï¼šJaegeréƒ¨ç½²
1. éƒ¨ç½²Jaeger All-in-One
2. é…ç½®æ•°æ®å­˜å‚¨ï¼ˆElasticsearchï¼‰
3. éªŒè¯åŸºç¡€åŠŸèƒ½

# ç¬¬2å‘¨ï¼šSDKé›†æˆ
1. PythonæœåŠ¡é›†æˆOpenTelemetry
2. é…ç½®è‡ªåŠ¨åŸ‹ç‚¹
3. æ·»åŠ è‡ªå®šä¹‰Span

# ç¬¬3å‘¨ï¼šé“¾è·¯åˆ†æ
1. åˆ†æå…³é”®ä¸šåŠ¡é“¾è·¯
2. è¯†åˆ«æ€§èƒ½ç“¶é¢ˆ
3. ä¼˜åŒ–æ…¢æŸ¥è¯¢

# ç¬¬4å‘¨ï¼šå‘Šè­¦é…ç½®
1. é…ç½®é“¾è·¯å¼‚å¸¸å‘Šè­¦
2. å»ºç«‹SLAç›‘æ§
3. æ€§èƒ½åŸºçº¿å»ºç«‹
```

#### æŠ€æœ¯å®ç°
```python
# OpenTelemetryé›†æˆ
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.instrumentation.fastapi import FastAPIInstrumentor
from opentelemetry.instrumentation.sqlalchemy import SQLAlchemyInstrumentor

# åˆå§‹åŒ–è¿½è¸ª
def init_tracing(service_name: str):
    trace.set_tracer_provider(TracerProvider())
    tracer = trace.get_tracer(__name__)
    
    # Jaegerå¯¼å‡ºå™¨
    jaeger_exporter = JaegerExporter(
        agent_host_name="jaeger-agent",
        agent_port=6831,
    )
    
    # æ‰¹é‡å¤„ç†å™¨
    span_processor = BatchSpanProcessor(jaeger_exporter)
    trace.get_tracer_provider().add_span_processor(span_processor)
    
    return tracer

# è‡ªåŠ¨åŸ‹ç‚¹
def setup_auto_instrumentation(app):
    # FastAPIè‡ªåŠ¨åŸ‹ç‚¹
    FastAPIInstrumentor.instrument_app(app)
    
    # SQLAlchemyè‡ªåŠ¨åŸ‹ç‚¹
    SQLAlchemyInstrumentor().instrument()

# è‡ªå®šä¹‰åŸ‹ç‚¹
@app.post("/api/v1/diagnosis")
async def create_diagnosis(request: DiagnosisRequest):
    tracer = trace.get_tracer(__name__)
    
    with tracer.start_as_current_span("diagnosis_creation") as span:
        # æ·»åŠ æ ‡ç­¾
        span.set_attribute("user_id", request.user_id)
        span.set_attribute("diagnosis_type", request.type)
        
        # è°ƒç”¨AIæ™ºèƒ½ä½“
        with tracer.start_as_current_span("ai_agent_call") as ai_span:
            ai_span.set_attribute("agent_name", "xiaoai")
            result = await call_ai_agent(request)
            ai_span.set_attribute("result_confidence", result.confidence)
        
        # ä¿å­˜ç»“æœ
        with tracer.start_as_current_span("save_diagnosis") as save_span:
            diagnosis_id = await save_diagnosis(result)
            save_span.set_attribute("diagnosis_id", diagnosis_id)
        
        span.set_attribute("status", "success")
        return {"diagnosis_id": diagnosis_id, "result": result}
```

### 2.2 ç›‘æ§ä½“ç³»å®Œå–„

#### Prometheusé…ç½®å‡çº§
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "suoke_life_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  # åº”ç”¨æœåŠ¡ç›‘æ§
  - job_name: 'suoke-life-services'
    static_configs:
      - targets: 
        - 'auth-service:8000'
        - 'user-service:8000'
        - 'health-data-service:8000'
        - 'xiaoai-service:8000'
        - 'xiaoke-service:8000'
        - 'laoke-service:8000'
        - 'soer-service:8000'
    metrics_path: /metrics
    scrape_interval: 10s

  # åŸºç¡€è®¾æ–½ç›‘æ§
  - job_name: 'infrastructure'
    static_configs:
      - targets:
        - 'postgres-exporter:9187'
        - 'redis-exporter:9121'
        - 'consul-exporter:9107'

  # APIç½‘å…³ç›‘æ§
  - job_name: 'api-gateway'
    static_configs:
      - targets: ['kong:8001']
    metrics_path: /metrics
```

#### å‘Šè­¦è§„åˆ™é…ç½®
```yaml
# suoke_life_rules.yml
groups:
- name: suoke_life_alerts
  rules:
  # æœåŠ¡å¯ç”¨æ€§å‘Šè­¦
  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "æœåŠ¡ {{ $labels.instance }} å·²ä¸‹çº¿"
      description: "æœåŠ¡ {{ $labels.instance }} å·²ä¸‹çº¿è¶…è¿‡1åˆ†é’Ÿ"

  # å“åº”æ—¶é—´å‘Šè­¦
  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "{{ $labels.instance }} å“åº”æ—¶é—´è¿‡é«˜"
      description: "95%è¯·æ±‚å“åº”æ—¶é—´è¶…è¿‡1ç§’ï¼Œå½“å‰å€¼: {{ $value }}ç§’"

  # AIæ™ºèƒ½ä½“è°ƒç”¨å¤±è´¥ç‡å‘Šè­¦
  - alert: AIAgentHighErrorRate
    expr: rate(ai_agent_requests_failed_total[5m]) / rate(ai_agent_requests_total[5m]) > 0.1
    for: 3m
    labels:
      severity: warning
    annotations:
      summary: "AIæ™ºèƒ½ä½“ {{ $labels.agent_name }} é”™è¯¯ç‡è¿‡é«˜"
      description: "é”™è¯¯ç‡: {{ $value | humanizePercentage }}"

  # æ•°æ®åº“è¿æ¥å‘Šè­¦
  - alert: DatabaseConnectionHigh
    expr: pg_stat_activity_count > 80
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: "æ•°æ®åº“è¿æ¥æ•°è¿‡é«˜"
      description: "å½“å‰è¿æ¥æ•°: {{ $value }}"
```

## â˜ï¸ ç¬¬ä¸‰é˜¶æ®µï¼šäº‘åŸç”Ÿæ”¹é€ ï¼ˆæœˆ5-7ï¼‰

### 3.1 Kubernetesè¿ç§»

#### è¿ç§»ç­–ç•¥
```bash
# ç¬¬1-2å‘¨ï¼šç¯å¢ƒå‡†å¤‡
1. æ­å»ºKubernetesé›†ç¾¤
2. é…ç½®ç½‘ç»œå’Œå­˜å‚¨
3. éƒ¨ç½²åŸºç¡€ç»„ä»¶ï¼ˆIngressã€DNSç­‰ï¼‰

# ç¬¬3-4å‘¨ï¼šåº”ç”¨å®¹å™¨åŒ–
1. ä¼˜åŒ–Dockerfile
2. æ„å»ºé•œåƒä»“åº“
3. ç¼–å†™Kubernetes YAML

# ç¬¬5-6å‘¨ï¼šæœåŠ¡è¿ç§»
1. åŸºç¡€è®¾æ–½æœåŠ¡è¿ç§»ï¼ˆæ•°æ®åº“ã€Redisï¼‰
2. æ ¸å¿ƒä¸šåŠ¡æœåŠ¡è¿ç§»
3. AIæ™ºèƒ½ä½“æœåŠ¡è¿ç§»

# ç¬¬7-8å‘¨ï¼šéªŒè¯å’Œä¼˜åŒ–
1. åŠŸèƒ½æµ‹è¯•éªŒè¯
2. æ€§èƒ½æµ‹è¯•å’Œè°ƒä¼˜
3. ç›‘æ§å’Œæ—¥å¿—é…ç½®
```

#### Kubernetesé…ç½®ç¤ºä¾‹
```yaml
# auth-serviceéƒ¨ç½²é…ç½®
apiVersion: apps/v1
kind: Deployment
metadata:
  name: auth-service
  namespace: suoke-life
  labels:
    app: auth-service
    version: v1.0.0
spec:
  replicas: 3
  selector:
    matchLabels:
      app: auth-service
  template:
    metadata:
      labels:
        app: auth-service
        version: v1.0.0
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: auth-service
        image: suoke-life/auth-service:v1.0.0
        ports:
        - containerPort: 8000
          name: http
        - containerPort: 50052
          name: grpc
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-secret
              key: auth-db-url
        - name: REDIS_URL
          valueFrom:
            configMapKeyRef:
              name: redis-config
              key: redis-url
        - name: LOG_LEVEL
          value: "INFO"
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
      volumes:
      - name: config-volume
        configMap:
          name: auth-service-config
---
apiVersion: v1
kind: Service
metadata:
  name: auth-service
  namespace: suoke-life
  labels:
    app: auth-service
spec:
  selector:
    app: auth-service
  ports:
  - name: http
    port: 8000
    targetPort: 8000
    protocol: TCP
  - name: grpc
    port: 50052
    targetPort: 50052
    protocol: TCP
  type: ClusterIP
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: auth-service-hpa
  namespace: suoke-life
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: auth-service
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### 3.2 CI/CDæµæ°´çº¿å»ºè®¾

#### GitLab CIé…ç½®
```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - deploy-dev
  - deploy-staging
  - deploy-prod

variables:
  DOCKER_REGISTRY: registry.suoke.life
  KUBERNETES_NAMESPACE_DEV: suoke-life-dev
  KUBERNETES_NAMESPACE_STAGING: suoke-life-staging
  KUBERNETES_NAMESPACE_PROD: suoke-life-prod

# æµ‹è¯•é˜¶æ®µ
test:
  stage: test
  image: python:3.11
  before_script:
    - pip install uv
    - uv pip install -r requirements.txt
  script:
    - pytest tests/ --cov=src/ --cov-report=xml
    - flake8 src/
    - mypy src/
  coverage: '/TOTAL.*\s+(\d+%)$/'
  artifacts:
    reports:
      coverage_report:
        coverage_format: cobertura
        path: coverage.xml

# æ„å»ºé˜¶æ®µ
build:
  stage: build
  image: docker:latest
  services:
    - docker:dind
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - docker build -t $DOCKER_REGISTRY/$CI_PROJECT_NAME:$CI_COMMIT_SHA .
    - docker push $DOCKER_REGISTRY/$CI_PROJECT_NAME:$CI_COMMIT_SHA
    - docker tag $DOCKER_REGISTRY/$CI_PROJECT_NAME:$CI_COMMIT_SHA $DOCKER_REGISTRY/$CI_PROJECT_NAME:latest
    - docker push $DOCKER_REGISTRY/$CI_PROJECT_NAME:latest
  only:
    - main
    - develop

# å¼€å‘ç¯å¢ƒéƒ¨ç½²
deploy-dev:
  stage: deploy-dev
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context $KUBE_CONTEXT_DEV
    - kubectl set image deployment/$CI_PROJECT_NAME $CI_PROJECT_NAME=$DOCKER_REGISTRY/$CI_PROJECT_NAME:$CI_COMMIT_SHA -n $KUBERNETES_NAMESPACE_DEV
    - kubectl rollout status deployment/$CI_PROJECT_NAME -n $KUBERNETES_NAMESPACE_DEV
  environment:
    name: development
    url: https://dev-api.suoke.life
  only:
    - develop

# ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
deploy-prod:
  stage: deploy-prod
  image: bitnami/kubectl:latest
  script:
    - kubectl config use-context $KUBE_CONTEXT_PROD
    - kubectl set image deployment/$CI_PROJECT_NAME $CI_PROJECT_NAME=$DOCKER_REGISTRY/$CI_PROJECT_NAME:$CI_COMMIT_SHA -n $KUBERNETES_NAMESPACE_PROD
    - kubectl rollout status deployment/$CI_PROJECT_NAME -n $KUBERNETES_NAMESPACE_PROD
  environment:
    name: production
    url: https://api.suoke.life
  when: manual
  only:
    - main
```

## ğŸ”„ ç¬¬å››é˜¶æ®µï¼šåˆ†å¸ƒå¼äº‹åŠ¡ï¼ˆæœˆ8-9ï¼‰

### 4.1 Sagaæ¨¡å¼å®ç°

#### äº‹åŠ¡åè°ƒå™¨
```python
# saga_orchestrator.py
from typing import List, Dict, Any, Callable
from dataclasses import dataclass
from enum import Enum
import asyncio
import logging

class SagaStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    COMPENSATING = "compensating"
    COMPENSATED = "compensated"

@dataclass
class SagaStep:
    name: str
    action: Callable
    compensate: Callable
    timeout: int = 30
    retry_count: int = 3

@dataclass
class SagaExecution:
    saga_id: str
    status: SagaStatus
    current_step: int
    executed_steps: List[str]
    context: Dict[str, Any]

class SagaOrchestrator:
    def __init__(self, redis_client):
        self.redis = redis_client
        self.logger = logging.getLogger(__name__)
    
    async def execute_saga(self, saga_id: str, steps: List[SagaStep], context: Dict[str, Any] = None):
        """æ‰§è¡ŒSagaäº‹åŠ¡"""
        execution = SagaExecution(
            saga_id=saga_id,
            status=SagaStatus.RUNNING,
            current_step=0,
            executed_steps=[],
            context=context or {}
        )
        
        try:
            # ä¿å­˜æ‰§è¡ŒçŠ¶æ€
            await self._save_execution(execution)
            
            # æ‰§è¡Œæ­¥éª¤
            for i, step in enumerate(steps):
                execution.current_step = i
                await self._save_execution(execution)
                
                # æ‰§è¡Œæ­¥éª¤
                success = await self._execute_step(step, execution.context)
                
                if success:
                    execution.executed_steps.append(step.name)
                    self.logger.info(f"Saga {saga_id} step {step.name} completed")
                else:
                    # æ‰§è¡Œè¡¥å¿
                    execution.status = SagaStatus.COMPENSATING
                    await self._compensate_saga(execution, steps)
                    return False
            
            # æ‰€æœ‰æ­¥éª¤æˆåŠŸ
            execution.status = SagaStatus.COMPLETED
            await self._save_execution(execution)
            self.logger.info(f"Saga {saga_id} completed successfully")
            return True
            
        except Exception as e:
            self.logger.error(f"Saga {saga_id} failed: {e}")
            execution.status = SagaStatus.FAILED
            await self._compensate_saga(execution, steps)
            return False
    
    async def _execute_step(self, step: SagaStep, context: Dict[str, Any]) -> bool:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤"""
        for attempt in range(step.retry_count):
            try:
                result = await asyncio.wait_for(
                    step.action(context), 
                    timeout=step.timeout
                )
                if result:
                    context.update(result)
                return True
            except Exception as e:
                self.logger.warning(f"Step {step.name} attempt {attempt + 1} failed: {e}")
                if attempt == step.retry_count - 1:
                    return False
                await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
        return False
    
    async def _compensate_saga(self, execution: SagaExecution, steps: List[SagaStep]):
        """æ‰§è¡Œè¡¥å¿æ“ä½œ"""
        self.logger.info(f"Starting compensation for saga {execution.saga_id}")
        
        # é€†åºæ‰§è¡Œè¡¥å¿
        for step_name in reversed(execution.executed_steps):
            step = next(s for s in steps if s.name == step_name)
            try:
                await step.compensate(execution.context)
                self.logger.info(f"Compensated step {step_name}")
            except Exception as e:
                self.logger.error(f"Compensation failed for step {step_name}: {e}")
        
        execution.status = SagaStatus.COMPENSATED
        await self._save_execution(execution)
    
    async def _save_execution(self, execution: SagaExecution):
        """ä¿å­˜æ‰§è¡ŒçŠ¶æ€"""
        await self.redis.hset(
            f"saga:{execution.saga_id}",
            mapping={
                "status": execution.status.value,
                "current_step": execution.current_step,
                "executed_steps": ",".join(execution.executed_steps),
                "context": json.dumps(execution.context)
            }
        )

# å¥åº·å’¨è¯¢Sagaç¤ºä¾‹
class HealthConsultationSaga:
    def __init__(self, orchestrator: SagaOrchestrator):
        self.orchestrator = orchestrator
    
    async def execute_consultation(self, user_id: str, consultation_data: Dict[str, Any]):
        """æ‰§è¡Œå¥åº·å’¨è¯¢æµç¨‹"""
        saga_id = f"consultation_{user_id}_{int(time.time())}"
        
        steps = [
            SagaStep(
                name="create_consultation_record",
                action=self._create_consultation_record,
                compensate=self._delete_consultation_record
            ),
            SagaStep(
                name="call_ai_agents",
                action=self._call_ai_agents,
                compensate=self._cancel_ai_analysis
            ),
            SagaStep(
                name="generate_diagnosis_report",
                action=self._generate_diagnosis_report,
                compensate=self._delete_diagnosis_report
            ),
            SagaStep(
                name="send_notification",
                action=self._send_notification,
                compensate=self._cancel_notification
            ),
            SagaStep(
                name="update_health_record",
                action=self._update_health_record,
                compensate=self._revert_health_record
            )
        ]
        
        context = {
            "user_id": user_id,
            "consultation_data": consultation_data,
            "timestamp": time.time()
        }
        
        return await self.orchestrator.execute_saga(saga_id, steps, context)
    
    async def _create_consultation_record(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºå’¨è¯¢è®°å½•"""
        # è°ƒç”¨å’¨è¯¢æœåŠ¡API
        consultation_id = await consultation_service.create_record(
            user_id=context["user_id"],
            data=context["consultation_data"]
        )
        return {"consultation_id": consultation_id}
    
    async def _delete_consultation_record(self, context: Dict[str, Any]):
        """åˆ é™¤å’¨è¯¢è®°å½•"""
        if "consultation_id" in context:
            await consultation_service.delete_record(context["consultation_id"])
    
    async def _call_ai_agents(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """è°ƒç”¨AIæ™ºèƒ½ä½“"""
        # å¹¶è¡Œè°ƒç”¨å¤šä¸ªæ™ºèƒ½ä½“
        tasks = [
            xiaoai_service.analyze(context["consultation_data"]),
            xiaoke_service.diagnose(context["consultation_data"]),
            laoke_service.recommend(context["consultation_data"])
        ]
        
        results = await asyncio.gather(*tasks)
        
        return {
            "xiaoai_result": results[0],
            "xiaoke_result": results[1],
            "laoke_result": results[2]
        }
    
    async def _cancel_ai_analysis(self, context: Dict[str, Any]):
        """å–æ¶ˆAIåˆ†æ"""
        # é€šçŸ¥æ™ºèƒ½ä½“å–æ¶ˆåˆ†æ
        if "xiaoai_result" in context:
            await xiaoai_service.cancel_analysis(context["xiaoai_result"]["analysis_id"])
```

## ğŸ“Š ç¬¬äº”é˜¶æ®µï¼šæ€§èƒ½ä¼˜åŒ–ï¼ˆæœˆ10-11ï¼‰

### 5.1 ç¼“å­˜æ¶æ„å‡çº§

#### å¤šçº§ç¼“å­˜å®ç°
```python
# multi_level_cache.py
from typing import Any, Optional, Dict
import asyncio
import json
import time
from dataclasses import dataclass

@dataclass
class CacheItem:
    value: Any
    expire_time: float
    hit_count: int = 0

class MultiLevelCache:
    def __init__(self, 
                 l1_size: int = 1000,
                 l1_ttl: int = 300,
                 l2_ttl: int = 3600,
                 redis_client=None):
        self.l1_cache: Dict[str, CacheItem] = {}  # å†…å­˜ç¼“å­˜
        self.l1_size = l1_size
        self.l1_ttl = l1_ttl
        self.l2_ttl = l2_ttl
        self.redis = redis_client  # Redisç¼“å­˜
        self.stats = {
            "l1_hits": 0,
            "l2_hits": 0,
            "misses": 0,
            "evictions": 0
        }
    
    async def get(self, key: str) -> Optional[Any]:
        """è·å–ç¼“å­˜å€¼"""
        # L1ç¼“å­˜æ£€æŸ¥
        if key in self.l1_cache:
            item = self.l1_cache[key]
            if time.time() < item.expire_time:
                item.hit_count += 1
                self.stats["l1_hits"] += 1
                return item.value
            else:
                del self.l1_cache[key]
        
        # L2ç¼“å­˜æ£€æŸ¥
        if self.redis:
            value = await self.redis.get(key)
            if value:
                self.stats["l2_hits"] += 1
                # ååºåˆ—åŒ–
                try:
                    data = json.loads(value)
                    # å†™å…¥L1ç¼“å­˜
                    await self._set_l1(key, data)
                    return data
                except json.JSONDecodeError:
                    return value
        
        self.stats["misses"] += 1
        return None
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None):
        """è®¾ç½®ç¼“å­˜å€¼"""
        # è®¾ç½®L1ç¼“å­˜
        await self._set_l1(key, value, ttl or self.l1_ttl)
        
        # è®¾ç½®L2ç¼“å­˜
        if self.redis:
            serialized_value = json.dumps(value) if isinstance(value, (dict, list)) else value
            await self.redis.setex(key, ttl or self.l2_ttl, serialized_value)
    
    async def _set_l1(self, key: str, value: Any, ttl: int = None):
        """è®¾ç½®L1ç¼“å­˜"""
        # æ£€æŸ¥å®¹é‡é™åˆ¶
        if len(self.l1_cache) >= self.l1_size:
            await self._evict_l1()
        
        expire_time = time.time() + (ttl or self.l1_ttl)
        self.l1_cache[key] = CacheItem(value=value, expire_time=expire_time)
    
    async def _evict_l1(self):
        """L1ç¼“å­˜æ·˜æ±°ç­–ç•¥ï¼ˆLFUï¼‰"""
        if not self.l1_cache:
            return
        
        # æ‰¾åˆ°æœ€å°‘ä½¿ç”¨çš„key
        min_hit_key = min(self.l1_cache.keys(), 
                         key=lambda k: self.l1_cache[k].hit_count)
        del self.l1_cache[min_hit_key]
        self.stats["evictions"] += 1
    
    async def delete(self, key: str):
        """åˆ é™¤ç¼“å­˜"""
        # åˆ é™¤L1ç¼“å­˜
        if key in self.l1_cache:
            del self.l1_cache[key]
        
        # åˆ é™¤L2ç¼“å­˜
        if self.redis:
            await self.redis.delete(key)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_requests = sum(self.stats.values()) - self.stats["evictions"]
        hit_rate = (self.stats["l1_hits"] + self.stats["l2_hits"]) / max(total_requests, 1)
        
        return {
            **self.stats,
            "l1_size": len(self.l1_cache),
            "hit_rate": hit_rate,
            "l1_hit_rate": self.stats["l1_hits"] / max(total_requests, 1),
            "l2_hit_rate": self.stats["l2_hits"] / max(total_requests, 1)
        }

# ç¼“å­˜è£…é¥°å™¨
def cached(ttl: int = 3600, key_prefix: str = ""):
    def decorator(func):
        async def wrapper(*args, **kwargs):
            # ç”Ÿæˆç¼“å­˜key
            cache_key = f"{key_prefix}:{func.__name__}:{hash(str(args) + str(kwargs))}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = await cache.get(cache_key)
            if cached_result is not None:
                return cached_result
            
            # æ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)
            
            # å­˜å…¥ç¼“å­˜
            await cache.set(cache_key, result, ttl)
            
            return result
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
cache = MultiLevelCache(redis_client=redis_client)

@cached(ttl=1800, key_prefix="user_profile")
async def get_user_profile(user_id: str):
    """è·å–ç”¨æˆ·æ¡£æ¡ˆ"""
    return await user_service.get_profile(user_id)

@cached(ttl=3600, key_prefix="ai_diagnosis")
async def get_ai_diagnosis(symptoms: str, user_id: str):
    """è·å–AIè¯Šæ–­ç»“æœ"""
    return await ai_service.diagnose(symptoms, user_id)
```

### 5.2 æ•°æ®åº“ä¼˜åŒ–

#### è¯»å†™åˆ†ç¦»é…ç½®
```python
# database.py
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import random

class DatabaseManager:
    def __init__(self, master_url: str, slave_urls: List[str]):
        # ä¸»åº“è¿æ¥ï¼ˆå†™æ“ä½œï¼‰
        self.master_engine = create_engine(
            master_url,
            pool_size=20,
            max_overflow=30,
            pool_pre_ping=True,
            pool_recycle=3600
        )
        self.MasterSession = sessionmaker(bind=self.master_engine)
        
        # ä»åº“è¿æ¥ï¼ˆè¯»æ“ä½œï¼‰
        self.slave_engines = [
            create_engine(
                url,
                pool_size=15,
                max_overflow=25,
                pool_pre_ping=True,
                pool_recycle=3600
            ) for url in slave_urls
        ]
        self.SlaveSessions = [
            sessionmaker(bind=engine) for engine in self.slave_engines
        ]
    
    def get_write_session(self):
        """è·å–å†™ä¼šè¯"""
        return self.MasterSession()
    
    def get_read_session(self):
        """è·å–è¯»ä¼šè¯ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰"""
        if not self.SlaveSessions:
            return self.MasterSession()
        
        # éšæœºé€‰æ‹©ä»åº“
        session_class = random.choice(self.SlaveSessions)
        return session_class()

# æ•°æ®åº“æ“ä½œåŸºç±»
class BaseRepository:
    def __init__(self, db_manager: DatabaseManager):
        self.db_manager = db_manager
    
    async def create(self, model_instance):
        """åˆ›å»ºæ“ä½œï¼ˆä½¿ç”¨ä¸»åº“ï¼‰"""
        with self.db_manager.get_write_session() as session:
            session.add(model_instance)
            session.commit()
            session.refresh(model_instance)
            return model_instance
    
    async def get_by_id(self, model_class, id: int):
        """æŸ¥è¯¢æ“ä½œï¼ˆä½¿ç”¨ä»åº“ï¼‰"""
        with self.db_manager.get_read_session() as session:
            return session.query(model_class).filter(model_class.id == id).first()
    
    async def update(self, model_instance):
        """æ›´æ–°æ“ä½œï¼ˆä½¿ç”¨ä¸»åº“ï¼‰"""
        with self.db_manager.get_write_session() as session:
            session.merge(model_instance)
            session.commit()
            return model_instance
```

#### æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–
```sql
-- ç”¨æˆ·å¥åº·æ•°æ®è¡¨ä¼˜åŒ–
-- åŸå§‹è¡¨ç»“æ„
CREATE TABLE user_health_data (
    id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL,
    data_type VARCHAR(50) NOT NULL,
    data_value JSONB NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- æ·»åŠ å¤åˆç´¢å¼•
CREATE INDEX CONCURRENTLY idx_user_health_data_user_type_time 
ON user_health_data(user_id, data_type, created_at DESC);

-- æ·»åŠ JSONBç´¢å¼•
CREATE INDEX CONCURRENTLY idx_user_health_data_value_gin 
ON user_health_data USING GIN (data_value);

-- åˆ†åŒºè¡¨ï¼ˆæŒ‰æ—¶é—´åˆ†åŒºï¼‰
CREATE TABLE user_health_data_2024_q1 PARTITION OF user_health_data
FOR VALUES FROM ('2024-01-01') TO ('2024-04-01');

CREATE TABLE user_health_data_2024_q2 PARTITION OF user_health_data
FOR VALUES FROM ('2024-04-01') TO ('2024-07-01');

-- è¯Šæ–­è®°å½•è¡¨ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_diagnosis_records_user_status_time
ON diagnosis_records(user_id, status, created_at DESC);

-- AIåˆ†æç»“æœè¡¨ä¼˜åŒ–
CREATE INDEX CONCURRENTLY idx_ai_analysis_agent_confidence
ON ai_analysis_results(agent_name, confidence DESC, created_at DESC);

-- æŸ¥è¯¢ä¼˜åŒ–ç¤ºä¾‹
-- ä¼˜åŒ–å‰
SELECT * FROM user_health_data 
WHERE user_id = 123 
ORDER BY created_at DESC 
LIMIT 10;

-- ä¼˜åŒ–åï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
SELECT id, user_id, data_type, data_value, created_at 
FROM user_health_data 
WHERE user_id = 123 
ORDER BY created_at DESC 
LIMIT 10;

-- JSONBæŸ¥è¯¢ä¼˜åŒ–
-- ä¼˜åŒ–å‰
SELECT * FROM user_health_data 
WHERE data_value->>'blood_pressure' IS NOT NULL;

-- ä¼˜åŒ–åï¼ˆä½¿ç”¨GINç´¢å¼•ï¼‰
SELECT * FROM user_health_data 
WHERE data_value ? 'blood_pressure';
```

## ğŸ“ˆ ç¬¬å…­é˜¶æ®µï¼šæ··åˆæ¶æ„å®æ–½ï¼ˆæœˆ12ï¼‰

### 6.1 GoæœåŠ¡å¼€å‘

#### APIç½‘å…³Goå®ç°
```go
// main.go
package main

import (
    "context"
    "log"
    "net/http"
    "time"

    "github.com/gin-gonic/gin"
    "github.com/zeromicro/go-zero/core/conf"
    "github.com/zeromicro/go-zero/rest"
)

type Config struct {
    rest.RestConf
    Services struct {
        AuthService    string `json:"authService"`
        UserService    string `json:"userService"`
        HealthService  string `json:"healthService"`
    } `json:"services"`
    RateLimit struct {
        Requests int `json:"requests"`
        Window   int `json:"window"`
    } `json:"rateLimit"`
}

func main() {
    var c Config
    conf.MustLoad("gateway.yaml", &c)

    server := rest.MustNewServer(c.RestConf)
    defer server.Stop()

    // æ³¨å†Œä¸­é—´ä»¶
    server.Use(RateLimitMiddleware(c.RateLimit))
    server.Use(AuthMiddleware())
    server.Use(LoggingMiddleware())
    server.Use(TracingMiddleware())

    // æ³¨å†Œè·¯ç”±
    registerRoutes(server, c)

    log.Printf("Starting gateway server at %s:%d...", c.Host, c.Port)
    server.Start()
}

func registerRoutes(server *rest.Server, c Config) {
    // è®¤è¯ç›¸å…³è·¯ç”±
    server.AddRoute(rest.Route{
        Method:  http.MethodPost,
        Path:    "/api/v1/auth/login",
        Handler: ProxyHandler(c.Services.AuthService + "/login"),
    })

    // ç”¨æˆ·ç›¸å…³è·¯ç”±
    server.AddRoute(rest.Route{
        Method:  http.MethodGet,
        Path:    "/api/v1/users/:id",
        Handler: ProxyHandler(c.Services.UserService + "/users/:id"),
    })

    // å¥åº·æ•°æ®è·¯ç”±
    server.AddRoute(rest.Route{
        Method:  http.MethodPost,
        Path:    "/api/v1/health/diagnosis",
        Handler: ProxyHandler(c.Services.HealthService + "/diagnosis"),
    })

    // AIæ™ºèƒ½ä½“è·¯ç”±ï¼ˆä¿æŒPythonæœåŠ¡ï¼‰
    server.AddRoute(rest.Route{
        Method:  http.MethodPost,
        Path:    "/api/v1/ai/xiaoai",
        Handler: ProxyHandler("http://xiaoai-service:8000/analyze"),
    })
}

// ä»£ç†å¤„ç†å™¨
func ProxyHandler(targetURL string) http.HandlerFunc {
    return func(w http.ResponseWriter, r *http.Request) {
        // å®ç°åå‘ä»£ç†é€»è¾‘
        proxy := &httputil.ReverseProxy{
            Director: func(req *http.Request) {
                req.URL.Scheme = "http"
                req.URL.Host = targetURL
                req.Host = targetURL
            },
            ModifyResponse: func(resp *http.Response) error {
                // æ·»åŠ å“åº”å¤´
                resp.Header.Set("X-Gateway", "suoke-life-gateway")
                return nil
            },
        }
        proxy.ServeHTTP(w, r)
    }
}

// é™æµä¸­é—´ä»¶
func RateLimitMiddleware(config struct{ Requests, Window int }) rest.Middleware {
    return func(next http.HandlerFunc) http.HandlerFunc {
        limiter := rate.NewLimiter(
            rate.Every(time.Duration(config.Window)*time.Second/time.Duration(config.Requests)),
            config.Requests,
        )
        
        return func(w http.ResponseWriter, r *http.Request) {
            if !limiter.Allow() {
                http.Error(w, "Rate limit exceeded", http.StatusTooManyRequests)
                return
            }
            next(w, r)
        }
    }
}

// è®¤è¯ä¸­é—´ä»¶
func AuthMiddleware() rest.Middleware {
    return func(next http.HandlerFunc) http.HandlerFunc {
        return func(w http.ResponseWriter, r *http.Request) {
            // è·³è¿‡è®¤è¯çš„è·¯å¾„
            skipPaths := []string{"/api/v1/auth/login", "/health", "/metrics"}
            for _, path := range skipPaths {
                if r.URL.Path == path {
                    next(w, r)
                    return
                }
            }

            // éªŒè¯JWT token
            token := r.Header.Get("Authorization")
            if token == "" {
                http.Error(w, "Missing authorization header", http.StatusUnauthorized)
                return
            }

            // éªŒè¯tokené€»è¾‘
            if !validateToken(token) {
                http.Error(w, "Invalid token", http.StatusUnauthorized)
                return
            }

            next(w, r)
        }
    }
}
```

### 6.2 æœåŠ¡é—´é€šä¿¡ä¼˜åŒ–

#### gRPCæœåŠ¡å®šä¹‰
```protobuf
// health_service.proto
syntax = "proto3";

package health;

option go_package = "github.com/SUOKE2024/suoke_life/services/health-data-service/pb";

// å¥åº·æœåŠ¡
service HealthService {
    // åˆ›å»ºè¯Šæ–­è®°å½•
    rpc CreateDiagnosis(CreateDiagnosisRequest) returns (CreateDiagnosisResponse);
    
    // è·å–è¯Šæ–­è®°å½•
    rpc GetDiagnosis(GetDiagnosisRequest) returns (GetDiagnosisResponse);
    
    // æ›´æ–°å¥åº·æ•°æ®
    rpc UpdateHealthData(UpdateHealthDataRequest) returns (UpdateHealthDataResponse);
    
    // è·å–å¥åº·æŠ¥å‘Š
    rpc GetHealthReport(GetHealthReportRequest) returns (GetHealthReportResponse);
}

message CreateDiagnosisRequest {
    string user_id = 1;
    string diagnosis_type = 2;
    map<string, string> symptoms = 3;
    repeated string images = 4;
    string audio_data = 5;
}

message CreateDiagnosisResponse {
    string diagnosis_id = 1;
    string status = 2;
    string message = 3;
}

message DiagnosisResult {
    string diagnosis_id = 1;
    string user_id = 2;
    string diagnosis_type = 3;
    map<string, string> results = 4;
    float confidence = 5;
    string created_at = 6;
    string updated_at = 7;
}
```

#### Go gRPCå®¢æˆ·ç«¯
```go
// health_client.go
package client

import (
    "context"
    "time"

    "google.golang.org/grpc"
    "google.golang.org/grpc/credentials/insecure"
    
    pb "github.com/SUOKE2024/suoke_life/services/health-data-service/pb"
)

type HealthClient struct {
    client pb.HealthServiceClient
    conn   *grpc.ClientConn
}

func NewHealthClient(address string) (*HealthClient, error) {
    conn, err := grpc.Dial(address, 
        grpc.WithTransportCredentials(insecure.NewCredentials()),
        grpc.WithTimeout(5*time.Second),
    )
    if err != nil {
        return nil, err
    }

    client := pb.NewHealthServiceClient(conn)
    return &HealthClient{
        client: client,
        conn:   conn,
    }, nil
}

func (hc *HealthClient) CreateDiagnosis(ctx context.Context, req *pb.CreateDiagnosisRequest) (*pb.CreateDiagnosisResponse, error) {
    ctx, cancel := context.WithTimeout(ctx, 30*time.Second)
    defer cancel()

    return hc.client.CreateDiagnosis(ctx, req)
}

func (hc *HealthClient) GetDiagnosis(ctx context.Context, diagnosisID string) (*pb.DiagnosisResult, error) {
    ctx, cancel := context.WithTimeout(ctx, 10*time.Second)
    defer cancel()

    req := &pb.GetDiagnosisRequest{
        DiagnosisId: diagnosisID,
    }

    resp, err := hc.client.GetDiagnosis(ctx, req)
    if err != nil {
        return nil, err
    }

    return resp.Diagnosis, nil
}

func (hc *HealthClient) Close() error {
    return hc.conn.Close()
}
```

## ğŸ“Š ç›‘æ§å’Œè¯„ä¼°

### å…³é”®æŒ‡æ ‡ç›‘æ§

#### æ€§èƒ½æŒ‡æ ‡
```yaml
# æ€§èƒ½ç›‘æ§æŒ‡æ ‡
performance_metrics:
  response_time:
    target: "< 200ms (P95)"
    current: "150ms (P95)"
    
  throughput:
    target: "> 1000 QPS"
    current: "800 QPS"
    
  error_rate:
    target: "< 0.1%"
    current: "0.05%"
    
  availability:
    target: "> 99.9%"
    current: "99.8%"

# ä¸šåŠ¡æŒ‡æ ‡
business_metrics:
  ai_agent_accuracy:
    target: "> 95%"
    current: "94%"
    
  diagnosis_completion_rate:
    target: "> 98%"
    current: "97%"
    
  user_satisfaction:
    target: "> 4.5/5"
    current: "4.3/5"
```

#### ç›‘æ§ä»ªè¡¨æ¿é…ç½®
```json
{
  "dashboard": {
    "title": "ç´¢å…‹ç”Ÿæ´»ç³»ç»Ÿç›‘æ§",
    "panels": [
      {
        "title": "APIç½‘å…³æ€§èƒ½",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m]))",
            "legendFormat": "P95å“åº”æ—¶é—´"
          },
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "QPS"
          }
        ]
      },
      {
        "title": "AIæ™ºèƒ½ä½“çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"ai-agents\"}",
            "legendFormat": "{{instance}}"
          }
        ]
      },
      {
        "title": "æ•°æ®åº“æ€§èƒ½",
        "type": "graph",
        "targets": [
          {
            "expr": "pg_stat_activity_count",
            "legendFormat": "æ´»è·ƒè¿æ¥æ•°"
          },
          {
            "expr": "rate(pg_stat_database_tup_returned[5m])",
            "legendFormat": "æŸ¥è¯¢QPS"
          }
        ]
      }
    ]
  }
}
```

## ğŸ¯ æ€»ç»“

æœ¬è¡ŒåŠ¨è®¡åˆ’é€šè¿‡å…­ä¸ªé˜¶æ®µçš„æ¸è¿›å¼å‡çº§ï¼Œå°†ç´¢å…‹ç”Ÿæ´»APPä»ç°æœ‰çš„Pythonå¾®æœåŠ¡æ¶æ„å‡çº§ä¸ºç°ä»£åŒ–çš„æ··åˆæ¶æ„ï¼š

### æ ¸å¿ƒæˆæœ
1. **æœåŠ¡æ²»ç†èƒ½åŠ›æå‡**: å¼•å…¥APIç½‘å…³ã€ç†”æ–­é™æµã€é…ç½®ä¸­å¿ƒ
2. **å¯è§‚æµ‹æ€§å®Œå–„**: å»ºç«‹é“¾è·¯è¿½è¸ªã€ç›‘æ§å‘Šè­¦ã€æ—¥å¿—ç®¡ç†ä½“ç³»
3. **äº‘åŸç”Ÿæ”¹é€ **: è¿ç§»åˆ°Kubernetesï¼Œå®ç°è‡ªåŠ¨æ‰©ç¼©å®¹
4. **åˆ†å¸ƒå¼äº‹åŠ¡**: å¼•å…¥Sagaæ¨¡å¼ï¼Œä¿è¯æ•°æ®ä¸€è‡´æ€§
5. **æ€§èƒ½ä¼˜åŒ–**: å¤šçº§ç¼“å­˜ã€æ•°æ®åº“ä¼˜åŒ–ã€è¯»å†™åˆ†ç¦»
6. **æ··åˆæ¶æ„**: Python+GoæŠ€æœ¯æ ˆï¼Œå‘æŒ¥å„è‡ªä¼˜åŠ¿

### é¢„æœŸæ”¶ç›Š
- **æ€§èƒ½æå‡**: å“åº”æ—¶é—´å‡å°‘50%ï¼Œååé‡æå‡100%
- **ç¨³å®šæ€§**: ç³»ç»Ÿå¯ç”¨æ€§ä»99.8%æå‡åˆ°99.99%
- **å¼€å‘æ•ˆç‡**: éƒ¨ç½²æ—¶é—´å‡å°‘60%ï¼Œæ–°åŠŸèƒ½ä¸Šçº¿æé€Ÿ40%
- **è¿ç»´æˆæœ¬**: äººå·¥å¹²é¢„å‡å°‘70%ï¼Œè¿ç»´æˆæœ¬é™ä½50%

### é£é™©æ§åˆ¶
- åˆ†é˜¶æ®µå®æ–½ï¼Œé™ä½æŠ€æœ¯é£é™©
- ä¿æŒä¸šåŠ¡è¿ç»­æ€§ï¼Œé‡‡ç”¨è“ç»¿éƒ¨ç½²
- å……åˆ†çš„æµ‹è¯•éªŒè¯å’Œå›¢é˜ŸåŸ¹è®­
- å»ºç«‹å®Œå–„çš„å›æ»šæœºåˆ¶

é€šè¿‡æœ¬è¡ŒåŠ¨è®¡åˆ’çš„å®æ–½ï¼Œç´¢å…‹ç”Ÿæ´»å°†æ‹¥æœ‰ä¸€ä¸ªæ—¢ä¿æŒAI/åŒ»ç–—ä¸“ä¸šä¼˜åŠ¿ï¼Œåˆå…·å¤‡ç°ä»£åŒ–å¾®æœåŠ¡æ²»ç†èƒ½åŠ›çš„æŠ€æœ¯æ¶æ„ï¼Œä¸ºä¸šåŠ¡çš„å¿«é€Ÿå‘å±•æä¾›å¼ºæœ‰åŠ›çš„æŠ€æœ¯æ”¯æ’‘ã€‚ 