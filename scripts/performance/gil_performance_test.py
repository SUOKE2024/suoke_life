"""
gil_performance_test - ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ¨¡å—
"""

from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from typing import List, Dict, Any
import asyncio
import json
import multiprocessing
import pickle
import psutil
import time
import zlib

#!/usr/bin/env python3
"""
GILæ€§èƒ½å½±å“æµ‹è¯•è„šæœ¬
ç”¨äºè¯„ä¼°é¡¹ç›®ä¸­CPUå¯†é›†å‹ä»»åŠ¡çš„GILå½±å“
"""


class GILPerformanceTester:
    """GILæ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results = {}
        self.cpu_count = multiprocessing.cpu_count()
        
    def cpu_intensive_task(self, n: int = 1000000) -> int:
        """CPUå¯†é›†å‹ä»»åŠ¡æ¨¡æ‹Ÿ"""
        result = 0
        for i in range(n):
            result += i ** 2
        return result
    
    def numpy_computation_task(self, size: int = 10000) -> np.ndarray:
        """NumPyè®¡ç®—ä»»åŠ¡"""
        arr1 = np.random.rand(size, size)
        arr2 = np.random.rand(size, size)
        return np.dot(arr1, arr2)
    
    def pandas_processing_task(self, rows: int = 100000) -> pd.DataFrame:
        """Pandasæ•°æ®å¤„ç†ä»»åŠ¡"""
        df = pd.DataFrame({
            'A': np.random.randn(rows),
            'B': np.random.randn(rows),
            'C': np.random.randn(rows)
        })
        
        # æ¨¡æ‹Ÿæ•°æ®å¤„ç†æ“ä½œ
        df['D'] = df['A'] * df['B']
        df['E'] = df.groupby(pd.cut(df['C'], 10))['A'].transform('mean')
        return df.describe()
    
    def serialization_task(self, data_size: int = 1000000) -> bytes:
        """åºåˆ—åŒ–ä»»åŠ¡"""
        data = {'numbers': list(range(data_size)), 'text': 'test' * 1000}
        serialized = pickle.dumps(data)
        compressed = zlib.compress(serialized)
        return compressed
    
    def test_single_thread(self, task_func, *args, **kwargs) -> Dict[str, Any]:
        """å•çº¿ç¨‹æµ‹è¯•"""
        start_time = time.time()
        
        results = []
        for _ in range(4):
            result = task_func(*args, **kwargs)
            results.append(result)
        
        end_time = time.time()
        
        return {
            'execution_time': end_time - start_time,
            'results_count': len(results),
            'cpu_usage_before': psutil.cpu_percent(),
            'memory_usage': psutil.Process().memory_info().rss / 1024 / 1024  # MB
        }
    
    def test_multi_thread(self, task_func, *args, **kwargs) -> Dict[str, Any]:
        """å¤šçº¿ç¨‹æµ‹è¯•ï¼ˆå—GILé™åˆ¶ï¼‰"""
        start_time = time.time()
        cpu_before = psutil.cpu_percent()
        
        with ThreadPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(task_func, *args, **kwargs) for _ in range(4)]
            results = [f.result() for f in futures]
        
        end_time = time.time()
        cpu_after = psutil.cpu_percent()
        
        return {
            'execution_time': end_time - start_time,
            'results_count': len(results),
            'cpu_usage_before': cpu_before,
            'cpu_usage_after': cpu_after,
            'memory_usage': psutil.Process().memory_info().rss / 1024 / 1024  # MB
        }
    
    def test_multi_process(self, task_func, *args, **kwargs) -> Dict[str, Any]:
        """å¤šè¿›ç¨‹æµ‹è¯•ï¼ˆç»•è¿‡GILï¼‰"""
        start_time = time.time()
        cpu_before = psutil.cpu_percent()
        
        with ProcessPoolExecutor(max_workers=4) as executor:
            futures = [executor.submit(task_func, *args, **kwargs) for _ in range(4)]
            results = [f.result() for f in futures]
        
        end_time = time.time()
        cpu_after = psutil.cpu_percent()
        
        return {
            'execution_time': end_time - start_time,
            'results_count': len(results),
            'cpu_usage_before': cpu_before,
            'cpu_usage_after': cpu_after,
            'memory_usage': psutil.Process().memory_info().rss / 1024 / 1024  # MB
        }
    
    async def test_async_io(self, delay: float = 0.1) -> Dict[str, Any]:
        """å¼‚æ­¥I/Oæµ‹è¯•ï¼ˆä¸å—GILé™åˆ¶ï¼‰"""
        start_time = time.time()
        
        async def async_task():
            await asyncio.sleep(delay)
            return "completed"
        
        tasks = [async_task() for _ in range(4)]
        results = await asyncio.gather(*tasks)
        
        end_time = time.time()
        
        return {
            'execution_time': end_time - start_time,
            'results_count': len(results),
            'memory_usage': psutil.Process().memory_info().rss / 1024 / 1024  # MB
        }
    
    def run_comprehensive_test(self) -> Dict[str, Any]:
        """è¿è¡Œç»¼åˆæ€§èƒ½æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹GILæ€§èƒ½å½±å“æµ‹è¯•...")
        print(f"CPUæ ¸å¿ƒæ•°: {self.cpu_count}")
        print(f"å½“å‰å†…å­˜ä½¿ç”¨: {psutil.Process().memory_info().rss / 1024 / 1024:.2f}MB")
        print("-" * 60)
        
        test_cases = [
            ("CPUå¯†é›†å‹è®¡ç®—", self.cpu_intensive_task, (), {}),
            ("NumPyçŸ©é˜µè¿ç®—", self.numpy_computation_task, (1000,), {}),
            ("Pandasæ•°æ®å¤„ç†", self.pandas_processing_task, (50000,), {}),
            ("åºåˆ—åŒ–å‹ç¼©", self.serialization_task, (100000,), {}),
        ]
        
        for test_name, task_func, args, kwargs in test_cases:
            print(f"\nğŸ“Š æµ‹è¯•: {test_name}")
            
            # å•çº¿ç¨‹åŸºå‡†
            single_result = self.test_single_thread(task_func, *args, **kwargs)
            print(f"  å•çº¿ç¨‹: {single_result['execution_time']:.2f}s")
            
            # å¤šçº¿ç¨‹æµ‹è¯•
            multi_thread_result = self.test_multi_thread(task_func, *args, **kwargs)
            thread_speedup = single_result['execution_time'] / multi_thread_result['execution_time']
            print(f"  å¤šçº¿ç¨‹: {multi_thread_result['execution_time']:.2f}s (åŠ é€Ÿæ¯”: {thread_speedup:.2f}x)")
            
            # å¤šè¿›ç¨‹æµ‹è¯•
            try:
                multi_process_result = self.test_multi_process(task_func, *args, **kwargs)
                process_speedup = single_result['execution_time'] / multi_process_result['execution_time']
                print(f"  å¤šè¿›ç¨‹: {multi_process_result['execution_time']:.2f}s (åŠ é€Ÿæ¯”: {process_speedup:.2f}x)")
            except Exception as e:
                print(f"  å¤šè¿›ç¨‹: æµ‹è¯•å¤±è´¥ - {e}")
                multi_process_result = None
                process_speedup = 0
            
            # GILå½±å“åˆ†æ
            gil_impact = self._analyze_gil_impact(thread_speedup, process_speedup)
            print(f"  GILå½±å“: {gil_impact}")
            
            # ä¿å­˜ç»“æœ
            self.results[test_name] = {
                'single_thread': single_result,
                'multi_thread': multi_thread_result,
                'multi_process': multi_process_result,
                'thread_speedup': thread_speedup,
                'process_speedup': process_speedup,
                'gil_impact': gil_impact
            }
        
        # å¼‚æ­¥I/Oæµ‹è¯•
        print(f"\nğŸ“Š æµ‹è¯•: å¼‚æ­¥I/O")
        async_result = asyncio.run(self.test_async_io(0.1))
        print(f"  å¼‚æ­¥I/O: {async_result['execution_time']:.2f}s (ç†è®ºæœ€ä¼˜: 0.10s)")
        
        self.results['å¼‚æ­¥I/O'] = async_result
        
        return self.results
    
    def _analyze_gil_impact(self, thread_speedup: float, process_speedup: float) -> str:
        """åˆ†æGILå½±å“ç¨‹åº¦"""
        if thread_speedup < 1.2:
            if process_speedup > 2.0:
                return "ğŸ”´ é«˜GILå½±å“ - å»ºè®®ä½¿ç”¨å¤šè¿›ç¨‹æˆ–å¼‚æ­¥"
            else:
                return "ğŸŸ¡ ä¸­ç­‰GILå½±å“ - è€ƒè™‘ç®—æ³•ä¼˜åŒ–"
        elif thread_speedup < 2.0:
            return "ğŸŸ¡ è½»å¾®GILå½±å“ - å¯æ¥å—"
        else:
            return "ğŸŸ¢ æ— æ˜æ˜¾GILå½±å“"
    
    def generate_report(self, output_file: str = "gil_performance_report.json"):
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        report = {
            'test_timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'system_info': {
                'cpu_count': self.cpu_count,
                'total_memory_gb': psutil.virtual_memory().total / 1024 / 1024 / 1024,
                'python_version': f"{multiprocessing.sys.version_info.major}.{multiprocessing.sys.version_info.minor}",
            },
            'test_results': self.results,
            'recommendations': self._generate_recommendations()
        }
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        return report
    
    def _generate_recommendations(self) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        for test_name, result in self.results.items():
            if test_name == 'å¼‚æ­¥I/O':
                continue
                
            thread_speedup = result.get('thread_speedup', 0)
            process_speedup = result.get('process_speedup', 0)
            
            if thread_speedup < 1.2 and process_speedup > 2.0:
                recommendations.append(
                    f"{test_name}: ä¸¥é‡å—GILé™åˆ¶ï¼Œå»ºè®®ä½¿ç”¨ProcessPoolExecutoræ›¿ä»£ThreadPoolExecutor"
                )
            elif thread_speedup < 1.5:
                recommendations.append(
                    f"{test_name}: å—GILå½±å“ï¼Œè€ƒè™‘ä½¿ç”¨Numba JITç¼–è¯‘æˆ–Cæ‰©å±•ä¼˜åŒ–"
                )
        
        if not recommendations:
            recommendations.append("å½“å‰æµ‹è¯•åœºæ™¯ä¸‹GILå½±å“è¾ƒå°ï¼Œç»§ç»­ç›‘æ§ç”Ÿäº§ç¯å¢ƒæ€§èƒ½")
        
        return recommendations
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ¯ GILæ€§èƒ½æµ‹è¯•æ‘˜è¦")
        print("="*60)
        
        high_impact_count = 0
        medium_impact_count = 0
        
        for test_name, result in self.results.items():
            if test_name == 'å¼‚æ­¥I/O':
                continue
                
            gil_impact = result.get('gil_impact', '')
            if 'ğŸ”´' in gil_impact:
                high_impact_count += 1
            elif 'ğŸŸ¡' in gil_impact:
                medium_impact_count += 1
        
        print(f"é«˜GILå½±å“ä»»åŠ¡: {high_impact_count}")
        print(f"ä¸­ç­‰GILå½±å“ä»»åŠ¡: {medium_impact_count}")
        print(f"æ€»æµ‹è¯•ä»»åŠ¡: {len(self.results) - 1}")  # æ’é™¤å¼‚æ­¥I/O
        
        if high_impact_count > 0:
            print("\nâš ï¸  å»ºè®®ç«‹å³ä¼˜åŒ–é«˜GILå½±å“çš„ä»»åŠ¡")
        elif medium_impact_count > 0:
            print("\nğŸ’¡ è€ƒè™‘ä¼˜åŒ–ä¸­ç­‰GILå½±å“çš„ä»»åŠ¡")
        else:
            print("\nâœ… å½“å‰GILå½±å“åœ¨å¯æ¥å—èŒƒå›´å†…")

def main():
    """ä¸»å‡½æ•°"""
    tester = GILPerformanceTester()
    
    # è¿è¡Œæµ‹è¯•
    results = tester.run_comprehensive_test()
    
    # æ‰“å°æ‘˜è¦
    tester.print_summary()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = tester.generate_report()
    
    # æ‰“å°å»ºè®®
    print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
    for i, recommendation in enumerate(report['recommendations'], 1):
        print(f"  {i}. {recommendation}")

if __name__ == "__main__":
    main() 