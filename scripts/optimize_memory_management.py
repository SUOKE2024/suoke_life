#!/usr/bin/env python3
"""
ç´¢å…‹ç”Ÿæ´»é¡¹ç›® - å†…å­˜ç®¡ç†ä¼˜åŒ–å·¥å…·
æ£€æµ‹å’Œä¿®å¤Pythonä»£ç ä¸­çš„å†…å­˜ç®¡ç†é—®é¢˜
"""

import ast
import gc
import json
import logging
import os
import re
import subprocess
import sys
import tracemalloc
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class MemoryIssue:
    """å†…å­˜é—®é¢˜"""

    file_path: str
    line_number: int
    issue_type: str
    description: str
    code_snippet: str
    suggested_fix: str
    severity: str


class MemoryOptimizer:
    """å†…å­˜ç®¡ç†ä¼˜åŒ–å™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.issues_found = []
        self.backup_dir = self.project_root / "backups" / "memory_optimization"

        # å†…å­˜é—®é¢˜æ£€æµ‹æ¨¡å¼
        self.memory_patterns = {
            "unclosed_file": {
                "patterns": [
                    r"open\s*\([^)]+\)(?!\s*with)",  # open() ä¸åœ¨ with è¯­å¥ä¸­
                    r"file\s*=\s*open\s*\([^)]+\)",  # file = open() æ¨¡å¼
                ],
                "severity": "HIGH",
                "description": "æœªæ­£ç¡®å…³é—­çš„æ–‡ä»¶å¥æŸ„",
            },
            "large_list_comprehension": {
                "patterns": [
                    r"\[[^\]]{100,}\]",  # è¶…é•¿åˆ—è¡¨æ¨å¯¼å¼
                    r"\[[^]]*for[^]]*for[^]]*\]",  # åµŒå¥—åˆ—è¡¨æ¨å¯¼å¼
                ],
                "severity": "MEDIUM",
                "description": "å¯èƒ½æ¶ˆè€—å¤§é‡å†…å­˜çš„åˆ—è¡¨æ¨å¯¼å¼",
            },
            "global_variables": {
                "patterns": [
                    r"global\s+\w+",
                    r"^\s*[A-Z_][A-Z0-9_]*\s*=.*",  # å…¨å±€å¸¸é‡æ¨¡å¼
                ],
                "severity": "MEDIUM",
                "description": "å…¨å±€å˜é‡å¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼",
            },
            "circular_reference": {
                "patterns": [r"self\.\w+\s*=\s*self", r"parent\.\w+\s*=\s*child"],
                "severity": "HIGH",
                "description": "å¯èƒ½çš„å¾ªç¯å¼•ç”¨",
            },
            "large_data_structures": {
                "patterns": [
                    r"dict\(\)\s*#.*large",
                    r"list\(\)\s*#.*large",
                    r"\[\]\s*#.*large",
                ],
                "severity": "MEDIUM",
                "description": "å¤§å‹æ•°æ®ç»“æ„",
            },
            "memory_intensive_operations": {
                "patterns": [
                    r"\.read\(\)",  # è¯»å–æ•´ä¸ªæ–‡ä»¶
                    r"\.readlines\(\)",  # è¯»å–æ‰€æœ‰è¡Œ
                    r"json\.loads\([^)]*\.read\(\)",  # åŠ è½½å¤§JSON
                ],
                "severity": "MEDIUM",
                "description": "å†…å­˜å¯†é›†å‹æ“ä½œ",
            },
        }

        # æ’é™¤çš„æ–‡ä»¶å’Œç›®å½•
        self.exclude_patterns = {
            "venv",
            "env",
            ".env",
            "__pycache__",
            ".git",
            "node_modules",
            ".pytest_cache",
            "dist",
            "build",
            ".idea",
            ".vscode",
            "*.pyc",
            "*.pyo",
            "*.egg-info",
        }

    def scan_memory_issues(self) -> List[MemoryIssue]:
        """æ‰«æå†…å­˜ç®¡ç†é—®é¢˜"""
        logger.info("ğŸ” æ‰«æå†…å­˜ç®¡ç†é—®é¢˜...")

        python_files = self._get_python_files()

        for file_path in python_files:
            try:
                self._analyze_file_memory(file_path)
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ†ææ–‡ä»¶ {file_path}: {e}")

        logger.info(f"å‘ç° {len(self.issues_found)} ä¸ªå†…å­˜é—®é¢˜")
        return self.issues_found

    def _get_python_files(self) -> List[Path]:
        """è·å–æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []

        for root, dirs, files in os.walk(self.project_root):
            # æ’é™¤ç‰¹å®šç›®å½•
            dirs[:] = [
                d
                for d in dirs
                if not any(pattern in d for pattern in self.exclude_patterns)
            ]

            for file in files:
                if file.endswith(".py"):
                    file_path = Path(root) / file
                    # æ’é™¤å¤‡ä»½æ–‡ä»¶
                    if "backup" not in str(file_path).lower():
                        python_files.append(file_path)

        return python_files

    def _analyze_file_memory(self, file_path: Path):
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„å†…å­˜é—®é¢˜"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # ä½¿ç”¨ASTåˆ†æ
            try:
                tree = ast.parse(content)
                self._analyze_ast_memory(file_path, tree, lines)
            except SyntaxError:
                # å¦‚æœASTè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
                self._analyze_regex_memory(file_path, lines)

        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")

    def _analyze_ast_memory(self, file_path: Path, tree: ast.AST, lines: List[str]):
        """ä½¿ç”¨ASTåˆ†æå†…å­˜é—®é¢˜"""
        for node in ast.walk(tree):
            # æ£€æŸ¥æ–‡ä»¶æ“ä½œ
            if isinstance(node, ast.Call):
                self._check_file_operations(file_path, node, lines)

            # æ£€æŸ¥åˆ—è¡¨æ¨å¯¼å¼
            elif isinstance(node, ast.ListComp):
                self._check_list_comprehension(file_path, node, lines)

            # æ£€æŸ¥å…¨å±€å˜é‡
            elif isinstance(node, ast.Global):
                self._check_global_variables(file_path, node, lines)

    def _check_file_operations(self, file_path: Path, node: ast.Call, lines: List[str]):
        """æ£€æŸ¥æ–‡ä»¶æ“ä½œ"""
        if isinstance(node.func, ast.Name) and node.func.id == "open":
            line_num = node.lineno
            line_content = lines[line_num - 1] if line_num <= len(lines) else ""

            # æ£€æŸ¥æ˜¯å¦åœ¨withè¯­å¥ä¸­
            if "with" not in line_content:
                issue = MemoryIssue(
                    file_path=str(file_path.relative_to(self.project_root)),
                    line_number=line_num,
                    issue_type="unclosed_file",
                    description="æ–‡ä»¶æœªä½¿ç”¨withè¯­å¥æ‰“å¼€ï¼Œå¯èƒ½å¯¼è‡´æ–‡ä»¶å¥æŸ„æ³„æ¼",
                    code_snippet=line_content.strip(),
                    suggested_fix=self._suggest_file_fix(line_content),
                    severity="HIGH",
                )
                self.issues_found.append(issue)

    def _check_list_comprehension(
        self, file_path: Path, node: ast.ListComp, lines: List[str]
    ):
        """æ£€æŸ¥åˆ—è¡¨æ¨å¯¼å¼"""
        line_num = node.lineno
        line_content = lines[line_num - 1] if line_num <= len(lines) else ""

        # æ£€æŸ¥åµŒå¥—å¾ªç¯
        if len(node.generators) > 1:
            issue = MemoryIssue(
                file_path=str(file_path.relative_to(self.project_root)),
                line_number=line_num,
                issue_type="large_list_comprehension",
                description="åµŒå¥—åˆ—è¡¨æ¨å¯¼å¼å¯èƒ½æ¶ˆè€—å¤§é‡å†…å­˜",
                code_snippet=line_content.strip(),
                suggested_fix="è€ƒè™‘ä½¿ç”¨ç”Ÿæˆå™¨è¡¨è¾¾å¼æˆ–åˆ†æ­¥å¤„ç†",
                severity="MEDIUM",
            )
            self.issues_found.append(issue)

    def _check_global_variables(
        self, file_path: Path, node: ast.Global, lines: List[str]
    ):
        """æ£€æŸ¥å…¨å±€å˜é‡"""
        line_num = node.lineno
        line_content = lines[line_num - 1] if line_num <= len(lines) else ""

        issue = MemoryIssue(
            file_path=str(file_path.relative_to(self.project_root)),
            line_number=line_num,
            issue_type="global_variables",
            description="å…¨å±€å˜é‡å¯èƒ½å¯¼è‡´å†…å­˜æ³„æ¼",
            code_snippet=line_content.strip(),
            suggested_fix="è€ƒè™‘ä½¿ç”¨ç±»å±æ€§æˆ–å‡½æ•°å‚æ•°æ›¿ä»£å…¨å±€å˜é‡",
            severity="MEDIUM",
        )
        self.issues_found.append(issue)

    def _analyze_regex_memory(self, file_path: Path, lines: List[str]):
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†æå†…å­˜é—®é¢˜ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        for line_num, line in enumerate(lines, 1):
            line_stripped = line.strip()

            for pattern_type, pattern_info in self.memory_patterns.items():
                for pattern in pattern_info["patterns"]:
                    if re.search(pattern, line_stripped):
                        issue = MemoryIssue(
                            file_path=str(file_path.relative_to(self.project_root)),
                            line_number=line_num,
                            issue_type=pattern_type,
                            description=pattern_info["description"],
                            code_snippet=line_stripped,
                            suggested_fix=self._generate_memory_fix(
                                pattern_type, line_stripped
                            ),
                            severity=pattern_info["severity"],
                        )
                        self.issues_found.append(issue)

    def _suggest_file_fix(self, line_content: str) -> str:
        """å»ºè®®æ–‡ä»¶æ“ä½œä¿®å¤æ–¹æ¡ˆ"""
        return f"""
å»ºè®®ä¿®å¤æ–¹æ¡ˆï¼š
åŸä»£ç : {line_content}
ä¿®å¤ä¸º:
with open(...) as f:
    # æ–‡ä»¶æ“ä½œ
    pass
# æ–‡ä»¶ä¼šè‡ªåŠ¨å…³é—­
"""

    def _generate_memory_fix(self, issue_type: str, code_snippet: str) -> str:
        """ç”Ÿæˆå†…å­˜é—®é¢˜ä¿®å¤å»ºè®®"""
        fixes = {
            "unclosed_file": "ä½¿ç”¨ with è¯­å¥ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­",
            "large_list_comprehension": "ä½¿ç”¨ç”Ÿæˆå™¨è¡¨è¾¾å¼: (x for x in ...) æ›¿ä»£ [x for x in ...]",
            "global_variables": "é¿å…ä½¿ç”¨å…¨å±€å˜é‡ï¼Œä½¿ç”¨ç±»å±æ€§æˆ–å‡½æ•°å‚æ•°",
            "circular_reference": "ä½¿ç”¨å¼±å¼•ç”¨ weakref é¿å…å¾ªç¯å¼•ç”¨",
            "large_data_structures": "è€ƒè™‘ä½¿ç”¨ç”Ÿæˆå™¨æˆ–åˆ†æ‰¹å¤„ç†å¤§å‹æ•°æ®",
            "memory_intensive_operations": "åˆ†å—è¯»å–å¤§æ–‡ä»¶ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½åˆ°å†…å­˜",
        }
        return fixes.get(issue_type, "ä¼˜åŒ–å†…å­˜ä½¿ç”¨")

    def create_memory_profiler(self) -> str:
        """åˆ›å»ºå†…å­˜åˆ†æå™¨"""
        logger.info("ğŸ“Š åˆ›å»ºå†…å­˜åˆ†æå™¨...")

        profiler_dir = self.project_root / "src" / "core" / "monitoring"
        profiler_dir.mkdir(parents=True, exist_ok=True)

        profiler_file = profiler_dir / "memory_profiler.py"

        profiler_content = '''"""
ç´¢å…‹ç”Ÿæ´»é¡¹ç›® - å†…å­˜åˆ†æå™¨
ç›‘æ§å’Œåˆ†æåº”ç”¨ç¨‹åºçš„å†…å­˜ä½¿ç”¨æƒ…å†µ
"""

import gc
import sys
import psutil
import tracemalloc
import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from functools import wraps
import time

logger = logging.getLogger(__name__)

@dataclass
class MemorySnapshot:
    """å†…å­˜å¿«ç…§"""
    timestamp: float
    current_memory: float
    peak_memory: float
    objects_count: int
    gc_collections: Dict[int, int]

class MemoryProfiler:
    """å†…å­˜åˆ†æå™¨"""
    
    def __init__(self):
        self.snapshots: List[MemorySnapshot] = []
        self.tracemalloc_started = False
        self.baseline_snapshot = None
    
    def start_profiling(self):
        """å¼€å§‹å†…å­˜åˆ†æ"""
        if not self.tracemalloc_started:
            tracemalloc.start()
            self.tracemalloc_started = True
            logger.info("å†…å­˜åˆ†æå·²å¯åŠ¨")
    
    def stop_profiling(self):
        """åœæ­¢å†…å­˜åˆ†æ"""
        if self.tracemalloc_started:
            tracemalloc.stop()
            self.tracemalloc_started = False
            logger.info("å†…å­˜åˆ†æå·²åœæ­¢")
    
    def take_snapshot(self, label: str = None) -> MemorySnapshot:
        """è·å–å†…å­˜å¿«ç…§"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        snapshot = MemorySnapshot(
            timestamp=time.time(),
            current_memory=memory_info.rss / 1024 / 1024,  # MB
            peak_memory=memory_info.vms / 1024 / 1024,     # MB
            objects_count=len(gc.get_objects()),
            gc_collections={
                0: gc.get_count()[0],
                1: gc.get_count()[1],
                2: gc.get_count()[2]
            }
        )
        
        self.snapshots.append(snapshot)
        
        if label:
            logger.info(f"å†…å­˜å¿«ç…§ [{label}]: {snapshot.current_memory:.2f}MB")
        
        return snapshot
    
    def set_baseline(self):
        """è®¾ç½®åŸºçº¿å¿«ç…§"""
        self.baseline_snapshot = self.take_snapshot("baseline")
    
    def get_memory_diff(self) -> Optional[float]:
        """è·å–ä¸åŸºçº¿çš„å†…å­˜å·®å¼‚"""
        if not self.baseline_snapshot or not self.snapshots:
            return None
        
        current = self.snapshots[-1]
        return current.current_memory - self.baseline_snapshot.current_memory
    
    def analyze_memory_leaks(self) -> List[str]:
        """åˆ†æå†…å­˜æ³„æ¼"""
        if not self.tracemalloc_started:
            return ["å†…å­˜åˆ†ææœªå¯åŠ¨"]
        
        current, peak = tracemalloc.get_traced_memory()
        top_stats = tracemalloc.take_snapshot().statistics('lineno')
        
        leaks = []
        for stat in top_stats[:10]:
            leaks.append(f"{stat.traceback.format()[-1]}: {stat.size / 1024:.1f} KB")
        
        return leaks
    
    def force_garbage_collection(self) -> Dict[str, int]:
        """å¼ºåˆ¶åƒåœ¾å›æ”¶"""
        before_counts = gc.get_count()
        collected = gc.collect()
        after_counts = gc.get_count()
        
        result = {
            'collected_objects': collected,
            'before_counts': before_counts,
            'after_counts': after_counts
        }
        
        logger.info(f"åƒåœ¾å›æ”¶å®Œæˆ: å›æ”¶äº† {collected} ä¸ªå¯¹è±¡")
        return result
    
    def get_memory_report(self) -> str:
        """ç”Ÿæˆå†…å­˜æŠ¥å‘Š"""
        if not self.snapshots:
            return "æ²¡æœ‰å†…å­˜å¿«ç…§æ•°æ®"
        
        latest = self.snapshots[-1]
        report = f"""
å†…å­˜ä½¿ç”¨æŠ¥å‘Š
============
å½“å‰å†…å­˜ä½¿ç”¨: {latest.current_memory:.2f} MB
å³°å€¼å†…å­˜ä½¿ç”¨: {latest.peak_memory:.2f} MB
å¯¹è±¡æ•°é‡: {latest.objects_count:,}
GCç»Ÿè®¡: Gen0={latest.gc_collections[0]}, Gen1={latest.gc_collections[1]}, Gen2={latest.gc_collections[2]}
"""
        
        if self.baseline_snapshot:
            diff = self.get_memory_diff()
            report += f"ä¸åŸºçº¿å·®å¼‚: {diff:+.2f} MB\\n"
        
        if len(self.snapshots) > 1:
            trend = latest.current_memory - self.snapshots[0].current_memory
            report += f"æ€»ä½“è¶‹åŠ¿: {trend:+.2f} MB\\n"
        
        return report

# å†…å­˜ç›‘æ§è£…é¥°å™¨
def memory_monitor(func):
    """å†…å­˜ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        profiler = MemoryProfiler()
        profiler.start_profiling()
        profiler.take_snapshot(f"before_{func.__name__}")
        
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            profiler.take_snapshot(f"after_{func.__name__}")
            diff = profiler.get_memory_diff()
            if diff and diff > 10:  # è¶…è¿‡10MBå¢é•¿
                logger.warning(f"å‡½æ•° {func.__name__} å†…å­˜å¢é•¿: {diff:.2f}MB")
            profiler.stop_profiling()
    
    return wrapper

# å†…å­˜ä¸Šä¸‹æ–‡ç®¡ç†å™¨
class MemoryContext:
    """å†…å­˜ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, operation_name: str):
        self.operation_name = operation_name
        self.profiler = MemoryProfiler()
    
    def __enter__(self):
        self.profiler.start_profiling()
        self.profiler.set_baseline()
        return self.profiler
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        final_snapshot = self.profiler.take_snapshot(f"final_{self.operation_name}")
        diff = self.profiler.get_memory_diff()
        
        if diff and diff > 5:  # è¶…è¿‡5MBå¢é•¿
            logger.warning(f"æ“ä½œ {self.operation_name} å†…å­˜å¢é•¿: {diff:.2f}MB")
        
        self.profiler.stop_profiling()

# å…¨å±€å†…å­˜åˆ†æå™¨å®ä¾‹
global_profiler = MemoryProfiler()
'''

        with open(profiler_file, "w", encoding="utf-8") as f:
            f.write(profiler_content)

        return str(profiler_file)

    def create_memory_optimization_guide(self) -> str:
        """åˆ›å»ºå†…å­˜ä¼˜åŒ–æŒ‡å—"""
        guide_path = (
            self.project_root / "docs" / "development" / "memory_optimization_guide.md"
        )
        guide_path.parent.mkdir(parents=True, exist_ok=True)

        guide_content = """# Pythonå†…å­˜ä¼˜åŒ–æŒ‡å—

## ğŸ“‹ å†…å­˜ç®¡ç†æœ€ä½³å®è·µ

### 1. æ–‡ä»¶æ“ä½œ
```python
# âœ… æ¨è - ä½¿ç”¨withè¯­å¥
with open('file.txt', 'r') as f:
    content = f.read()
# æ–‡ä»¶è‡ªåŠ¨å…³é—­

# âŒ é¿å… - æ‰‹åŠ¨ç®¡ç†æ–‡ä»¶
f = open('file.txt', 'r')
content = f.read()
# å¯èƒ½å¿˜è®°å…³é—­æ–‡ä»¶
```

### 2. å¤§æ•°æ®å¤„ç†
```python
# âœ… æ¨è - ä½¿ç”¨ç”Ÿæˆå™¨
def read_large_file(filename):
    with open(filename, 'r') as f:
        for line in f:
            yield line.strip()

# âŒ é¿å… - ä¸€æ¬¡æ€§åŠ è½½
def read_large_file_bad(filename):
    with open(filename, 'r') as f:
        return f.readlines()  # å ç”¨å¤§é‡å†…å­˜
```

### 3. åˆ—è¡¨æ¨å¯¼å¼
```python
# âœ… æ¨è - ç”Ÿæˆå™¨è¡¨è¾¾å¼
data_gen = (x * 2 for x in range(1000000))

# âŒ é¿å… - å¤§å‹åˆ—è¡¨æ¨å¯¼å¼
data_list = [x * 2 for x in range(1000000)]  # å ç”¨å¤§é‡å†…å­˜
```

### 4. å¾ªç¯å¼•ç”¨
```python
import weakref

class Parent:
    def __init__(self):
        self.children = []
    
    def add_child(self, child):
        self.children.append(child)
        # âœ… ä½¿ç”¨å¼±å¼•ç”¨é¿å…å¾ªç¯å¼•ç”¨
        child.parent = weakref.ref(self)

class Child:
    def __init__(self):
        self.parent = None
```

### 5. å…¨å±€å˜é‡
```python
# âŒ é¿å… - å…¨å±€å˜é‡
global_cache = {}

# âœ… æ¨è - ç±»å±æ€§æˆ–å‡½æ•°å‚æ•°
class CacheManager:
    def __init__(self):
        self._cache = {}
    
    def get(self, key):
        return self._cache.get(key)
```

## ğŸ”§ å†…å­˜ç›‘æ§å·¥å…·

### 1. ä½¿ç”¨å†…å­˜åˆ†æå™¨
```python
from src.core.monitoring.memory_profiler import MemoryContext, memory_monitor

# ä¸Šä¸‹æ–‡ç®¡ç†å™¨
with MemoryContext("data_processing") as profiler:
    # æ‰§è¡Œå†…å­˜å¯†é›†å‹æ“ä½œ
    process_large_data()
    print(profiler.get_memory_report())

# è£…é¥°å™¨
@memory_monitor
def expensive_operation():
    # å†…å­˜å¯†é›†å‹æ“ä½œ
    pass
```

### 2. æ‰‹åŠ¨å†…å­˜æ£€æŸ¥
```python
import gc
import psutil

def check_memory():
    process = psutil.Process()
    memory_mb = process.memory_info().rss / 1024 / 1024
    print(f"å½“å‰å†…å­˜ä½¿ç”¨: {memory_mb:.2f} MB")
    
    # å¼ºåˆ¶åƒåœ¾å›æ”¶
    collected = gc.collect()
    print(f"å›æ”¶å¯¹è±¡æ•°: {collected}")
```

## ğŸš« å¸¸è§å†…å­˜é™·é˜±

### 1. æœªå…³é—­çš„èµ„æº
- æ–‡ä»¶å¥æŸ„
- æ•°æ®åº“è¿æ¥
- ç½‘ç»œè¿æ¥
- çº¿ç¨‹å’Œè¿›ç¨‹

### 2. å¤§å‹æ•°æ®ç»“æ„
- å·¨å¤§çš„åˆ—è¡¨æˆ–å­—å…¸
- æœªæ¸…ç†çš„ç¼“å­˜
- ç´¯ç§¯çš„æ—¥å¿—æ•°æ®

### 3. å¾ªç¯å¼•ç”¨
- çˆ¶å­å¯¹è±¡ç›¸äº’å¼•ç”¨
- å›è°ƒå‡½æ•°æŒæœ‰å¯¹è±¡å¼•ç”¨
- äº‹ä»¶ç›‘å¬å™¨æœªæ­£ç¡®ç§»é™¤

### 4. å†…å­˜æ³„æ¼æ¨¡å¼
```python
# âŒ æ³„æ¼æ¨¡å¼1: å…¨å±€åˆ—è¡¨ç´¯ç§¯
global_list = []
def add_data(data):
    global_list.append(data)  # æ°¸è¿œä¸æ¸…ç†

# âŒ æ³„æ¼æ¨¡å¼2: é—­åŒ…æŒæœ‰å¤§å¯¹è±¡
def create_handler(large_data):
    def handler():
        # å³ä½¿ä¸ä½¿ç”¨large_dataï¼Œé—­åŒ…ä¹Ÿä¼šæŒæœ‰å¼•ç”¨
        pass
    return handler

# âŒ æ³„æ¼æ¨¡å¼3: ç¼“å­˜æ— é™å¢é•¿
cache = {}
def get_data(key):
    if key not in cache:
        cache[key] = expensive_operation(key)  # ç¼“å­˜æ°¸è¿œä¸æ¸…ç†
    return cache[key]
```

## ğŸ¯ ä¼˜åŒ–ç­–ç•¥

### 1. åˆ†æ‰¹å¤„ç†
```python
def process_large_dataset(data):
    batch_size = 1000
    for i in range(0, len(data), batch_size):
        batch = data[i:i + batch_size]
        process_batch(batch)
        # æ‰¹å¤„ç†å®Œæˆåï¼Œbatchä¼šè¢«åƒåœ¾å›æ”¶
```

### 2. ä½¿ç”¨__slots__
```python
class OptimizedClass:
    __slots__ = ['x', 'y', 'z']  # å‡å°‘å†…å­˜ä½¿ç”¨
    
    def __init__(self, x, y, z):
        self.x = x
        self.y = y
        self.z = z
```

### 3. åŠæ—¶æ¸…ç†
```python
def process_data():
    large_data = load_large_dataset()
    result = process(large_data)
    
    # åŠæ—¶åˆ é™¤å¤§å¯¹è±¡
    del large_data
    gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
    
    return result
```

### 4. ä½¿ç”¨ç”Ÿæˆå™¨é“¾
```python
def data_pipeline(filename):
    return (
        transform(line)
        for line in read_file(filename)
        if filter_condition(line)
    )
```

## ğŸ“Š å†…å­˜ç›‘æ§

### 1. å®šæœŸæ£€æŸ¥
- ç›‘æ§å†…å­˜ä½¿ç”¨è¶‹åŠ¿
- è®¾ç½®å†…å­˜ä½¿ç”¨é˜ˆå€¼
- è‡ªåŠ¨è§¦å‘åƒåœ¾å›æ”¶

### 2. æ€§èƒ½æµ‹è¯•
- å‹åŠ›æµ‹è¯•å†…å­˜ä½¿ç”¨
- é•¿æ—¶é—´è¿è¡Œæµ‹è¯•
- å†…å­˜æ³„æ¼æ£€æµ‹

### 3. ç”Ÿäº§ç¯å¢ƒç›‘æ§
- å®æ—¶å†…å­˜ç›‘æ§
- å†…å­˜ä½¿ç”¨å‘Šè­¦
- è‡ªåŠ¨é‡å¯æœºåˆ¶
"""

        with open(guide_path, "w", encoding="utf-8") as f:
            f.write(guide_content)

        return str(guide_path)

    def generate_report(self) -> str:
        """ç”Ÿæˆå†…å­˜ä¼˜åŒ–æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆå†…å­˜ä¼˜åŒ–æŠ¥å‘Š...")

        report = f"""# å†…å­˜ç®¡ç†ä¼˜åŒ–æŠ¥å‘Š

## ğŸ“Š æ‰«æç»“æœæ¦‚è§ˆ

- **æ‰«ææ–‡ä»¶æ•°é‡**: {len(self._get_python_files())}
- **å‘ç°å†…å­˜é—®é¢˜**: {len(self.issues_found)}
- **é—®é¢˜ç±»å‹åˆ†å¸ƒ**:
"""

        # ç»Ÿè®¡é—®é¢˜ç±»å‹
        issue_types = {}
        severity_count = {}

        for issue in self.issues_found:
            issue_types[issue.issue_type] = issue_types.get(issue.issue_type, 0) + 1
            severity_count[issue.severity] = severity_count.get(issue.severity, 0) + 1

        for issue_type, count in issue_types.items():
            report += f"  - {issue_type}: {count}\n"

        report += "\n- **ä¸¥é‡æ€§åˆ†å¸ƒ**:\n"
        for severity, count in severity_count.items():
            report += f"  - {severity}: {count}\n"

        report += "\n## ğŸ” å‘ç°çš„å†…å­˜é—®é¢˜è¯¦æƒ…\n\n"

        # æŒ‰ä¸¥é‡æ€§åˆ†ç»„
        by_severity = {}
        for issue in self.issues_found:
            if issue.severity not in by_severity:
                by_severity[issue.severity] = []
            by_severity[issue.severity].append(issue)

        for severity in ["HIGH", "MEDIUM", "LOW"]:
            if severity in by_severity:
                report += f"### {severity} ä¸¥é‡æ€§\n\n"
                for issue in by_severity[severity]:
                    report += f"**æ–‡ä»¶**: `{issue.file_path}:{issue.line_number}`\n"
                    report += f"**ç±»å‹**: {issue.issue_type}\n"
                    report += f"**æè¿°**: {issue.description}\n"
                    report += f"**ä»£ç **: `{issue.code_snippet}`\n"
                    report += f"**ä¿®å¤å»ºè®®**: {issue.suggested_fix}\n\n"

        report += """
## ğŸ› ï¸ ä¿®å¤æ­¥éª¤

### 1. ç«‹å³ä¿®å¤ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
1. ä¿®å¤æ‰€æœ‰æœªæ­£ç¡®å…³é—­çš„æ–‡ä»¶æ“ä½œ
2. è§£å†³å¾ªç¯å¼•ç”¨é—®é¢˜
3. ä¼˜åŒ–å¤§å‹æ•°æ®ç»“æ„çš„ä½¿ç”¨

### 2. ä¸­æœŸä¼˜åŒ–
1. æ›¿æ¢å¤§å‹åˆ—è¡¨æ¨å¯¼å¼ä¸ºç”Ÿæˆå™¨
2. å‡å°‘å…¨å±€å˜é‡çš„ä½¿ç”¨
3. å®æ–½å†…å­˜ç›‘æ§

### 3. é•¿æœŸæ”¹è¿›
1. å»ºç«‹å†…å­˜ä½¿ç”¨è§„èŒƒ
2. å®šæœŸè¿›è¡Œå†…å­˜åˆ†æ
3. ä¼˜åŒ–ç®—æ³•å’Œæ•°æ®ç»“æ„

## ğŸ“‹ å†…å­˜ä¼˜åŒ–æŒ‡å—

è¯·å‚è€ƒ `docs/development/memory_optimization_guide.md` äº†è§£è¯¦ç»†çš„å†…å­˜ä¼˜åŒ–æŒ‡å—ã€‚

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ–‡ä»¶å¥æŸ„æ³„æ¼**ä¼šå¯¼è‡´ç³»ç»Ÿèµ„æºè€—å°½
2. **å¾ªç¯å¼•ç”¨**ä¼šé˜»æ­¢åƒåœ¾å›æ”¶
3. **å¤§å‹æ•°æ®ç»“æ„**ä¼šå¿«é€Ÿæ¶ˆè€—å†…å­˜
4. **å…¨å±€å˜é‡**ä¼šæŒç»­å ç”¨å†…å­˜ç›´åˆ°ç¨‹åºç»“æŸ
"""

        return report


def main():
    """ä¸»å‡½æ•°"""
    project_root = os.getcwd()
    print("ğŸ§  ç´¢å…‹ç”Ÿæ´»é¡¹ç›® - å†…å­˜ç®¡ç†ä¼˜åŒ–å·¥å…·")
    print("=" * 60)

    optimizer = MemoryOptimizer(project_root)

    # 1. æ‰«æå†…å­˜é—®é¢˜
    issues = optimizer.scan_memory_issues()

    # 2. åˆ›å»ºå†…å­˜åˆ†æå™¨
    profiler_file = optimizer.create_memory_profiler()
    print(f"âœ… å·²åˆ›å»ºå†…å­˜åˆ†æå™¨: {profiler_file}")

    # 3. åˆ›å»ºå†…å­˜ä¼˜åŒ–æŒ‡å—
    guide_file = optimizer.create_memory_optimization_guide()
    print(f"âœ… å·²åˆ›å»ºå†…å­˜ä¼˜åŒ–æŒ‡å—: {guide_file}")

    # 4. ç”ŸæˆæŠ¥å‘Š
    report = optimizer.generate_report()

    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(project_root) / "memory_optimization_report.md"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"ğŸ“Š ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    if issues:
        print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªå†…å­˜é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Šè¯¦æƒ…")
    else:
        print("\nâœ… æœªå‘ç°å†…å­˜é—®é¢˜")


if __name__ == "__main__":
    main()
