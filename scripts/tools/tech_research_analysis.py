#!/usr/bin/env python3
"""
æŠ€æœ¯è°ƒç ”åˆ†æè„šæœ¬
æ·±å…¥ç ”ç©¶æ¨èçš„æ ¸å¿ƒé¡¹ç›®ï¼Œåˆ†æå…¶æ¶æ„æ¨¡å¼å’Œæœ€ä½³å®è·µ
"""

import requests
import json
import os
from typing import Dict, List, Any
import time

class TechResearchAnalyzer:
    def __init__(self, token: str = None):
        self.token = token
        self.base_url = "https://api.github.com"
        self.headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "SuokeLife-TechResearch"
        }
        if token:
            self.headers["Authorization"] = f"token {token}"

    def get_repository_details(self, owner: str, repo: str) -> Dict:
        """è·å–ä»“åº“è¯¦ç»†ä¿¡æ¯"""
        url = f"{self.base_url}/repos/{owner}/{repo}"
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"è·å–ä»“åº“è¯¦æƒ…å¤±è´¥: {e}")
            return {}

    def get_repository_structure(self, owner: str, repo: str, path: str = "") -> List[Dict]:
        """è·å–ä»“åº“ç›®å½•ç»“æ„"""
        url = f"{self.base_url}/repos/{owner}/{repo}/contents/{path}"
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            return response.json()
        except requests.RequestException as e:
            print(f"è·å–ç›®å½•ç»“æ„å¤±è´¥: {e}")
            return []

    def get_file_content(self, owner: str, repo: str, path: str) -> str:
        """è·å–æ–‡ä»¶å†…å®¹"""
        url = f"{self.base_url}/repos/{owner}/{repo}/contents/{path}"
        try:
            response = requests.get(url, headers=self.headers)
            response.raise_for_status()
            content = response.json()
            if content.get('encoding') == 'base64':
                import base64
                return base64.b64decode(content['content']).decode('utf-8')
            return content.get('content', '')
        except requests.RequestException as e:
            print(f"è·å–æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            return ""

    def analyze_project_architecture(self, owner: str, repo: str) -> Dict:
        """åˆ†æé¡¹ç›®æ¶æ„"""
        print(f"\nğŸ” åˆ†æé¡¹ç›®: {owner}/{repo}")
        print("=" * 50)

        # è·å–åŸºæœ¬ä¿¡æ¯
        repo_info = self.get_repository_details(owner, repo)
        if not repo_info:
            return {}

        analysis = {
            "name": f"{owner}/{repo}",
            "description": repo_info.get("description", ""),
            "language": repo_info.get("language", ""),
            "stars": repo_info.get("stargazers_count", 0),
            "forks": repo_info.get("forks_count", 0),
            "size": repo_info.get("size", 0),
            "topics": repo_info.get("topics", []),
            "architecture_patterns": [],
            "tech_stack": [],
            "best_practices": [],
            "directory_structure": {},
            "key_files": {}
        }

        # è·å–ç›®å½•ç»“æ„
        root_contents = self.get_repository_structure(owner, repo)
        analysis["directory_structure"] = self._analyze_directory_structure(root_contents)

        # åˆ†æå…³é”®æ–‡ä»¶
        key_files = ["README.md", "package.json", "go.mod", "requirements.txt",
                    "Dockerfile", "docker-compose.yml", "Makefile", "pyproject.toml"]

        for file_name in key_files:
            for item in root_contents:
                if item.get("name") == file_name:
                    content = self.get_file_content(owner, repo, file_name)
                    analysis["key_files"][file_name] = self._analyze_file_content(file_name, content)
                    break

        # åˆ†ææ¶æ„æ¨¡å¼
        analysis["architecture_patterns"] = self._identify_architecture_patterns(analysis)
        analysis["tech_stack"] = self._identify_tech_stack(analysis)
        analysis["best_practices"] = self._identify_best_practices(analysis)

        return analysis

    def _analyze_directory_structure(self, contents: List[Dict]) -> Dict:
        """åˆ†æç›®å½•ç»“æ„"""
        structure = {
            "directories": [],
            "files": [],
            "patterns": []
        }

        for item in contents:
            if item.get("type") == "dir":
                structure["directories"].append(item.get("name"))
            else:
                structure["files"].append(item.get("name"))

        # è¯†åˆ«å¸¸è§æ¨¡å¼
        dirs = structure["directories"]
        if "cmd" in dirs and "internal" in dirs:
            structure["patterns"].append("Go Standard Project Layout")
        if "src" in dirs and "tests" in dirs:
            structure["patterns"].append("Source/Test Separation")
        if "docker" in dirs or "k8s" in dirs:
            structure["patterns"].append("Container/Kubernetes Ready")
        if "docs" in dirs:
            structure["patterns"].append("Documentation Included")
        if "examples" in dirs:
            structure["patterns"].append("Example Code Provided")

        return structure

    def _analyze_file_content(self, filename: str, content: str) -> Dict:
        """åˆ†ææ–‡ä»¶å†…å®¹"""
        analysis = {"type": filename, "insights": []}

        if filename == "package.json" and content:
            try:
                package_data = json.loads(content)
                analysis["insights"].append(f"Node.jsé¡¹ç›®ï¼Œä¾èµ–æ•°é‡: {len(package_data.get('dependencies', {}))}")
                if "react-native" in package_data.get("dependencies", {}):
                    analysis["insights"].append("React Nativeç§»åŠ¨åº”ç”¨")
                if "@reduxjs/toolkit" in package_data.get("dependencies", {}):
                    analysis["insights"].append("ä½¿ç”¨Redux ToolkitçŠ¶æ€ç®¡ç†")
                if "typescript" in package_data.get("devDependencies", {}):
                    analysis["insights"].append("TypeScriptæ”¯æŒ")
            except:
                pass

        elif filename == "go.mod" and content:
            analysis["insights"].append("Goé¡¹ç›®")
            if "gin" in content.lower():
                analysis["insights"].append("ä½¿ç”¨Gin Webæ¡†æ¶")
            if "grpc" in content.lower():
                analysis["insights"].append("æ”¯æŒgRPC")
            if "kubernetes" in content.lower():
                analysis["insights"].append("Kubernetesé›†æˆ")

        elif filename == "requirements.txt" or filename == "pyproject.toml":
            analysis["insights"].append("Pythoné¡¹ç›®")
            if "fastapi" in content.lower():
                analysis["insights"].append("ä½¿ç”¨FastAPIæ¡†æ¶")
            if "django" in content.lower():
                analysis["insights"].append("ä½¿ç”¨Djangoæ¡†æ¶")
            if "langchain" in content.lower():
                analysis["insights"].append("é›†æˆLangChain")

        elif filename == "Dockerfile" and content:
            analysis["insights"].append("å®¹å™¨åŒ–æ”¯æŒ")
            if "multi-stage" in content.lower() or "FROM" in content and content.count("FROM") > 1:
                analysis["insights"].append("å¤šé˜¶æ®µæ„å»º")

        return analysis

    def _identify_architecture_patterns(self, analysis: Dict) -> List[str]:
        """è¯†åˆ«æ¶æ„æ¨¡å¼"""
        patterns = []

        dirs = analysis["directory_structure"]["directories"]

        # å¾®æœåŠ¡æ¨¡å¼
        if any(d in dirs for d in ["services", "microservices", "cmd"]):
            patterns.append("Microservices Architecture")

        # æ¸…æ´æ¶æ„
        if any(d in dirs for d in ["internal", "pkg", "domain", "application"]):
            patterns.append("Clean Architecture")

        # DDDæ¨¡å¼
        if any(d in dirs for d in ["domain", "aggregate", "entity"]):
            patterns.append("Domain Driven Design")

        # APIä¼˜å…ˆ
        if any(d in dirs for d in ["api", "swagger", "openapi"]):
            patterns.append("API-First Design")

        # äº‹ä»¶é©±åŠ¨
        if any(d in dirs for d in ["events", "messaging", "queue"]):
            patterns.append("Event-Driven Architecture")

        return patterns

    def _identify_tech_stack(self, analysis: Dict) -> List[str]:
        """è¯†åˆ«æŠ€æœ¯æ ˆ"""
        tech_stack = []

        # ä»è¯­è¨€å’Œæ–‡ä»¶æ¨æ–­
        if analysis["language"] == "Go":
            tech_stack.append("Go")
        if analysis["language"] == "Python":
            tech_stack.append("Python")
        if analysis["language"] == "TypeScript":
            tech_stack.append("TypeScript")
        if analysis["language"] == "JavaScript":
            tech_stack.append("JavaScript")

        # ä»å…³é”®æ–‡ä»¶æ¨æ–­
        if "package.json" in analysis["key_files"]:
            tech_stack.append("Node.js")
        if "go.mod" in analysis["key_files"]:
            tech_stack.append("Go Modules")
        if "requirements.txt" in analysis["key_files"] or "pyproject.toml" in analysis["key_files"]:
            tech_stack.append("Python")
        if "Dockerfile" in analysis["key_files"]:
            tech_stack.append("Docker")

        return list(set(tech_stack))

    def _identify_best_practices(self, analysis: Dict) -> List[str]:
        """è¯†åˆ«æœ€ä½³å®è·µ"""
        practices = []

        dirs = analysis["directory_structure"]["directories"]
        files = analysis["directory_structure"]["files"]

        # æ–‡æ¡£å®è·µ
        if "README.md" in files:
            practices.append("Comprehensive Documentation")
        if "docs" in dirs:
            practices.append("Dedicated Documentation Directory")

        # æµ‹è¯•å®è·µ
        if any(d in dirs for d in ["test", "tests", "__tests__"]):
            practices.append("Test Coverage")

        # CI/CDå®è·µ
        if ".github" in dirs:
            practices.append("GitHub Actions CI/CD")

        # å®¹å™¨åŒ–å®è·µ
        if "Dockerfile" in files:
            practices.append("Containerization")
        if "docker-compose.yml" in files:
            practices.append("Multi-Container Orchestration")

        # é…ç½®ç®¡ç†
        if any(f in files for f in ["config.yml", "config.json", ".env.example"]):
            practices.append("Configuration Management")

        # ä»£ç è´¨é‡
        if any(f in files for f in [".eslintrc", ".pylintrc", "golangci.yml"]):
            practices.append("Code Quality Tools")

        return practices

def main():
    """ä¸»å‡½æ•°ï¼šåˆ†ææ¨èçš„æ ¸å¿ƒé¡¹ç›®"""

    # æ ¸å¿ƒæ¨èé¡¹ç›®åˆ—è¡¨
    core_projects = [
        # å¾®æœåŠ¡æ¶æ„
        ("Mikaelemmmm", "go-zero-looklook"),
        ("aeraki-mesh", "aeraki"),
        ("vardius", "go-api-boilerplate"),

        # React Native
        ("thecodingmachine", "react-native-boilerplate"),
        ("software-mansion", "react-native-screens"),
        ("infinitered", "ignite"),

        # AI/MLå¤šæ™ºèƒ½ä½“
        ("MervinPraison", "PraisonAI"),
        ("BerriAI", "litellm"),
        ("microsoft", "autogen"),

        # æ¶æ„æ¨¡å¼
        ("mehdihadeli", "awesome-software-architecture"),
        ("DovAmir", "awesome-design-patterns"),
    ]

    analyzer = TechResearchAnalyzer()
    all_analyses = []

    print("ğŸš€ å¼€å§‹æ·±å…¥æŠ€æœ¯è°ƒç ”...")
    print("åˆ†ææ¨èçš„æ ¸å¿ƒé¡¹ç›®æ¶æ„æ¨¡å¼å’Œæœ€ä½³å®è·µ")
    print("=" * 60)

    for owner, repo in core_projects:
        try:
            analysis = analyzer.analyze_project_architecture(owner, repo)
            if analysis:
                all_analyses.append(analysis)

                # æ˜¾ç¤ºå…³é”®ä¿¡æ¯
                print(f"ğŸ“Š {analysis['name']}")
                print(f"   æè¿°: {analysis['description'][:100]}...")
                print(f"   è¯­è¨€: {analysis['language']}, â­{analysis['stars']}")
                print(f"   æ¶æ„æ¨¡å¼: {', '.join(analysis['architecture_patterns'])}")
                print(f"   æŠ€æœ¯æ ˆ: {', '.join(analysis['tech_stack'])}")
                print(f"   æœ€ä½³å®è·µ: {', '.join(analysis['best_practices'][:3])}...")
                print()

            # é¿å…APIé™åˆ¶
            time.sleep(2)

        except Exception as e:
            print(f"âŒ åˆ†æ {owner}/{repo} å¤±è´¥: {e}")
            continue

    # ä¿å­˜è¯¦ç»†åˆ†æç»“æœ
    output_file = "tech_research_analysis.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_analyses, f, ensure_ascii=False, indent=2)

    print(f"âœ… æŠ€æœ¯è°ƒç ”å®Œæˆï¼è¯¦ç»†åˆ†æå·²ä¿å­˜åˆ°: {output_file}")

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    generate_summary_report(all_analyses)

def generate_summary_report(analyses: List[Dict]):
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    print("\n" + "="*60)
    print("ğŸ“‹ æŠ€æœ¯è°ƒç ”æ€»ç»“æŠ¥å‘Š")
    print("="*60)

    # ç»Ÿè®¡æ¶æ„æ¨¡å¼
    all_patterns = []
    for analysis in analyses:
        all_patterns.extend(analysis.get("architecture_patterns", []))

    pattern_counts = {}
    for pattern in all_patterns:
        pattern_counts[pattern] = pattern_counts.get(pattern, 0) + 1

    print("\nğŸ—ï¸ æœ€å¸¸è§çš„æ¶æ„æ¨¡å¼:")
    for pattern, count in sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"  {pattern}: {count}ä¸ªé¡¹ç›®")

    # ç»Ÿè®¡æŠ€æœ¯æ ˆ
    all_tech = []
    for analysis in analyses:
        all_tech.extend(analysis.get("tech_stack", []))

    tech_counts = {}
    for tech in all_tech:
        tech_counts[tech] = tech_counts.get(tech, 0) + 1

    print("\nğŸ’» æœ€å¸¸ç”¨çš„æŠ€æœ¯æ ˆ:")
    for tech, count in sorted(tech_counts.items(), key=lambda x: x[1], reverse=True):
        print(f"  {tech}: {count}ä¸ªé¡¹ç›®")

    # ç»Ÿè®¡æœ€ä½³å®è·µ
    all_practices = []
    for analysis in analyses:
        all_practices.extend(analysis.get("best_practices", []))

    practice_counts = {}
    for practice in all_practices:
        practice_counts[practice] = practice_counts.get(practice, 0) + 1

    print("\nâœ¨ æœ€å¸¸è§çš„æœ€ä½³å®è·µ:")
    for practice, count in sorted(practice_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
        print(f"  {practice}: {count}ä¸ªé¡¹ç›®")

if __name__ == "__main__":
    main()