#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç´¢å…‹ç”Ÿæ´» - æ•°æ®åº“ç®¡ç†è„šæœ¬
Database Management Script for Suoke Life
"""

import asyncio
import logging
import os
import sys
from pathlib import Path
from typing import List, Dict, Any
import subprocess
import json
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent.parent))

from config.database import get_database_config, ServiceDatabaseMapping
import asyncpg
import aiofiles

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self):
        self.config = get_database_config()
        self.service_mapping = ServiceDatabaseMapping()
        
    async def create_databases(self):
        """åˆ›å»ºæ‰€æœ‰æ•°æ®åº“"""
        logger.info("ğŸ—„ï¸ å¼€å§‹åˆ›å»ºæ•°æ®åº“...")
        
        try:
            # è¿æ¥åˆ°PostgreSQLæœåŠ¡å™¨
            conn = await asyncpg.connect(
                host=self.config.primary_host,
                port=self.config.primary_port,
                user=self.config.primary_user,
                password=self.config.primary_password,
                database='postgres'  # è¿æ¥åˆ°é»˜è®¤æ•°æ®åº“
            )
            
            # è·å–æ‰€æœ‰éœ€è¦åˆ›å»ºçš„æ•°æ®åº“
            databases = self.service_mapping.get_all_databases()
            databases.append(self.config.primary_database)  # æ·»åŠ ä¸»æ•°æ®åº“
            
            for database in databases:
                try:
                    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
                    exists = await conn.fetchval(
                        "SELECT 1 FROM pg_database WHERE datname = $1", database
                    )
                    
                    if not exists:
                        # åˆ›å»ºæ•°æ®åº“
                        await conn.execute(f'CREATE DATABASE "{database}"')
                        logger.info(f"âœ… åˆ›å»ºæ•°æ®åº“: {database}")
                    else:
                        logger.info(f"ğŸ“‹ æ•°æ®åº“å·²å­˜åœ¨: {database}")
                        
                except Exception as e:
                    logger.error(f"âŒ åˆ›å»ºæ•°æ®åº“å¤±è´¥ {database}: {e}")
                    
            await conn.close()
            logger.info("ğŸ‰ æ•°æ®åº“åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    async def run_migrations(self):
        """è¿è¡Œæ•°æ®åº“è¿ç§»"""
        logger.info("ğŸ”„ å¼€å§‹è¿è¡Œæ•°æ®åº“è¿ç§»...")
        
        try:
            # è¿è¡ŒAlembicè¿ç§»
            result = subprocess.run(
                ["alembic", "upgrade", "head"],
                capture_output=True,
                text=True,
                cwd=Path(__file__).parent.parent.parent
            )
            
            if result.returncode == 0:
                logger.info("âœ… æ•°æ®åº“è¿ç§»æˆåŠŸ")
                logger.info(result.stdout)
            else:
                logger.error("âŒ æ•°æ®åº“è¿ç§»å¤±è´¥")
                logger.error(result.stderr)
                raise Exception(f"Migration failed: {result.stderr}")
                
        except Exception as e:
            logger.error(f"âŒ è¿è¡Œè¿ç§»å¤±è´¥: {e}")
            raise
    
    async def backup_database(self, database_name: str, backup_path: str = None):
        """å¤‡ä»½æ•°æ®åº“"""
        if not backup_path:
            backup_path = f"backups/{database_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"
        
        logger.info(f"ğŸ’¾ å¼€å§‹å¤‡ä»½æ•°æ®åº“: {database_name}")
        
        try:
            # ç¡®ä¿å¤‡ä»½ç›®å½•å­˜åœ¨
            Path(backup_path).parent.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨pg_dumpå¤‡ä»½
            cmd = [
                "pg_dump",
                f"--host={self.config.primary_host}",
                f"--port={self.config.primary_port}",
                f"--username={self.config.primary_user}",
                f"--dbname={database_name}",
                f"--file={backup_path}",
                "--verbose",
                "--no-password"
            ]
            
            env = os.environ.copy()
            env['PGPASSWORD'] = self.config.primary_password
            
            result = subprocess.run(cmd, capture_output=True, text=True, env=env)
            
            if result.returncode == 0:
                logger.info(f"âœ… æ•°æ®åº“å¤‡ä»½æˆåŠŸ: {backup_path}")
                return backup_path
            else:
                logger.error(f"âŒ æ•°æ®åº“å¤‡ä»½å¤±è´¥: {result.stderr}")
                raise Exception(f"Backup failed: {result.stderr}")
                
        except Exception as e:
            logger.error(f"âŒ å¤‡ä»½æ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    async def restore_database(self, database_name: str, backup_path: str):
        """æ¢å¤æ•°æ®åº“"""
        logger.info(f"ğŸ”„ å¼€å§‹æ¢å¤æ•°æ®åº“: {database_name}")
        
        try:
            # ä½¿ç”¨psqlæ¢å¤
            cmd = [
                "psql",
                f"--host={self.config.primary_host}",
                f"--port={self.config.primary_port}",
                f"--username={self.config.primary_user}",
                f"--dbname={database_name}",
                f"--file={backup_path}",
                "--quiet"
            ]
            
            env = os.environ.copy()
            env['PGPASSWORD'] = self.config.primary_password
            
            result = subprocess.run(cmd, capture_output=True, text=True, env=env)
            
            if result.returncode == 0:
                logger.info(f"âœ… æ•°æ®åº“æ¢å¤æˆåŠŸ: {database_name}")
            else:
                logger.error(f"âŒ æ•°æ®åº“æ¢å¤å¤±è´¥: {result.stderr}")
                raise Exception(f"Restore failed: {result.stderr}")
                
        except Exception as e:
            logger.error(f"âŒ æ¢å¤æ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    async def check_database_health(self):
        """æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€"""
        logger.info("ğŸ” æ£€æŸ¥æ•°æ®åº“å¥åº·çŠ¶æ€...")
        
        health_report = {
            "timestamp": datetime.now().isoformat(),
            "databases": {},
            "overall_status": "healthy"
        }
        
        databases = self.service_mapping.get_all_databases()
        databases.append(self.config.primary_database)
        
        for database in databases:
            try:
                conn = await asyncpg.connect(
                    host=self.config.primary_host,
                    port=self.config.primary_port,
                    user=self.config.primary_user,
                    password=self.config.primary_password,
                    database=database
                )
                
                # æ£€æŸ¥è¿æ¥
                await conn.fetchval("SELECT 1")
                
                # è·å–æ•°æ®åº“å¤§å°
                size = await conn.fetchval(
                    "SELECT pg_size_pretty(pg_database_size($1))", database
                )
                
                # è·å–è¿æ¥æ•°
                connections = await conn.fetchval(
                    "SELECT count(*) FROM pg_stat_activity WHERE datname = $1", database
                )
                
                health_report["databases"][database] = {
                    "status": "healthy",
                    "size": size,
                    "connections": connections
                }
                
                await conn.close()
                logger.info(f"âœ… æ•°æ®åº“å¥åº·: {database}")
                
            except Exception as e:
                health_report["databases"][database] = {
                    "status": "unhealthy",
                    "error": str(e)
                }
                health_report["overall_status"] = "unhealthy"
                logger.error(f"âŒ æ•°æ®åº“ä¸å¥åº·: {database} - {e}")
        
        return health_report
    
    async def optimize_databases(self):
        """ä¼˜åŒ–æ•°æ®åº“"""
        logger.info("âš¡ å¼€å§‹ä¼˜åŒ–æ•°æ®åº“...")
        
        databases = self.service_mapping.get_all_databases()
        databases.append(self.config.primary_database)
        
        for database in databases:
            try:
                conn = await asyncpg.connect(
                    host=self.config.primary_host,
                    port=self.config.primary_port,
                    user=self.config.primary_user,
                    password=self.config.primary_password,
                    database=database
                )
                
                # è¿è¡ŒVACUUM ANALYZE
                await conn.execute("VACUUM ANALYZE")
                
                # é‡å»ºç´¢å¼•
                await conn.execute("REINDEX DATABASE CONCURRENTLY")
                
                await conn.close()
                logger.info(f"âœ… æ•°æ®åº“ä¼˜åŒ–å®Œæˆ: {database}")
                
            except Exception as e:
                logger.error(f"âŒ æ•°æ®åº“ä¼˜åŒ–å¤±è´¥: {database} - {e}")
    
    async def generate_database_report(self):
        """ç”Ÿæˆæ•°æ®åº“æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆæ•°æ®åº“æŠ¥å‘Š...")
        
        report = {
            "timestamp": datetime.now().isoformat(),
            "config": {
                "host": self.config.primary_host,
                "port": self.config.primary_port,
                "databases_count": len(self.service_mapping.get_all_databases()) + 1
            },
            "health": await self.check_database_health(),
            "services": self.service_mapping.SERVICES
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = f"reports/database_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        Path(report_path).parent.mkdir(parents=True, exist_ok=True)
        
        async with aiofiles.open(report_path, 'w', encoding='utf-8') as f:
            await f.write(json.dumps(report, indent=2, ensure_ascii=False))
        
        logger.info(f"ğŸ“‹ æ•°æ®åº“æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return report

async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç´¢å…‹ç”Ÿæ´»æ•°æ®åº“ç®¡ç†å·¥å…·')
    parser.add_argument('action', choices=[
        'create', 'migrate', 'backup', 'restore', 'health', 'optimize', 'report'
    ], help='æ‰§è¡Œçš„æ“ä½œ')
    parser.add_argument('--database', help='æ•°æ®åº“åç§°')
    parser.add_argument('--backup-path', help='å¤‡ä»½æ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    manager = DatabaseManager()
    
    try:
        if args.action == 'create':
            await manager.create_databases()
        elif args.action == 'migrate':
            await manager.run_migrations()
        elif args.action == 'backup':
            if not args.database:
                logger.error("å¤‡ä»½æ“ä½œéœ€è¦æŒ‡å®šæ•°æ®åº“åç§°")
                return
            await manager.backup_database(args.database, args.backup_path)
        elif args.action == 'restore':
            if not args.database or not args.backup_path:
                logger.error("æ¢å¤æ“ä½œéœ€è¦æŒ‡å®šæ•°æ®åº“åç§°å’Œå¤‡ä»½æ–‡ä»¶è·¯å¾„")
                return
            await manager.restore_database(args.database, args.backup_path)
        elif args.action == 'health':
            health = await manager.check_database_health()
            print(json.dumps(health, indent=2, ensure_ascii=False))
        elif args.action == 'optimize':
            await manager.optimize_databases()
        elif args.action == 'report':
            await manager.generate_database_report()
            
    except Exception as e:
        logger.error(f"æ“ä½œå¤±è´¥: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main()) 