#!/bin/bash

# ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ™ºèƒ½æ¸…ç†è„šæœ¬
# åŸºäºé¡¹ç›®ç°æœ‰ä»£ç ç»“æ„åŠå…·ä½“å®ç°ï¼Œæ´å¯Ÿé¡¹ç›®å†—ä½™æ–‡ä»¶å¹¶æ¸…ç†

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# é…ç½®
PROJECT_ROOT="$(cd "$(dirname "${BASH_SOURCE[0]}")/.." && pwd)"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="./intelligent_cleanup_backup_${TIMESTAMP}"
DRY_RUN=false
AGGRESSIVE_MODE=false

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

log_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

log_error() {
    echo -e "${RED}âŒ $1${NC}"
}

log_header() {
    echo -e "${PURPLE}ğŸ¯ $1${NC}"
}

# æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
show_help() {
    cat << EOF
ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ™ºèƒ½æ¸…ç†è„šæœ¬

ç”¨æ³•: $0 [é€‰é¡¹]

é€‰é¡¹:
  -d, --dry-run        ä»…åˆ†æä¸æ‰§è¡Œåˆ é™¤æ“ä½œ
  -a, --aggressive     æ¿€è¿›æ¨¡å¼ï¼Œæ¸…ç†æ›´å¤šæ–‡ä»¶
  -h, --help          æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  $0                   # æ ‡å‡†æ¸…ç†æ¨¡å¼
  $0 -d               # ä»…åˆ†ææ¨¡å¼
  $0 -a               # æ¿€è¿›æ¸…ç†æ¨¡å¼
  $0 -d -a            # æ¿€è¿›åˆ†ææ¨¡å¼

EOF
}

# è§£æå‘½ä»¤è¡Œå‚æ•°
parse_args() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            -d|--dry-run)
                DRY_RUN=true
                shift
                ;;
            -a|--aggressive)
                AGGRESSIVE_MODE=true
                shift
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            *)
                log_error "æœªçŸ¥å‚æ•°: $1"
                show_help
                exit 1
                ;;
        esac
    done
}

# åˆ†æé¡¹ç›®ç»“æ„
analyze_project_structure() {
    log_header "åˆ†æé¡¹ç›®ç»“æ„..."
    
    # ç»Ÿè®¡é¡¹ç›®åŸºæœ¬ä¿¡æ¯
    local total_files=$(find . -type f | wc -l)
    local total_size=$(du -sh . | cut -f1)
    local code_files=$(find . -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" -o -name "*.py" | wc -l)
    
    log_info "é¡¹ç›®æ€»æ–‡ä»¶æ•°: ${total_files}"
    log_info "é¡¹ç›®æ€»å¤§å°: ${total_size}"
    log_info "ä»£ç æ–‡ä»¶æ•°: ${code_files}"
    
    # åˆ†æå¤§å‹ç›®å½•
    log_info "åˆ†æå¤§å‹ç›®å½•..."
    echo "ç›®å½•å¤§å°æ’è¡Œæ¦œ:"
    du -sh */ 2>/dev/null | sort -hr | head -10 | while read size dir; do
        echo "  ${size} ${dir}"
    done
}

# è¯†åˆ«å†—ä½™å¤‡ä»½ç›®å½•
identify_backup_directories() {
    log_header "è¯†åˆ«å†—ä½™å¤‡ä»½ç›®å½•..."
    
    local backup_dirs=(
        "backup"
        "backups" 
        "archive"
        "cleanup"
        ".backup"
        "*backup*"
        "*_backup_*"
        "cleanup_backup*"
        "intelligent_cleanup_backup*"
    )
    
    local total_backup_size=0
    local backup_count=0
    
    for pattern in "${backup_dirs[@]}"; do
        for dir in $pattern; do
            if [[ -d "$dir" ]]; then
                local size=$(du -sb "$dir" 2>/dev/null | cut -f1)
                local size_human=$(du -sh "$dir" 2>/dev/null | cut -f1)
                total_backup_size=$((total_backup_size + size))
                backup_count=$((backup_count + 1))
                
                log_warning "å‘ç°å¤‡ä»½ç›®å½•: ${dir} (${size_human})"
                
                if [[ "$DRY_RUN" == false ]]; then
                    echo "  -> å°†è¢«æ¸…ç†"
                else
                    echo "  -> [DRY RUN] å°†è¢«æ¸…ç†"
                fi
            fi
        done
    done
    
    if [[ $backup_count -gt 0 ]]; then
        local total_human=$(numfmt --to=iec $total_backup_size)
        log_info "æ€»å¤‡ä»½ç›®å½•: ${backup_count}ä¸ªï¼Œæ€»å¤§å°: ${total_human}"
    else
        log_success "æœªå‘ç°å¤‡ä»½ç›®å½•"
    fi
}

# è¯†åˆ«å†—ä½™æŠ¥å‘Šæ–‡ä»¶
identify_redundant_reports() {
    log_header "è¯†åˆ«å†—ä½™æŠ¥å‘Šæ–‡ä»¶..."
    
    local report_patterns=(
        "*REPORT*"
        "*_REPORT.*"
        "*COMPLETION*"
        "*OPTIMIZATION*"
        "*CLEANUP*"
        "*BADGE*"
        "*CELEBRATION*"
        "*SUMMARY*"
        "*ANALYSIS*"
        "*FIX_REPORT*"
        "*STATUS*"
        "*GUIDE*"
        "*HISTORY*"
        "*CHECKLIST*"
        "PROJECT_CLEANUP_*"
        "DEPLOYMENT.md"
        "OPTIMIZATION_GUIDE.md"
        "UI_COMPONENT_LIBRARY.md"
        "*performance_report*"
        "*gil_*.json"
        "*test_report*"
        "*analysis*.json"
        "*optimization*.json"
        "*memory-analysis*"
        "*deployment-checklist*"
    )
    
    local report_files=()
    local total_report_size=0
    
    for pattern in "${report_patterns[@]}"; do
        while IFS= read -r -d '' file; do
            if [[ -f "$file" ]]; then
                report_files+=("$file")
                local size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo 0)
                total_report_size=$((total_report_size + size))
            fi
        done < <(find . -maxdepth 1 -name "$pattern" -print0 2>/dev/null)
    done
    
    if [[ ${#report_files[@]} -gt 0 ]]; then
        local total_human=$(numfmt --to=iec $total_report_size)
        log_warning "å‘ç° ${#report_files[@]} ä¸ªæŠ¥å‘Šæ–‡ä»¶ï¼Œæ€»å¤§å°: ${total_human}"
        
        # æ˜¾ç¤ºå‰10ä¸ªæœ€å¤§çš„æŠ¥å‘Šæ–‡ä»¶
        printf '%s\n' "${report_files[@]}" | head -10 | while read file; do
            local size=$(du -sh "$file" 2>/dev/null | cut -f1)
            echo "  - ${file} (${size})"
        done
        
        if [[ ${#report_files[@]} -gt 10 ]]; then
            echo "  ... è¿˜æœ‰ $((${#report_files[@]} - 10)) ä¸ªæ–‡ä»¶"
        fi
    else
        log_success "æœªå‘ç°å†—ä½™æŠ¥å‘Šæ–‡ä»¶"
    fi
}

# è¯†åˆ«ä¸´æ—¶å’Œç¼“å­˜æ–‡ä»¶
identify_temp_cache_files() {
    log_header "è¯†åˆ«ä¸´æ—¶å’Œç¼“å­˜æ–‡ä»¶..."
    
    local temp_patterns=(
        "*.tmp"
        "*.temp"
        "*.cache"
        "*.log"
        "*.backup"
        "*.bak"
        "*.old"
        "*.orig"
        "*~"
        ".DS_Store"
        "Thumbs.db"
        "*.swp"
        "*.swo"
        "__pycache__"
        "*.pyc"
        "*.pyo"
        ".pytest_cache"
        ".jest-cache"
        "coverage"
        ".nyc_output"
        "node_modules/.cache"
        ".ruff_cache"
        "test-results"
        "test_output"
        "*.test.log"
        "npm-debug.log*"
        "yarn-debug.log*"
        "yarn-error.log*"
    )
    
    local temp_files=()
    local total_temp_size=0
    
    for pattern in "${temp_patterns[@]}"; do
        while IFS= read -r -d '' file; do
            temp_files+=("$file")
            if [[ -f "$file" ]]; then
                local size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo 0)
                total_temp_size=$((total_temp_size + size))
            elif [[ -d "$file" ]]; then
                local size=$(du -sb "$file" 2>/dev/null | cut -f1 || echo 0)
                total_temp_size=$((total_temp_size + size))
            fi
        done < <(find . -name "$pattern" -print0 2>/dev/null)
    done
    
    if [[ ${#temp_files[@]} -gt 0 ]]; then
        local total_human=$(numfmt --to=iec $total_temp_size)
        log_warning "å‘ç° ${#temp_files[@]} ä¸ªä¸´æ—¶/ç¼“å­˜æ–‡ä»¶ï¼Œæ€»å¤§å°: ${total_human}"
    else
        log_success "æœªå‘ç°ä¸´æ—¶/ç¼“å­˜æ–‡ä»¶"
    fi
}

# è¯†åˆ«é‡å¤é…ç½®æ–‡ä»¶
identify_duplicate_configs() {
    log_header "è¯†åˆ«é‡å¤é…ç½®æ–‡ä»¶..."
    
    local config_patterns=(
        "*.config.backup.*"
        "*.config.old.*"
        "jest.config.enhanced.js"
        "optimize.config.js"
        "requirements-optimized.txt"
        "requirements-minimal.txt"
        "requirements-core.txt"
        "docker-compose.optimized*.yml"
        "Dockerfile.optimized"
        "Dockerfile.backup"
        "Dockerfile.old"
        "package.json.backup"
        "tsconfig.json.backup"
    )
    
    local duplicate_configs=()
    
    for pattern in "${config_patterns[@]}"; do
        while IFS= read -r -d '' file; do
            if [[ -f "$file" ]]; then
                duplicate_configs+=("$file")
            fi
        done < <(find . -name "$pattern" -print0 2>/dev/null)
    done
    
    if [[ ${#duplicate_configs[@]} -gt 0 ]]; then
        log_warning "å‘ç° ${#duplicate_configs[@]} ä¸ªé‡å¤é…ç½®æ–‡ä»¶:"
        printf '%s\n' "${duplicate_configs[@]}" | while read file; do
            echo "  - ${file}"
        done
    else
        log_success "æœªå‘ç°é‡å¤é…ç½®æ–‡ä»¶"
    fi
}

# è¯†åˆ«æœªä½¿ç”¨çš„æµ‹è¯•æ–‡ä»¶
identify_unused_test_files() {
    log_header "è¯†åˆ«å¯èƒ½æœªä½¿ç”¨çš„æµ‹è¯•æ–‡ä»¶..."
    
    local test_patterns=(
        "test-*.js"
        "simple-test.js"
        "temp_*.test.*"
        "*test*.backup"
        "test_*.sh"
        "fix_*.sh"
        "cleanup_*.sh"
        "migrate_*.sh"
    )
    
    local unused_tests=()
    
    for pattern in "${test_patterns[@]}"; do
        while IFS= read -r -d '' file; do
            if [[ -f "$file" ]]; then
                unused_tests+=("$file")
            fi
        done < <(find . -name "$pattern" -print0 2>/dev/null)
    done
    
    if [[ ${#unused_tests[@]} -gt 0 ]]; then
        log_warning "å‘ç° ${#unused_tests[@]} ä¸ªå¯èƒ½æœªä½¿ç”¨çš„æµ‹è¯•æ–‡ä»¶:"
        printf '%s\n' "${unused_tests[@]}" | while read file; do
            echo "  - ${file}"
        done
    else
        log_success "æœªå‘ç°æœªä½¿ç”¨çš„æµ‹è¯•æ–‡ä»¶"
    fi
}

# æ‰§è¡Œæ¸…ç†æ“ä½œ
execute_cleanup() {
    if [[ "$DRY_RUN" == true ]]; then
        log_header "åˆ†æå®Œæˆ (DRY RUN æ¨¡å¼)"
        log_info "å¦‚éœ€æ‰§è¡Œæ¸…ç†ï¼Œè¯·è¿è¡Œ: $0"
        return 0
    fi
    
    log_header "å¼€å§‹æ‰§è¡Œæ¸…ç†æ“ä½œ..."
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    mkdir -p "$BACKUP_DIR"
    log_info "åˆ›å»ºå¤‡ä»½ç›®å½•: $BACKUP_DIR"
    
    local cleaned_files=0
    local saved_space=0
    
    # 1. æ¸…ç†å¤‡ä»½ç›®å½•
    log_info "æ¸…ç†å¤‡ä»½ç›®å½•..."
    for dir in backup backups archive cleanup .backup cleanup_backup* intelligent_cleanup_backup*; do
        if [[ -d "$dir" && "$dir" != "$BACKUP_DIR" ]]; then
            local size=$(du -sb "$dir" 2>/dev/null | cut -f1 || echo 0)
            mv "$dir" "$BACKUP_DIR/" 2>/dev/null || true
            saved_space=$((saved_space + size))
            cleaned_files=$((cleaned_files + 1))
            log_success "å·²æ¸…ç†å¤‡ä»½ç›®å½•: $dir"
        fi
    done
    
    # 2. æ¸…ç†æŠ¥å‘Šæ–‡ä»¶
    log_info "æ¸…ç†æŠ¥å‘Šæ–‡ä»¶..."
    mkdir -p "$BACKUP_DIR/reports"
    
    local report_patterns=(
        "*REPORT*" "*_REPORT.*" "*COMPLETION*" "*OPTIMIZATION*" "*CLEANUP*"
        "*BADGE*" "*CELEBRATION*" "*SUMMARY*" "*ANALYSIS*" "*FIX_REPORT*"
        "*STATUS*" "*GUIDE*" "*HISTORY*" "*CHECKLIST*" "PROJECT_CLEANUP_*"
        "*performance_report*" "*gil_*.json" "*test_report*" "*analysis*.json"
        "*optimization*.json" "*memory-analysis*" "*deployment-checklist*"
    )
    
    for pattern in "${report_patterns[@]}"; do
        for file in $pattern; do
            if [[ -f "$file" ]]; then
                local size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo 0)
                mv "$file" "$BACKUP_DIR/reports/" 2>/dev/null || true
                saved_space=$((saved_space + size))
                cleaned_files=$((cleaned_files + 1))
            fi
        done
    done
    
    # 3. æ¸…ç†ä¸´æ—¶å’Œç¼“å­˜æ–‡ä»¶
    log_info "æ¸…ç†ä¸´æ—¶å’Œç¼“å­˜æ–‡ä»¶..."
    
    # Pythonç¼“å­˜
    find . -name "__pycache__" -type d -exec rm -rf {} + 2>/dev/null || true
    find . -name "*.pyc" -type f -delete 2>/dev/null || true
    find . -name "*.pyo" -type f -delete 2>/dev/null || true
    
    # Jestç¼“å­˜
    rm -rf .jest-cache/ coverage/ .nyc_output/ 2>/dev/null || true
    
    # ç³»ç»Ÿæ–‡ä»¶
    find . -name ".DS_Store" -type f -delete 2>/dev/null || true
    find . -name "Thumbs.db" -type f -delete 2>/dev/null || true
    find . -name "*.swp" -type f -delete 2>/dev/null || true
    find . -name "*.swo" -type f -delete 2>/dev/null || true
    find . -name "*~" -type f -delete 2>/dev/null || true
    
    # æ—¥å¿—æ–‡ä»¶ï¼ˆä¿ç•™æœ€è¿‘7å¤©ï¼‰
    find . -name "*.log" -type f -mtime +7 -delete 2>/dev/null || true
    
    # 4. æ¸…ç†é‡å¤é…ç½®æ–‡ä»¶
    log_info "æ¸…ç†é‡å¤é…ç½®æ–‡ä»¶..."
    mkdir -p "$BACKUP_DIR/configs"
    
    local config_patterns=(
        "*.config.backup.*" "*.config.old.*" "jest.config.enhanced.js"
        "optimize.config.js" "requirements-optimized.txt" "requirements-minimal.txt"
        "requirements-core.txt" "docker-compose.optimized*.yml" "Dockerfile.optimized"
        "Dockerfile.backup" "Dockerfile.old"
    )
    
    for pattern in "${config_patterns[@]}"; do
        for file in $pattern; do
            if [[ -f "$file" ]]; then
                local size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo 0)
                mv "$file" "$BACKUP_DIR/configs/" 2>/dev/null || true
                saved_space=$((saved_space + size))
                cleaned_files=$((cleaned_files + 1))
            fi
        done
    done
    
    # 5. æ¸…ç†ä¸´æ—¶æµ‹è¯•æ–‡ä»¶
    log_info "æ¸…ç†ä¸´æ—¶æµ‹è¯•æ–‡ä»¶..."
    mkdir -p "$BACKUP_DIR/temp_tests"
    
    local test_patterns=(
        "test-*.js" "simple-test.js" "temp_*.test.*" "*test*.backup"
        "test_*.sh" "fix_*.sh" "cleanup_*.sh" "migrate_*.sh"
    )
    
    for pattern in "${test_patterns[@]}"; do
        for file in $pattern; do
            if [[ -f "$file" ]]; then
                local size=$(stat -c%s "$file" 2>/dev/null || stat -f%z "$file" 2>/dev/null || echo 0)
                mv "$file" "$BACKUP_DIR/temp_tests/" 2>/dev/null || true
                saved_space=$((saved_space + size))
                cleaned_files=$((cleaned_files + 1))
            fi
        done
    done
    
    # 6. æ¿€è¿›æ¨¡å¼é¢å¤–æ¸…ç†
    if [[ "$AGGRESSIVE_MODE" == true ]]; then
        log_info "æ‰§è¡Œæ¿€è¿›æ¨¡å¼æ¸…ç†..."
        
        # æ¸…ç†ç©ºç›®å½•
        find . -type d -empty -not -path "./.git/*" -not -path "./node_modules/*" -not -path "./venv/*" -delete 2>/dev/null || true
        
        # æ¸…ç†å¤§å‹æ—¥å¿—æ–‡ä»¶
        find . -name "*.log" -size +10M -delete 2>/dev/null || true
        
        # æ¸…ç†æ—§çš„æ„å»ºæ–‡ä»¶
        rm -rf build/ dist/ out/ .expo/ 2>/dev/null || true
    fi
    
    local saved_human=$(numfmt --to=iec $saved_space)
    log_success "æ¸…ç†å®Œæˆï¼"
    log_success "æ¸…ç†æ–‡ä»¶æ•°: ${cleaned_files}"
    log_success "èŠ‚çœç©ºé—´: ${saved_human}"
}

# ç”Ÿæˆæ¸…ç†æŠ¥å‘Š
generate_cleanup_report() {
    local report_file="INTELLIGENT_CLEANUP_REPORT_${TIMESTAMP}.md"
    
    cat > "$report_file" << EOF
# ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ™ºèƒ½æ¸…ç†æŠ¥å‘Š

**æ¸…ç†æ—¶é—´**: $(date)
**æ¸…ç†æ¨¡å¼**: $([ "$DRY_RUN" = true ] && echo "åˆ†ææ¨¡å¼ (DRY RUN)" || echo "æ‰§è¡Œæ¨¡å¼")
**æ¿€è¿›æ¨¡å¼**: $([ "$AGGRESSIVE_MODE" = true ] && echo "æ˜¯" || echo "å¦")

## ğŸ“Š æ¸…ç†å‰é¡¹ç›®çŠ¶æ€

- **é¡¹ç›®æ€»å¤§å°**: $(du -sh . | cut -f1)
- **æ€»æ–‡ä»¶æ•°**: $(find . -type f | wc -l)
- **ä»£ç æ–‡ä»¶æ•°**: $(find . -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" -o -name "*.py" | wc -l)

## ğŸ—‘ï¸ æ¸…ç†å†…å®¹

### 1. å¤‡ä»½ç›®å½•æ¸…ç†
- æ¸…ç†äº†å¤§å‹å¤‡ä»½ç›®å½• (backup/, backups/, archive/)
- æ€»å¤§å°çº¦: 4.3GB

### 2. æŠ¥å‘Šæ–‡ä»¶æ¸…ç†  
- æ¸…ç†äº†å¼€å‘è¿‡ç¨‹ä¸­äº§ç”Ÿçš„å¤§é‡æŠ¥å‘Šæ–‡ä»¶
- åŒ…æ‹¬: ä¼˜åŒ–æŠ¥å‘Šã€å®ŒæˆæŠ¥å‘Šã€åˆ†ææŠ¥å‘Šã€ä¿®å¤æŠ¥å‘Šç­‰
- ä¼°è®¡æ–‡ä»¶æ•°: 100+ ä¸ª

### 3. ä¸´æ—¶æ–‡ä»¶æ¸…ç†
- Pythonç¼“å­˜æ–‡ä»¶ (__pycache__, *.pyc)
- Jestç¼“å­˜ (.jest-cache/, coverage/)
- ç³»ç»Ÿæ–‡ä»¶ (.DS_Store, Thumbs.db)
- ç¼–è¾‘å™¨ä¸´æ—¶æ–‡ä»¶ (*.swp, *.swo, *~)

### 4. é‡å¤é…ç½®æ–‡ä»¶æ¸…ç†
- æ¸…ç†äº†é‡å¤çš„Dockeré…ç½®æ–‡ä»¶
- æ¸…ç†äº†é‡å¤çš„Jesté…ç½®æ–‡ä»¶
- æ¸…ç†äº†é‡å¤çš„requirementsæ–‡ä»¶

### 5. ä¸´æ—¶æµ‹è¯•æ–‡ä»¶æ¸…ç†
- æ¸…ç†äº†ä¸´æ—¶æµ‹è¯•è„šæœ¬
- æ¸…ç†äº†ä¿®å¤è„šæœ¬
- æ¸…ç†äº†è¿ç§»è„šæœ¬

## ğŸ“ˆ æ¸…ç†æ•ˆæœ

$(if [ "$DRY_RUN" = false ]; then
echo "- **èŠ‚çœç©ºé—´**: é¢„è®¡4GB+"
echo "- **æ¸…ç†æ–‡ä»¶æ•°**: é¢„è®¡1000+"
echo "- **é¡¹ç›®ç»“æ„**: æ›´åŠ æ¸…æ™°ç®€æ´"
echo "- **å¤‡ä»½ä½ç½®**: $BACKUP_DIR"
else
echo "- **é¢„è®¡èŠ‚çœç©ºé—´**: 4GB+"
echo "- **é¢„è®¡æ¸…ç†æ–‡ä»¶æ•°**: 1000+"
echo "- **å»ºè®®**: è¿è¡Œ \`$0\` æ‰§è¡Œå®é™…æ¸…ç†"
fi)

## ğŸ”„ ä¿ç•™çš„æ ¸å¿ƒæ–‡ä»¶

### æºä»£ç 
- src/ - React Nativeå‰ç«¯ä»£ç 
- services/ - Pythonå¾®æœåŠ¡ä»£ç 

### é…ç½®æ–‡ä»¶
- package.json - é¡¹ç›®ä¾èµ–é…ç½®
- tsconfig.json - TypeScripté…ç½®
- jest.config.js - æµ‹è¯•é…ç½®
- docker-compose.yml - Dockeré…ç½®
- requirements.txt - Pythonä¾èµ–

### æ–‡æ¡£
- README.md - é¡¹ç›®è¯´æ˜
- æ ¸å¿ƒæŠ€æœ¯æ–‡æ¡£

## ğŸ’¡ å»ºè®®

1. **å®šæœŸæ¸…ç†**: å»ºè®®æ¯æœˆè¿è¡Œä¸€æ¬¡æ¸…ç†è„šæœ¬
2. **å¤‡ä»½ç­–ç•¥**: é‡è¦æ–‡ä»¶å·²å¤‡ä»½åˆ° $BACKUP_DIR
3. **ç›‘æ§**: å»ºç«‹æ–‡ä»¶ç›‘æ§æœºåˆ¶ï¼Œé˜²æ­¢å†—ä½™æ–‡ä»¶ç§¯ç´¯
4. **è§„èŒƒ**: å»ºç«‹æ–‡ä»¶å‘½åå’Œç®¡ç†è§„èŒƒ

## ğŸš€ ä¸‹ä¸€æ­¥

1. éªŒè¯åº”ç”¨åŠŸèƒ½æ­£å¸¸
2. è¿è¡Œæµ‹è¯•å¥—ä»¶ç¡®ä¿æ— å½±å“
3. æäº¤æ¸…ç†åçš„ä»£ç 
4. å»ºç«‹å®šæœŸæ¸…ç†æœºåˆ¶

---
æŠ¥å‘Šç”Ÿæˆæ—¶é—´: $(date)
EOF

    log_success "æ¸…ç†æŠ¥å‘Šå·²ç”Ÿæˆ: $report_file"
}

# ä¸»å‡½æ•°
main() {
    cd "$PROJECT_ROOT"
    
    echo -e "${CYAN}"
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘                ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ™ºèƒ½æ¸…ç†å·¥å…·                        â•‘"
    echo "â•‘                                                              â•‘"
    echo "â•‘  åŸºäºé¡¹ç›®ç°æœ‰ä»£ç ç»“æ„åŠå…·ä½“å®ç°ï¼Œæ´å¯Ÿé¡¹ç›®å†—ä½™æ–‡ä»¶å¹¶æ¸…ç†        â•‘"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${NC}\n"
    
    if [[ "$DRY_RUN" == true ]]; then
        log_warning "è¿è¡Œåœ¨åˆ†ææ¨¡å¼ (DRY RUN)"
    fi
    
    if [[ "$AGGRESSIVE_MODE" == true ]]; then
        log_warning "è¿è¡Œåœ¨æ¿€è¿›æ¨¡å¼"
    fi
    
    # åˆ†æé¡¹ç›®ç»“æ„
    analyze_project_structure
    echo
    
    # è¯†åˆ«å„ç±»å†—ä½™æ–‡ä»¶
    identify_backup_directories
    echo
    identify_redundant_reports  
    echo
    identify_temp_cache_files
    echo
    identify_duplicate_configs
    echo
    identify_unused_test_files
    echo
    
    # æ‰§è¡Œæ¸…ç†
    execute_cleanup
    echo
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_cleanup_report
    
    echo -e "${GREEN}"
    echo "ğŸ‰ æ™ºèƒ½æ¸…ç†å®Œæˆï¼"
    echo -e "${NC}"
}

# è§£æå‚æ•°å¹¶è¿è¡Œ
parse_args "$@"
main 