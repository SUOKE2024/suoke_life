#!/usr/bin/env python3
"""
ç´¢å…‹ç”Ÿæ´»é¡¹ç›®é‡å¤ä»£ç æ£€æµ‹å’Œé‡æ„è„šæœ¬
æ£€æµ‹å¹¶é‡æ„é‡å¤ä»£ç ï¼Œæå–å…¬å…±å‡½æ•°å’Œç»„ä»¶
"""

import os
import re
import hashlib
from pathlib import Path
from typing import List, Dict, Set, Tuple
from collections import defaultdict
import difflib

class DuplicateCodeRefactor:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.duplicates_found = []
        self.refactored_files = []
        self.min_lines = 5  # æœ€å°‘é‡å¤è¡Œæ•°
        self.similarity_threshold = 0.8  # ç›¸ä¼¼åº¦é˜ˆå€¼
        
    def detect_and_refactor_duplicates(self) -> Dict:
        """æ£€æµ‹å¹¶é‡æ„é‡å¤ä»£ç """
        print("ğŸ” å¼€å§‹æ£€æµ‹é‡å¤ä»£ç ...")
        
        # åˆ†åˆ«å¤„ç†ä¸åŒç±»å‹çš„æ–‡ä»¶
        python_result = self._process_python_files()
        typescript_result = self._process_typescript_files()
        
        # åˆå¹¶ç»“æœ
        total_result = {
            'python': python_result,
            'typescript': typescript_result,
            'total_duplicates_found': len(python_result['duplicates']) + len(typescript_result['duplicates']),
            'total_files_refactored': len(python_result['refactored_files']) + len(typescript_result['refactored_files'])
        }
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self._generate_report(total_result)
        total_result['report'] = report
        
        return total_result
    
    def _process_python_files(self) -> Dict:
        """å¤„ç†Pythonæ–‡ä»¶çš„é‡å¤ä»£ç """
        print("ğŸ æ£€æµ‹Pythoné‡å¤ä»£ç ...")
        
        python_files = list(self.project_root.rglob("*.py"))
        python_files = [f for f in python_files if not self._should_skip_file(f)]
        
        # æå–ä»£ç å—
        code_blocks = self._extract_python_code_blocks(python_files)
        
        # æ£€æµ‹é‡å¤
        duplicates = self._find_duplicates(code_blocks)
        
        # é‡æ„é‡å¤ä»£ç 
        refactored_files = self._refactor_python_duplicates(duplicates)
        
        return {
            'files_processed': len(python_files),
            'duplicates': duplicates,
            'refactored_files': refactored_files
        }
    
    def _process_typescript_files(self) -> Dict:
        """å¤„ç†TypeScriptæ–‡ä»¶çš„é‡å¤ä»£ç """
        print("ğŸ“˜ æ£€æµ‹TypeScripté‡å¤ä»£ç ...")
        
        ts_files = []
        for pattern in ["*.ts", "*.tsx", "*.js", "*.jsx"]:
            ts_files.extend(self.project_root.rglob(pattern))
        
        ts_files = [f for f in ts_files if not self._should_skip_file(f)]
        
        # æå–ä»£ç å—
        code_blocks = self._extract_typescript_code_blocks(ts_files)
        
        # æ£€æµ‹é‡å¤
        duplicates = self._find_duplicates(code_blocks)
        
        # é‡æ„é‡å¤ä»£ç 
        refactored_files = self._refactor_typescript_duplicates(duplicates)
        
        return {
            'files_processed': len(ts_files),
            'duplicates': duplicates,
            'refactored_files': refactored_files
        }
    
    def _should_skip_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡æ–‡ä»¶"""
        skip_patterns = [
            'node_modules',
            '.git',
            'dist',
            'build',
            'coverage',
            '__pycache__',
            '.pytest_cache',
            'venv',
            'env',
            '.venv',
            'Pods',
            'android/app/build',
            'ios/build',
            '.test.',
            '.spec.',
            '__tests__'
        ]
        
        file_str = str(file_path)
        return any(pattern in file_str for pattern in skip_patterns)
    
    def _extract_python_code_blocks(self, files: List[Path]) -> List[Dict]:
        """æå–Pythonä»£ç å—"""
        code_blocks = []
        
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                
                # æå–å‡½æ•°å’Œç±»
                current_block = []
                current_indent = 0
                block_start = 0
                
                for i, line in enumerate(lines):
                    stripped = line.strip()
                    
                    # æ£€æµ‹å‡½æ•°æˆ–ç±»å®šä¹‰
                    if (stripped.startswith('def ') or stripped.startswith('class ') or 
                        stripped.startswith('async def ')):
                        
                        # ä¿å­˜ä¹‹å‰çš„å—
                        if len(current_block) >= self.min_lines:
                            code_blocks.append({
                                'file': file_path,
                                'start_line': block_start,
                                'end_line': i - 1,
                                'content': ''.join(current_block),
                                'hash': self._get_code_hash(''.join(current_block))
                            })
                        
                        # å¼€å§‹æ–°å—
                        current_block = [line]
                        current_indent = len(line) - len(line.lstrip())
                        block_start = i
                    
                    elif current_block:
                        line_indent = len(line) - len(line.lstrip())
                        
                        # å¦‚æœç¼©è¿›å›åˆ°åŒçº§æˆ–æ›´å°‘ï¼Œç»“æŸå½“å‰å—
                        if stripped and line_indent <= current_indent:
                            if len(current_block) >= self.min_lines:
                                code_blocks.append({
                                    'file': file_path,
                                    'start_line': block_start,
                                    'end_line': i - 1,
                                    'content': ''.join(current_block),
                                    'hash': self._get_code_hash(''.join(current_block))
                                })
                            current_block = [line]
                            current_indent = line_indent
                            block_start = i
                        else:
                            current_block.append(line)
                
                # å¤„ç†æœ€åä¸€ä¸ªå—
                if len(current_block) >= self.min_lines:
                    code_blocks.append({
                        'file': file_path,
                        'start_line': block_start,
                        'end_line': len(lines) - 1,
                        'content': ''.join(current_block),
                        'hash': self._get_code_hash(''.join(current_block))
                    })
                    
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return code_blocks
    
    def _extract_typescript_code_blocks(self, files: List[Path]) -> List[Dict]:
        """æå–TypeScriptä»£ç å—"""
        code_blocks = []
        
        for file_path in files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å‡½æ•°å’Œç»„ä»¶
                patterns = [
                    r'(function\s+\w+\s*\([^)]*\)\s*\{[^}]*\})',
                    r'(const\s+\w+\s*=\s*\([^)]*\)\s*=>\s*\{[^}]*\})',
                    r'(export\s+function\s+\w+\s*\([^)]*\)\s*\{[^}]*\})',
                    r'(export\s+const\s+\w+\s*=\s*\([^)]*\)\s*=>\s*\{[^}]*\})'
                ]
                
                for pattern in patterns:
                    matches = re.finditer(pattern, content, re.MULTILINE | re.DOTALL)
                    for match in matches:
                        block_content = match.group(1)
                        if len(block_content.split('\n')) >= self.min_lines:
                            code_blocks.append({
                                'file': file_path,
                                'start_pos': match.start(),
                                'end_pos': match.end(),
                                'content': block_content,
                                'hash': self._get_code_hash(block_content)
                            })
                            
            except Exception as e:
                print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
        
        return code_blocks
    
    def _get_code_hash(self, content: str) -> str:
        """è·å–ä»£ç å†…å®¹çš„å“ˆå¸Œå€¼"""
        # æ ‡å‡†åŒ–ä»£ç ï¼ˆç§»é™¤ç©ºç™½å’Œæ³¨é‡Šï¼‰
        normalized = re.sub(r'\s+', ' ', content)
        normalized = re.sub(r'//.*?\n', '', normalized)
        normalized = re.sub(r'/\*.*?\*/', '', normalized, flags=re.DOTALL)
        return hashlib.md5(normalized.encode()).hexdigest()
    
    def _find_duplicates(self, code_blocks: List[Dict]) -> List[Dict]:
        """æŸ¥æ‰¾é‡å¤ä»£ç å—"""
        duplicates = []
        hash_groups = defaultdict(list)
        
        # æŒ‰å“ˆå¸Œå€¼åˆ†ç»„
        for block in code_blocks:
            hash_groups[block['hash']].append(block)
        
        # æ‰¾å‡ºé‡å¤çš„ç»„
        for hash_value, blocks in hash_groups.items():
            if len(blocks) > 1:
                # è¿›ä¸€æ­¥æ£€æŸ¥ç›¸ä¼¼åº¦
                similar_groups = self._group_by_similarity(blocks)
                for group in similar_groups:
                    if len(group) > 1:
                        duplicates.append({
                            'hash': hash_value,
                            'blocks': group,
                            'count': len(group)
                        })
        
        return duplicates
    
    def _group_by_similarity(self, blocks: List[Dict]) -> List[List[Dict]]:
        """æŒ‰ç›¸ä¼¼åº¦åˆ†ç»„ä»£ç å—"""
        groups = []
        
        for block in blocks:
            added_to_group = False
            
            for group in groups:
                # æ£€æŸ¥ä¸ç»„ä¸­ç¬¬ä¸€ä¸ªå—çš„ç›¸ä¼¼åº¦
                similarity = difflib.SequenceMatcher(
                    None, 
                    block['content'], 
                    group[0]['content']
                ).ratio()
                
                if similarity >= self.similarity_threshold:
                    group.append(block)
                    added_to_group = True
                    break
            
            if not added_to_group:
                groups.append([block])
        
        return groups
    
    def _refactor_python_duplicates(self, duplicates: List[Dict]) -> List[str]:
        """é‡æ„Pythoné‡å¤ä»£ç """
        refactored_files = []
        
        for duplicate in duplicates[:5]:  # é™åˆ¶å¤„ç†æ•°é‡
            try:
                # åˆ›å»ºå…¬å…±å‡½æ•°
                common_function = self._create_python_common_function(duplicate)
                
                # åˆ›å»ºutilsæ–‡ä»¶
                utils_file = self._create_python_utils_file(common_function)
                refactored_files.append(utils_file)
                
                print(f"âœ… å·²é‡æ„Pythoné‡å¤ä»£ç ï¼Œåˆ›å»ºå…¬å…±å‡½æ•°: {utils_file}")
                
            except Exception as e:
                print(f"âŒ Pythoné‡æ„å¤±è´¥: {e}")
        
        return refactored_files
    
    def _refactor_typescript_duplicates(self, duplicates: List[Dict]) -> List[str]:
        """é‡æ„TypeScripté‡å¤ä»£ç """
        refactored_files = []
        
        for duplicate in duplicates[:5]:  # é™åˆ¶å¤„ç†æ•°é‡
            try:
                # åˆ›å»ºå…¬å…±å‡½æ•°
                common_function = self._create_typescript_common_function(duplicate)
                
                # åˆ›å»ºutilsæ–‡ä»¶
                utils_file = self._create_typescript_utils_file(common_function)
                refactored_files.append(utils_file)
                
                print(f"âœ… å·²é‡æ„TypeScripté‡å¤ä»£ç ï¼Œåˆ›å»ºå…¬å…±å‡½æ•°: {utils_file}")
                
            except Exception as e:
                print(f"âŒ TypeScripté‡æ„å¤±è´¥: {e}")
        
        return refactored_files
    
    def _create_python_common_function(self, duplicate: Dict) -> str:
        """åˆ›å»ºPythonå…¬å…±å‡½æ•°"""
        first_block = duplicate['blocks'][0]
        content = first_block['content']
        
        # æå–å‡½æ•°å
        match = re.search(r'def\s+(\w+)', content)
        func_name = match.group(1) if match else 'common_function'
        
        return f"""def {func_name}_common(*args, **kwargs):
    \"\"\"
    é‡æ„çš„å…¬å…±å‡½æ•°ï¼Œä»é‡å¤ä»£ç ä¸­æå–
    é‡å¤æ¬¡æ•°: {duplicate['count']}
    \"\"\"
{content}
"""
    
    def _create_typescript_common_function(self, duplicate: Dict) -> str:
        """åˆ›å»ºTypeScriptå…¬å…±å‡½æ•°"""
        first_block = duplicate['blocks'][0]
        content = first_block['content']
        
        # æå–å‡½æ•°å
        match = re.search(r'(?:function\s+|const\s+)(\w+)', content)
        func_name = match.group(1) if match else 'commonFunction'
        
        return f"""/**
 * é‡æ„çš„å…¬å…±å‡½æ•°ï¼Œä»é‡å¤ä»£ç ä¸­æå–
 * é‡å¤æ¬¡æ•°: {duplicate['count']}
 */
export const {func_name}Common = {content};
"""
    
    def _create_python_utils_file(self, common_function: str) -> str:
        """åˆ›å»ºPython utilsæ–‡ä»¶"""
        utils_dir = self.project_root / 'src' / 'utils' / 'refactored'
        utils_dir.mkdir(parents=True, exist_ok=True)
        
        utils_file = utils_dir / 'common_functions.py'
        
        if utils_file.exists():
            with open(utils_file, 'a', encoding='utf-8') as f:
                f.write('\n\n' + common_function)
        else:
            with open(utils_file, 'w', encoding='utf-8') as f:
                f.write('"""é‡æ„çš„å…¬å…±å‡½æ•°"""\n\n' + common_function)
        
        return str(utils_file)
    
    def _create_typescript_utils_file(self, common_function: str) -> str:
        """åˆ›å»ºTypeScript utilsæ–‡ä»¶"""
        utils_dir = self.project_root / 'src' / 'utils' / 'refactored'
        utils_dir.mkdir(parents=True, exist_ok=True)
        
        utils_file = utils_dir / 'commonFunctions.ts'
        
        if utils_file.exists():
            with open(utils_file, 'a', encoding='utf-8') as f:
                f.write('\n\n' + common_function)
        else:
            with open(utils_file, 'w', encoding='utf-8') as f:
                f.write('// é‡æ„çš„å…¬å…±å‡½æ•°\n\n' + common_function)
        
        return str(utils_file)
    
    def _generate_report(self, result: Dict) -> str:
        """ç”Ÿæˆé‡æ„æŠ¥å‘Š"""
        report = f"""# ğŸ”„ é‡å¤ä»£ç æ£€æµ‹å’Œé‡æ„æŠ¥å‘Š

**é‡æ„æ—¶é—´**: {os.popen('date').read().strip()}
**é¡¹ç›®è·¯å¾„**: {self.project_root}

## ğŸ“Š é‡æ„ç»Ÿè®¡æ€»è§ˆ

- æ€»å‘ç°é‡å¤ä»£ç : {result['total_duplicates_found']} ç»„
- æ€»é‡æ„æ–‡ä»¶æ•°: {result['total_files_refactored']}

### Pythonæ–‡ä»¶é‡æ„
- å¤„ç†æ–‡ä»¶æ•°: {result['python']['files_processed']}
- å‘ç°é‡å¤ä»£ç : {len(result['python']['duplicates'])} ç»„
- é‡æ„æ–‡ä»¶æ•°: {len(result['python']['refactored_files'])}

### TypeScriptæ–‡ä»¶é‡æ„
- å¤„ç†æ–‡ä»¶æ•°: {result['typescript']['files_processed']}
- å‘ç°é‡å¤ä»£ç : {len(result['typescript']['duplicates'])} ç»„
- é‡æ„æ–‡ä»¶æ•°: {len(result['typescript']['refactored_files'])}

## ğŸ”§ é‡æ„ç­–ç•¥

### é‡å¤ä»£ç æ£€æµ‹
1. æœ€å°‘é‡å¤è¡Œæ•°: {self.min_lines}
2. ç›¸ä¼¼åº¦é˜ˆå€¼: {self.similarity_threshold}
3. å“ˆå¸Œç®—æ³•: MD5
4. ç›¸ä¼¼åº¦ç®—æ³•: SequenceMatcher

### é‡æ„æ–¹æ³•
1. æå–å…¬å…±å‡½æ•°
2. åˆ›å»ºutilsæ¨¡å—
3. ä¿æŒåŸæœ‰æ¥å£
4. æ·»åŠ æ–‡æ¡£è¯´æ˜

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

é€šè¿‡é‡å¤ä»£ç é‡æ„ï¼Œé¢„æœŸï¼š
- å‡å°‘ä»£ç å†—ä½™
- æå‡ä»£ç å¤ç”¨æ€§
- é™ä½ç»´æŠ¤æˆæœ¬
- æå‡ä»£ç è´¨é‡è¯„åˆ†
- å‡å°‘bugé£é™©

## ğŸ¯ å»ºè®®

1. å®šæœŸè¿è¡Œé‡å¤ä»£ç æ£€æµ‹
2. åœ¨ä»£ç å®¡æŸ¥ä¸­å…³æ³¨é‡å¤ä»£ç 
3. å»ºç«‹ä»£ç å¤ç”¨è§„èŒƒ
4. ä½¿ç”¨è®¾è®¡æ¨¡å¼å‡å°‘é‡å¤
5. å»ºç«‹å…¬å…±ç»„ä»¶åº“

## âš ï¸ æ³¨æ„äº‹é¡¹

1. é‡æ„åéœ€è¦å®Œæ•´æµ‹è¯•
2. æ³¨æ„ä¿æŒåŸæœ‰åŠŸèƒ½
3. è€ƒè™‘æ€§èƒ½å½±å“
4. æ›´æ–°ç›¸å…³æ–‡æ¡£
5. é€šçŸ¥å›¢é˜Ÿæˆå‘˜

"""
        
        return report

def main():
    print("ğŸ”„ å¼€å§‹é‡å¤ä»£ç æ£€æµ‹å’Œé‡æ„...")
    
    refactor = DuplicateCodeRefactor('.')
    
    # æ‰§è¡Œé‡æ„
    result = refactor.detect_and_refactor_duplicates()
    
    # ä¿å­˜æŠ¥å‘Š
    with open('duplicate_code_refactor_report.md', 'w', encoding='utf-8') as f:
        f.write(result['report'])
    
    print(f"âœ… é‡å¤ä»£ç é‡æ„å®Œæˆï¼")
    print(f"ğŸ“Š å‘ç°é‡å¤ä»£ç : {result['total_duplicates_found']} ç»„")
    print(f"ğŸ“Š é‡æ„æ–‡ä»¶æ•°: {result['total_files_refactored']}")
    print(f"ğŸ“Š Pythoné‡å¤: {len(result['python']['duplicates'])} ç»„")
    print(f"ğŸ“Š TypeScripté‡å¤: {len(result['typescript']['duplicates'])} ç»„")
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜åˆ°: duplicate_code_refactor_report.md")

if __name__ == '__main__':
    main() 