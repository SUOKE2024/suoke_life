#!/usr/bin/env python3
"""
ç´¢å…‹ç”Ÿæ´»é¡¹ç›® GIL ä¼˜åŒ–å»ºè®®ç”Ÿæˆå™¨
åˆ†æé¡¹ç›®ä»£ç å¹¶ç”Ÿæˆå…·ä½“çš„ä¼˜åŒ–å»ºè®®
"""

import os
import re
import json
from pathlib import Path
from typing import Dict, List, Tuple, Any
from dataclasses import dataclass


@dataclass
class GILIssue:
    """GILé—®é¢˜æè¿°"""
    file_path: str
    line_number: int
    issue_type: str
    severity: str  # high, medium, low
    description: str
    current_code: str
    suggested_fix: str
    performance_impact: str


class GILOptimizationAnalyzer:
    """GILä¼˜åŒ–åˆ†æå™¨"""
    
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.issues: List[GILIssue] = []
        
        # å®šä¹‰é—®é¢˜æ¨¡å¼
        self.patterns = {
            'thread_pool_executor': {
                'pattern': r'ThreadPoolExecutor\s*\(',
                'severity': 'high',
                'description': 'ThreadPoolExecutorç”¨äºCPUå¯†é›†å‹ä»»åŠ¡ï¼Œå—GILé™åˆ¶'
            },
            'threading_lock': {
                'pattern': r'threading\.Lock\(\)|from\s+threading\s+import.*Lock',
                'severity': 'medium',
                'description': 'æ˜¾å¼çº¿ç¨‹é”å¯èƒ½å¯¼è‡´GILç«äº‰'
            }
        }
    
    def analyze_file(self, file_path: Path) -> List[GILIssue]:
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
        except Exception as e:
            print(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
            return issues
        
        # æ£€æŸ¥æ¯ä¸ªæ¨¡å¼
        for pattern_name, pattern_info in self.patterns.items():
            matches = re.finditer(pattern_info['pattern'], content, re.MULTILINE | re.IGNORECASE)
            
            for match in matches:
                # æ‰¾åˆ°åŒ¹é…çš„è¡Œå·
                line_number = content[:match.start()].count('\n') + 1
                current_line = lines[line_number - 1] if line_number <= len(lines) else ""
                
                # ç”Ÿæˆä¼˜åŒ–å»ºè®®
                suggested_fix = self._generate_fix_suggestion(pattern_name, current_line)
                performance_impact = self._estimate_performance_impact(pattern_name)
                
                issue = GILIssue(
                    file_path=str(file_path.relative_to(self.project_root)),
                    line_number=line_number,
                    issue_type=pattern_name,
                    severity=pattern_info['severity'],
                    description=pattern_info['description'],
                    current_code=current_line.strip(),
                    suggested_fix=suggested_fix,
                    performance_impact=performance_impact
                )
                
                issues.append(issue)
        
        return issues
    
    def _generate_fix_suggestion(self, pattern_name: str, current_line: str) -> str:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        suggestions = {
            'thread_pool_executor': f"""
å½“å‰ä»£ç ï¼ˆå—GILé™åˆ¶ï¼‰:
{current_line}

ä¼˜åŒ–å»ºè®®1: ä½¿ç”¨ProcessPoolExecutor
from concurrent.futures import ProcessPoolExecutor
executor = ProcessPoolExecutor(max_workers=4)

ä¼˜åŒ–å»ºè®®2: ä½¿ç”¨å¼‚æ­¥I/Oï¼ˆå¦‚æœæ˜¯I/Oå¯†é›†å‹ï¼‰
import asyncio
async def async_task():
    # å¼‚æ­¥å®ç°
    pass

ä¼˜åŒ–å»ºè®®3: ä½¿ç”¨Numba JITï¼ˆå¦‚æœæ˜¯æ•°å€¼è®¡ç®—ï¼‰
from numba import jit
@jit(nopython=True)
def optimized_computation():
    # JITç¼–è¯‘çš„è®¡ç®—å‡½æ•°
    pass
""",
            'threading_lock': f"""
å½“å‰ä»£ç :
{current_line}

ä¼˜åŒ–å»ºè®®1: ä½¿ç”¨asyncio.Lockï¼ˆå¼‚æ­¥ç¯å¢ƒï¼‰
import asyncio
lock = asyncio.Lock()

ä¼˜åŒ–å»ºè®®2: è€ƒè™‘æ— é”æ•°æ®ç»“æ„
import queue
thread_safe_queue = queue.Queue()

ä¼˜åŒ–å»ºè®®3: ä½¿ç”¨å¤šè¿›ç¨‹é€šä¿¡
import multiprocessing
manager = multiprocessing.Manager()
shared_dict = manager.dict()
"""
        }
        
        return suggestions.get(pattern_name, f"å½“å‰ä»£ç : {current_line}\nå»ºè®®: è€ƒè™‘ä½¿ç”¨ProcessPoolExecutoræˆ–å¼‚æ­¥I/Oä¼˜åŒ–")
    
    def _estimate_performance_impact(self, pattern_name: str) -> str:
        """ä¼°ç®—æ€§èƒ½å½±å“"""
        impacts = {
            'thread_pool_executor': "é«˜å½±å“ï¼šå¯èƒ½æŸå¤±60-80%çš„å¤šæ ¸æ€§èƒ½",
            'threading_lock': "ä¸­ç­‰å½±å“ï¼šå¯èƒ½å¯¼è‡´çº¿ç¨‹ç«äº‰å’Œä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€"
        }
        return impacts.get(pattern_name, "å½±å“ç¨‹åº¦å¾…è¯„ä¼°")
    
    def analyze_project(self) -> List[GILIssue]:
        """åˆ†ææ•´ä¸ªé¡¹ç›®"""
        print("ğŸ” å¼€å§‹åˆ†æé¡¹ç›®GILé—®é¢˜...")
        
        # æŸ¥æ‰¾æ‰€æœ‰Pythonæ–‡ä»¶
        python_files = list(self.project_root.rglob("*.py"))
        
        # æ’é™¤æŸäº›ç›®å½•
        excluded_dirs = {'.git', '__pycache__', '.pytest_cache', 'node_modules', 'venv', '.venv'}
        python_files = [
            f for f in python_files 
            if not any(excluded in f.parts for excluded in excluded_dirs)
        ]
        
        print(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
        
        all_issues = []
        for file_path in python_files:
            file_issues = self.analyze_file(file_path)
            all_issues.extend(file_issues)
            
            if file_issues:
                print(f"  ğŸ“„ {file_path.relative_to(self.project_root)}: {len(file_issues)} ä¸ªé—®é¢˜")
        
        self.issues = all_issues
        return all_issues
    
    def generate_report(self, output_file: str = "gil_optimization_report.json") -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        # æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†ç»„
        high_severity = [issue for issue in self.issues if issue.severity == 'high']
        medium_severity = [issue for issue in self.issues if issue.severity == 'medium']
        low_severity = [issue for issue in self.issues if issue.severity == 'low']
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„
        files_with_issues = {}
        for issue in self.issues:
            if issue.file_path not in files_with_issues:
                files_with_issues[issue.file_path] = []
            files_with_issues[issue.file_path].append(issue)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        issue_types = {}
        for issue in self.issues:
            issue_types[issue.issue_type] = issue_types.get(issue.issue_type, 0) + 1
        
        report = {
            'analysis_timestamp': __import__('time').strftime('%Y-%m-%d %H:%M:%S'),
            'summary': {
                'total_issues': len(self.issues),
                'high_severity': len(high_severity),
                'medium_severity': len(medium_severity),
                'low_severity': len(low_severity),
                'affected_files': len(files_with_issues)
            },
            'issue_types': issue_types,
            'top_affected_files': sorted(
                [(path, len(issues)) for path, issues in files_with_issues.items()],
                key=lambda x: x[1],
                reverse=True
            )[:10],
            'high_priority_issues': [
                {
                    'file': issue.file_path,
                    'line': issue.line_number,
                    'type': issue.issue_type,
                    'description': issue.description,
                    'current_code': issue.current_code,
                    'performance_impact': issue.performance_impact
                }
                for issue in high_severity[:20]  # å‰20ä¸ªé«˜ä¼˜å…ˆçº§é—®é¢˜
            ],
            'optimization_recommendations': self._generate_optimization_plan()
        }
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“Š ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        return report
    
    def _generate_optimization_plan(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–è®¡åˆ’"""
        high_issues = [issue for issue in self.issues if issue.severity == 'high']
        medium_issues = [issue for issue in self.issues if issue.severity == 'medium']
        
        return {
            'phase_1_immediate': {
                'description': 'ç«‹å³ä¼˜åŒ–ï¼ˆ1-2å‘¨ï¼‰',
                'targets': [
                    'æ›¿æ¢AIæ¨ç†æœåŠ¡ä¸­çš„ThreadPoolExecutorä¸ºProcessPoolExecutor',
                    'ä¼˜åŒ–ç¼“å­˜ç®¡ç†å™¨ä½¿ç”¨å¼‚æ­¥I/O',
                    'ä¿®å¤é«˜ä¼˜å…ˆçº§GILç“¶é¢ˆ'
                ],
                'affected_files': len(set(issue.file_path for issue in high_issues)),
                'estimated_performance_gain': '30-50%'
            },
            'phase_2_systematic': {
                'description': 'ç³»ç»Ÿä¼˜åŒ–ï¼ˆ1ä¸ªæœˆï¼‰',
                'targets': [
                    'é‡æ„æ•°æ®å¤„ç†ç®¡é“ä½¿ç”¨å¤šè¿›ç¨‹',
                    'å®æ–½Numba JITç¼–è¯‘ä¼˜åŒ–',
                    'å®Œå–„å¼‚æ­¥I/Oä½¿ç”¨'
                ],
                'affected_files': len(set(issue.file_path for issue in medium_issues)),
                'estimated_performance_gain': '50-80%'
            },
            'phase_3_advanced': {
                'description': 'é«˜çº§ä¼˜åŒ–ï¼ˆ2-3ä¸ªæœˆï¼‰',
                'targets': [
                    'å¼€å‘å…³é”®ç®—æ³•çš„Cæ‰©å±•',
                    'å¾®æœåŠ¡æ¶æ„è°ƒæ•´',
                    'æ€§èƒ½ç›‘æ§ç³»ç»Ÿå®Œå–„'
                ],
                'estimated_performance_gain': '80-200%'
            }
        }
    
    def print_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ¯ GILä¼˜åŒ–åˆ†ææ‘˜è¦")
        print("="*60)
        
        high_count = len([i for i in self.issues if i.severity == 'high'])
        medium_count = len([i for i in self.issues if i.severity == 'medium'])
        low_count = len([i for i in self.issues if i.severity == 'low'])
        
        print(f"æ€»é—®é¢˜æ•°: {len(self.issues)}")
        print(f"ğŸ”´ é«˜ä¼˜å…ˆçº§: {high_count}")
        print(f"ğŸŸ¡ ä¸­ä¼˜å…ˆçº§: {medium_count}")
        print(f"ğŸŸ¢ ä½ä¼˜å…ˆçº§: {low_count}")
        
        # æ˜¾ç¤ºæœ€ä¸¥é‡çš„é—®é¢˜
        if high_count > 0:
            print(f"\nâš ï¸  å‘ç° {high_count} ä¸ªé«˜ä¼˜å…ˆçº§GILé—®é¢˜ï¼Œå»ºè®®ç«‹å³ä¼˜åŒ–")
            print("\nğŸ”¥ æœ€ä¸¥é‡çš„é—®é¢˜:")
            for i, issue in enumerate([i for i in self.issues if i.severity == 'high'][:5], 1):
                print(f"  {i}. {issue.file_path}:{issue.line_number} - {issue.description}")
        
        # æŒ‰é—®é¢˜ç±»å‹ç»Ÿè®¡
        issue_types = {}
        for issue in self.issues:
            issue_types[issue.issue_type] = issue_types.get(issue.issue_type, 0) + 1
        
        if issue_types:
            print(f"\nğŸ“Š é—®é¢˜ç±»å‹åˆ†å¸ƒ:")
            for issue_type, count in sorted(issue_types.items(), key=lambda x: x[1], reverse=True):
                print(f"  {issue_type}: {count} ä¸ª")


def main():
    """ä¸»å‡½æ•°"""
    project_root = os.getcwd()
    analyzer = GILOptimizationAnalyzer(project_root)
    
    # åˆ†æé¡¹ç›®
    issues = analyzer.analyze_project()
    
    # æ‰“å°æ‘˜è¦
    analyzer.print_summary()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = analyzer.generate_report()
    
    # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
    print(f"\nğŸ’¡ ä¼˜åŒ–è®¡åˆ’:")
    for phase, details in report['optimization_recommendations'].items():
        print(f"\n{details['description']}:")
        for target in details['targets']:
            print(f"  â€¢ {target}")
        print(f"  é¢„æœŸæ€§èƒ½æå‡: {details['estimated_performance_gain']}")


if __name__ == "__main__":
    main() 