#!/usr/bin/env python3
"""
ç´¢å…‹ç”Ÿæ´»é¡¹ç›® - å¯¼å…¥è¯­å¥ä¼˜åŒ–å·¥å…·
è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤Pythonä»£ç ä¸­çš„å¯¼å…¥é—®é¢˜
"""

import ast
import json
import logging
import os
import re
import subprocess
import sys
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class ImportIssue:
    """å¯¼å…¥é—®é¢˜"""

    file_path: str
    line_number: int
    issue_type: str
    original_import: str
    suggested_fix: str
    severity: str


class ImportOptimizer:
    """å¯¼å…¥è¯­å¥ä¼˜åŒ–å™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.issues_found = []
        self.backup_dir = self.project_root / "backups" / "import_optimization"

        # æ’é™¤çš„æ–‡ä»¶å’Œç›®å½•
        self.exclude_patterns = {
            "venv",
            "env",
            ".env",
            "__pycache__",
            ".git",
            "node_modules",
            ".pytest_cache",
            "dist",
            "build",
            ".idea",
            ".vscode",
            "*.pyc",
            "*.pyo",
            "*.egg-info",
        }

    def scan_import_issues(self) -> List[ImportIssue]:
        """æ‰«æå¯¼å…¥é—®é¢˜"""
        logger.info("ğŸ” æ‰«æå¯¼å…¥è¯­å¥é—®é¢˜...")

        python_files = self._get_python_files()

        for file_path in python_files:
            try:
                self._analyze_file_imports(file_path)
            except Exception as e:
                logger.warning(f"æ— æ³•åˆ†ææ–‡ä»¶ {file_path}: {e}")

        logger.info(f"å‘ç° {len(self.issues_found)} ä¸ªå¯¼å…¥é—®é¢˜")
        return self.issues_found

    def _get_python_files(self) -> List[Path]:
        """è·å–æ‰€æœ‰Pythonæ–‡ä»¶"""
        python_files = []

        for root, dirs, files in os.walk(self.project_root):
            # æ’é™¤ç‰¹å®šç›®å½•
            dirs[:] = [
                d
                for d in dirs
                if not any(pattern in d for pattern in self.exclude_patterns)
            ]

            for file in files:
                if file.endswith(".py"):
                    file_path = Path(root) / file
                    # æ’é™¤å¤‡ä»½æ–‡ä»¶
                    if "backup" not in str(file_path).lower():
                        python_files.append(file_path)

        return python_files

    def _analyze_file_imports(self, file_path: Path):
        """åˆ†æå•ä¸ªæ–‡ä»¶çš„å¯¼å…¥è¯­å¥"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                content = f.read()
                lines = content.split("\n")

            # ä½¿ç”¨ASTåˆ†æ
            try:
                tree = ast.parse(content)
                self._analyze_ast_imports(file_path, tree, lines)
            except SyntaxError:
                # å¦‚æœASTè§£æå¤±è´¥ï¼Œä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼
                self._analyze_regex_imports(file_path, lines)

        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")

    def _analyze_ast_imports(self, file_path: Path, tree: ast.AST, lines: List[str]):
        """ä½¿ç”¨ASTåˆ†æå¯¼å…¥è¯­å¥"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ImportFrom):
                self._check_import_from(file_path, node, lines)
            elif isinstance(node, ast.Import):
                self._check_import(file_path, node, lines)

    def _check_import_from(
        self, file_path: Path, node: ast.ImportFrom, lines: List[str]
    ):
        """æ£€æŸ¥ from ... import ... è¯­å¥"""
        line_num = node.lineno
        line_content = lines[line_num - 1] if line_num <= len(lines) else ""

        # æ£€æŸ¥é€šé…ç¬¦å¯¼å…¥
        for alias in node.names:
            if alias.name == "*":
                issue = ImportIssue(
                    file_path=str(file_path.relative_to(self.project_root)),
                    line_number=line_num,
                    issue_type="wildcard_import",
                    original_import=line_content.strip(),
                    suggested_fix=self._suggest_wildcard_fix(node),
                    severity="HIGH",
                )
                self.issues_found.append(issue)

        # æ£€æŸ¥è¿‡é•¿çš„å¯¼å…¥è¡Œ
        if len(line_content) > 100:
            issue = ImportIssue(
                file_path=str(file_path.relative_to(self.project_root)),
                line_number=line_num,
                issue_type="long_import_line",
                original_import=line_content.strip(),
                suggested_fix=self._suggest_multiline_import(node),
                severity="MEDIUM",
            )
            self.issues_found.append(issue)

    def _check_import(self, file_path: Path, node: ast.Import, lines: List[str]):
        """æ£€æŸ¥ import ... è¯­å¥"""
        line_num = node.lineno
        line_content = lines[line_num - 1] if line_num <= len(lines) else ""

        # æ£€æŸ¥å¤šä¸ªæ¨¡å—åœ¨ä¸€è¡Œå¯¼å…¥
        if len(node.names) > 1:
            issue = ImportIssue(
                file_path=str(file_path.relative_to(self.project_root)),
                line_number=line_num,
                issue_type="multiple_imports",
                original_import=line_content.strip(),
                suggested_fix=self._suggest_separate_imports(node),
                severity="MEDIUM",
            )
            self.issues_found.append(issue)

    def _analyze_regex_imports(self, file_path: Path, lines: List[str]):
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†æå¯¼å…¥è¯­å¥ï¼ˆå¤‡ç”¨æ–¹æ³•ï¼‰"""
        for line_num, line in enumerate(lines, 1):
            line_stripped = line.strip()

            # æ£€æŸ¥é€šé…ç¬¦å¯¼å…¥
            if re.match(r"from\s+\w+.*\s+import\s+\*", line_stripped):
                issue = ImportIssue(
                    file_path=str(file_path.relative_to(self.project_root)),
                    line_number=line_num,
                    issue_type="wildcard_import",
                    original_import=line_stripped,
                    suggested_fix="ä½¿ç”¨å…·ä½“çš„å¯¼å…¥åç§°æ›¿æ¢ *",
                    severity="HIGH",
                )
                self.issues_found.append(issue)

            # æ£€æŸ¥å¤šä¸ªå¯¼å…¥åœ¨ä¸€è¡Œ
            if re.match(r"import\s+\w+,", line_stripped):
                issue = ImportIssue(
                    file_path=str(file_path.relative_to(self.project_root)),
                    line_number=line_num,
                    issue_type="multiple_imports",
                    original_import=line_stripped,
                    suggested_fix="å°†å¤šä¸ªå¯¼å…¥åˆ†åˆ«å†™åœ¨ä¸åŒè¡Œ",
                    severity="MEDIUM",
                )
                self.issues_found.append(issue)

    def _suggest_wildcard_fix(self, node: ast.ImportFrom) -> str:
        """å»ºè®®é€šé…ç¬¦å¯¼å…¥çš„ä¿®å¤æ–¹æ¡ˆ"""
        module_name = node.module or ""
        return f"""
å»ºè®®ä¿®å¤æ–¹æ¡ˆï¼š
1. åˆ†æä»£ç ä¸­å®é™…ä½¿ç”¨çš„å‡½æ•°/ç±»
2. æ›¿æ¢ä¸ºå…·ä½“å¯¼å…¥ï¼š
   from {module_name} import specific_function, SpecificClass
3. æˆ–ä½¿ç”¨æ¨¡å—å¯¼å…¥ï¼š
   import {module_name}
   # ç„¶åä½¿ç”¨ {module_name}.function_name
"""

    def _suggest_multiline_import(self, node: ast.ImportFrom) -> str:
        """å»ºè®®å¤šè¡Œå¯¼å…¥çš„ä¿®å¤æ–¹æ¡ˆ"""
        module_name = node.module or ""
        imports = [alias.name for alias in node.names]

        if len(imports) > 3:
            multiline_import = f"from {module_name} import (\n"
            for imp in imports:
                multiline_import += f"    {imp},\n"
            multiline_import += ")"

            return f"""
å»ºè®®ä¿®å¤æ–¹æ¡ˆï¼š
{multiline_import}
"""
        return "å°†å¯¼å…¥è¯­å¥åˆ†è¡Œä»¥æé«˜å¯è¯»æ€§"

    def _suggest_separate_imports(self, node: ast.Import) -> str:
        """å»ºè®®åˆ†ç¦»å¯¼å…¥çš„ä¿®å¤æ–¹æ¡ˆ"""
        separate_imports = []
        for alias in node.names:
            separate_imports.append(f"import {alias.name}")

        return f"""
å»ºè®®ä¿®å¤æ–¹æ¡ˆï¼š
{chr(10).join(separate_imports)}
"""

    def optimize_imports_with_isort(self) -> bool:
        """ä½¿ç”¨isortä¼˜åŒ–å¯¼å…¥è¯­å¥"""
        logger.info("ğŸ”§ ä½¿ç”¨isortä¼˜åŒ–å¯¼å…¥è¯­å¥...")

        try:
            # æ£€æŸ¥isortæ˜¯å¦å®‰è£…
            result = subprocess.run(
                ["isort", "--version"], capture_output=True, text=True
            )
            if result.returncode != 0:
                logger.warning("isortæœªå®‰è£…ï¼Œè·³è¿‡è‡ªåŠ¨ä¼˜åŒ–")
                return False

            # åˆ›å»ºisorté…ç½®
            self._create_isort_config()

            # è¿è¡Œisort
            python_files = self._get_python_files()
            for file_path in python_files:
                try:
                    subprocess.run(
                        ["isort", str(file_path)],
                        capture_output=True,
                        text=True,
                        check=True,
                    )
                except subprocess.CalledProcessError as e:
                    logger.warning(f"isortå¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

            logger.info("âœ… isortä¼˜åŒ–å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"isortä¼˜åŒ–å¤±è´¥: {e}")
            return False

    def _create_isort_config(self):
        """åˆ›å»ºisorté…ç½®æ–‡ä»¶"""
        config_content = """[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true

# å¯¼å…¥åˆ†ç»„
known_first_party = ["src", "services", "agents"]
known_third_party = ["fastapi", "pydantic", "sqlalchemy", "redis", "celery"]

# å¯¼å…¥é¡ºåº
sections = ["FUTURE", "STDLIB", "THIRDPARTY", "FIRSTPARTY", "LOCALFOLDER"]

# è·³è¿‡çš„æ–‡ä»¶
skip = ["venv", "env", ".env", "__pycache__", ".git", "node_modules"]
"""

        config_file = self.project_root / "pyproject.toml"

        # å¦‚æœæ–‡ä»¶å­˜åœ¨ï¼Œè¿½åŠ é…ç½®ï¼›å¦åˆ™åˆ›å»ºæ–°æ–‡ä»¶
        if config_file.exists():
            with open(config_file, "a", encoding="utf-8") as f:
                f.write("\n" + config_content)
        else:
            with open(config_file, "w", encoding="utf-8") as f:
                f.write(config_content)

    def remove_unused_imports(self) -> bool:
        """ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥"""
        logger.info("ğŸ§¹ ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥...")

        try:
            # æ£€æŸ¥autoflakeæ˜¯å¦å®‰è£…
            result = subprocess.run(
                ["autoflake", "--version"], capture_output=True, text=True
            )
            if result.returncode != 0:
                logger.warning("autoflakeæœªå®‰è£…ï¼Œè·³è¿‡æœªä½¿ç”¨å¯¼å…¥ç§»é™¤")
                return False

            # è¿è¡Œautoflake
            python_files = self._get_python_files()
            for file_path in python_files:
                try:
                    subprocess.run(
                        [
                            "autoflake",
                            "--in-place",
                            "--remove-all-unused-imports",
                            "--remove-unused-variables",
                            str(file_path),
                        ],
                        capture_output=True,
                        text=True,
                        check=True,
                    )
                except subprocess.CalledProcessError as e:
                    logger.warning(f"autoflakeå¤„ç†æ–‡ä»¶å¤±è´¥ {file_path}: {e}")

            logger.info("âœ… æœªä½¿ç”¨å¯¼å…¥ç§»é™¤å®Œæˆ")
            return True

        except Exception as e:
            logger.error(f"ç§»é™¤æœªä½¿ç”¨å¯¼å…¥å¤±è´¥: {e}")
            return False

    def create_import_guidelines(self) -> str:
        """åˆ›å»ºå¯¼å…¥è§„èŒƒæŒ‡å—"""
        guidelines_path = (
            self.project_root / "docs" / "development" / "import_guidelines.md"
        )
        guidelines_path.parent.mkdir(parents=True, exist_ok=True)

        guidelines_content = """# Pythonå¯¼å…¥è¯­å¥è§„èŒƒæŒ‡å—

## ğŸ“‹ å¯¼å…¥é¡ºåº

æŒ‰ç…§ä»¥ä¸‹é¡ºåºç»„ç»‡å¯¼å…¥è¯­å¥ï¼š

1. **æ ‡å‡†åº“å¯¼å…¥**
2. **ç¬¬ä¸‰æ–¹åº“å¯¼å…¥**
3. **æœ¬åœ°åº”ç”¨å¯¼å…¥**

æ¯ç»„ä¹‹é—´ç”¨ç©ºè¡Œåˆ†éš”ã€‚

## âœ… æ¨èåšæ³•

### 1. ä½¿ç”¨å…·ä½“å¯¼å…¥
```python
# âœ… æ¨è
from typing import List, Dict, Optional
from pathlib import Path

# âŒ é¿å…
from typing import *
```

### 2. å¯¼å…¥è¯­å¥åˆ†è¡Œ
```python
# âœ… æ¨è - å¤šä¸ªå¯¼å…¥æ—¶ä½¿ç”¨æ‹¬å·åˆ†è¡Œ
from some_module import (
    function_one,
    function_two,
    ClassOne,
    ClassTwo
)

# âŒ é¿å… - è¿‡é•¿çš„å•è¡Œå¯¼å…¥
from some_module import function_one, function_two, ClassOne, ClassTwo, function_three
```

### 3. æ¨¡å—å¯¼å…¥ vs å…·ä½“å¯¼å…¥
```python
# âœ… æ¨è - å¯¹äºå¸¸ç”¨çš„å¤§å‹æ¨¡å—
import os
import sys
import json

# âœ… æ¨è - å¯¹äºç‰¹å®šåŠŸèƒ½
from datetime import datetime, timedelta
from pathlib import Path

# âŒ é¿å… - é€šé…ç¬¦å¯¼å…¥
from os import *
```

### 4. ç›¸å¯¹å¯¼å…¥
```python
# âœ… æ¨è - æ˜ç¡®çš„ç›¸å¯¹å¯¼å…¥
from .models import User
from ..utils import helper_function

# âœ… æ¨è - ç»å¯¹å¯¼å…¥
from src.models import User
from src.utils import helper_function
```

## ğŸ› ï¸ å·¥å…·é…ç½®

### isorté…ç½®
åœ¨ `pyproject.toml` ä¸­é…ç½®ï¼š
```toml
[tool.isort]
profile = "black"
multi_line_output = 3
line_length = 88
include_trailing_comma = true
```

### autoflakeé…ç½®
ç§»é™¤æœªä½¿ç”¨çš„å¯¼å…¥ï¼š
```bash
autoflake --in-place --remove-all-unused-imports file.py
```

## ğŸš« é¿å…çš„åšæ³•

1. **é€šé…ç¬¦å¯¼å…¥**
   ```python
   # âŒ é¿å…
   from module import *
   ```

2. **å¤šä¸ªæ¨¡å—å•è¡Œå¯¼å…¥**
   ```python
   # âŒ é¿å…
   import os, sys, json
   ```

3. **æœªä½¿ç”¨çš„å¯¼å…¥**
   ```python
   # âŒ é¿å…
   import unused_module
   ```

4. **å¾ªç¯å¯¼å…¥**
   ```python
   # âŒ é¿å…
   # file_a.py
   from file_b import something
   
   # file_b.py
   from file_a import something_else
   ```

## ğŸ”§ è‡ªåŠ¨åŒ–å·¥å…·

### 1. ä½¿ç”¨isortæ’åºå¯¼å…¥
```bash
isort your_file.py
```

### 2. ä½¿ç”¨autoflakeç§»é™¤æœªä½¿ç”¨å¯¼å…¥
```bash
autoflake --in-place --remove-all-unused-imports your_file.py
```

### 3. ä½¿ç”¨blackæ ¼å¼åŒ–ä»£ç 
```bash
black your_file.py
```

## ğŸ“ æ£€æŸ¥æ¸…å•

åœ¨æäº¤ä»£ç å‰æ£€æŸ¥ï¼š

- [ ] å¯¼å…¥è¯­å¥æŒ‰æ­£ç¡®é¡ºåºæ’åˆ—
- [ ] æ²¡æœ‰é€šé…ç¬¦å¯¼å…¥
- [ ] æ²¡æœ‰æœªä½¿ç”¨çš„å¯¼å…¥
- [ ] é•¿å¯¼å…¥è¯­å¥å·²åˆ†è¡Œ
- [ ] æ²¡æœ‰å¾ªç¯å¯¼å…¥

## ğŸ¯ æœ€ä½³å®è·µ

1. **å®šæœŸè¿è¡Œå¯¼å…¥ä¼˜åŒ–å·¥å…·**
2. **åœ¨CI/CDä¸­é›†æˆå¯¼å…¥æ£€æŸ¥**
3. **å›¢é˜Ÿä»£ç å®¡æŸ¥æ—¶å…³æ³¨å¯¼å…¥è´¨é‡**
4. **ä½¿ç”¨IDEæ’ä»¶è‡ªåŠ¨ä¼˜åŒ–å¯¼å…¥**
"""

        with open(guidelines_path, "w", encoding="utf-8") as f:
            f.write(guidelines_content)

        return str(guidelines_path)

    def generate_report(self) -> str:
        """ç”Ÿæˆå¯¼å…¥ä¼˜åŒ–æŠ¥å‘Š"""
        logger.info("ğŸ“Š ç”Ÿæˆå¯¼å…¥ä¼˜åŒ–æŠ¥å‘Š...")

        report = f"""# å¯¼å…¥è¯­å¥ä¼˜åŒ–æŠ¥å‘Š

## ğŸ“Š æ‰«æç»“æœæ¦‚è§ˆ

- **æ‰«ææ–‡ä»¶æ•°é‡**: {len(self._get_python_files())}
- **å‘ç°å¯¼å…¥é—®é¢˜**: {len(self.issues_found)}
- **é—®é¢˜ç±»å‹åˆ†å¸ƒ**:
"""

        # ç»Ÿè®¡é—®é¢˜ç±»å‹
        issue_types = {}
        severity_count = {}

        for issue in self.issues_found:
            issue_types[issue.issue_type] = issue_types.get(issue.issue_type, 0) + 1
            severity_count[issue.severity] = severity_count.get(issue.severity, 0) + 1

        for issue_type, count in issue_types.items():
            report += f"  - {issue_type}: {count}\n"

        report += "\n- **ä¸¥é‡æ€§åˆ†å¸ƒ**:\n"
        for severity, count in severity_count.items():
            report += f"  - {severity}: {count}\n"

        report += "\n## ğŸ” å‘ç°çš„å¯¼å…¥é—®é¢˜è¯¦æƒ…\n\n"

        # æŒ‰ä¸¥é‡æ€§åˆ†ç»„
        by_severity = {}
        for issue in self.issues_found:
            if issue.severity not in by_severity:
                by_severity[issue.severity] = []
            by_severity[issue.severity].append(issue)

        for severity in ["HIGH", "MEDIUM", "LOW"]:
            if severity in by_severity:
                report += f"### {severity} ä¸¥é‡æ€§\n\n"
                for issue in by_severity[severity]:
                    report += f"**æ–‡ä»¶**: `{issue.file_path}:{issue.line_number}`\n"
                    report += f"**ç±»å‹**: {issue.issue_type}\n"
                    report += f"**åŸå§‹å¯¼å…¥**: `{issue.original_import}`\n"
                    report += f"**ä¿®å¤å»ºè®®**: {issue.suggested_fix}\n\n"

        report += """
## ğŸ› ï¸ ä¿®å¤æ­¥éª¤

### 1. è‡ªåŠ¨ä¿®å¤
```bash
# å®‰è£…å·¥å…·
pip install isort autoflake black

# ä¼˜åŒ–å¯¼å…¥é¡ºåº
isort .

# ç§»é™¤æœªä½¿ç”¨å¯¼å…¥
autoflake --in-place --remove-all-unused-imports --recursive .

# æ ¼å¼åŒ–ä»£ç 
black .
```

### 2. æ‰‹åŠ¨ä¿®å¤
1. æ›¿æ¢æ‰€æœ‰é€šé…ç¬¦å¯¼å…¥ä¸ºå…·ä½“å¯¼å…¥
2. å°†é•¿å¯¼å…¥è¯­å¥åˆ†è¡Œ
3. åˆ†ç¦»å¤šä¸ªæ¨¡å—çš„å¯¼å…¥è¯­å¥

### 3. é…ç½®å·¥å…·
1. é…ç½®isortå’Œautoflake
2. åœ¨IDEä¸­å¯ç”¨å¯¼å…¥ä¼˜åŒ–
3. åœ¨CI/CDä¸­æ·»åŠ å¯¼å…¥æ£€æŸ¥

## ğŸ“‹ å¯¼å…¥è§„èŒƒ

è¯·å‚è€ƒ `docs/development/import_guidelines.md` äº†è§£è¯¦ç»†çš„å¯¼å…¥è§„èŒƒã€‚

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **é€šé…ç¬¦å¯¼å…¥**å¯èƒ½å¯¼è‡´å‘½åå†²çªå’Œéš¾ä»¥è¿½è¸ªçš„bug
2. **æœªä½¿ç”¨çš„å¯¼å…¥**ä¼šå¢åŠ ä»£ç å¤æ‚åº¦å’ŒåŠ è½½æ—¶é—´
3. **ä¸è§„èŒƒçš„å¯¼å…¥é¡ºåº**ä¼šå½±å“ä»£ç å¯è¯»æ€§
4. **å¾ªç¯å¯¼å…¥**ä¼šå¯¼è‡´è¿è¡Œæ—¶é”™è¯¯
"""

        return report


def main():
    """ä¸»å‡½æ•°"""
    project_root = os.getcwd()
    print("ğŸ“¦ ç´¢å…‹ç”Ÿæ´»é¡¹ç›® - å¯¼å…¥è¯­å¥ä¼˜åŒ–å·¥å…·")
    print("=" * 60)

    optimizer = ImportOptimizer(project_root)

    # 1. æ‰«æå¯¼å…¥é—®é¢˜
    issues = optimizer.scan_import_issues()

    # 2. è‡ªåŠ¨ä¼˜åŒ–å¯¼å…¥ï¼ˆå¦‚æœå·¥å…·å¯ç”¨ï¼‰
    isort_success = optimizer.optimize_imports_with_isort()
    autoflake_success = optimizer.remove_unused_imports()

    # 3. åˆ›å»ºå¯¼å…¥è§„èŒƒæŒ‡å—
    guidelines_file = optimizer.create_import_guidelines()
    print(f"âœ… å·²åˆ›å»ºå¯¼å…¥è§„èŒƒæŒ‡å—: {guidelines_file}")

    # 4. ç”ŸæˆæŠ¥å‘Š
    report = optimizer.generate_report()

    # ä¿å­˜æŠ¥å‘Š
    report_file = Path(project_root) / "import_optimization_report.md"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"ğŸ“Š ä¼˜åŒ–æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

    if issues:
        print(f"\nâš ï¸  å‘ç° {len(issues)} ä¸ªå¯¼å…¥é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æŠ¥å‘Šè¯¦æƒ…")
    else:
        print("\nâœ… æœªå‘ç°å¯¼å…¥é—®é¢˜")

    if isort_success:
        print("âœ… isortå¯¼å…¥æ’åºå®Œæˆ")

    if autoflake_success:
        print("âœ… æœªä½¿ç”¨å¯¼å…¥ç§»é™¤å®Œæˆ")


if __name__ == "__main__":
    main()
