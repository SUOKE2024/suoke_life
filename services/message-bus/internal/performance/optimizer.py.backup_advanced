"""
optimizer - 索克生活项目模块
"""

from collections import defaultdict, deque
from concurrent.futures import ThreadPoolExecutor
from dataclasses import dataclass
from internal.observability.metrics import MetricsService
from typing import Dict, Any, Optional, Callable, List
import asyncio
import gc
import psutil
import threading
import time

"""
性能优化模块
"""




@dataclass
class PerformanceMetrics:
    """性能指标数据类"""
    cpu_usage: float
    memory_usage: float
    memory_available: float
    active_connections: int
    message_throughput: float
    latency_p95: float
    latency_p99: float
    error_rate: float
    timestamp: float


class MemoryManager:
    """内存管理器"""

    def __init__(self, max_memory_mb: int = 1024):
        """TODO: 添加文档字符串"""
        self.max_memory_mb = max_memory_mb
        self.memory_threshold = 0.8  # 80%阈值
        self.gc_interval = 30  # 30秒GC间隔
        self.last_gc_time = time.time()

    def check_memory_usage(self) - > float:
        """检查内存使用率"""
        process = psutil.Process()
        memory_info = process.memory_info()
        memory_mb = memory_info.rss / 1024 / 1024
        usage_ratio = memory_mb / self.max_memory_mb
        return usage_ratio

    def should_trigger_gc(self) - > bool:
        """判断是否应该触发垃圾回收"""
        current_time = time.time()
        memory_usage = self.check_memory_usage()

        # 内存使用超过阈值或距离上次GC超过间隔时间
        return (
            memory_usage > self.memory_threshold or
            current_time - self.last_gc_time > self.gc_interval
        )

    def force_gc(self) - > None:
        """强制垃圾回收"""
        collected = gc.collect()
        self.last_gc_time = time.time()
        return collected

    async def monitor_memory(self) - > None:
        """监控内存使用"""
        while True:
            if self.should_trigger_gc():
                collected = self.force_gc()
                print(f"GC triggered, collected {collected} objects")

            await asyncio.sleep(10)  # 每10秒检查一次


class ConnectionPool:
    """连接池管理器"""

    def __init__(self, max_connections: int = 100):
        """TODO: 添加文档字符串"""
        self.max_connections = max_connections
        self.active_connections = 0
        self.connection_queue = asyncio.Queue(maxsize = max_connections)
        self.connection_stats = defaultdict(int)

    async def acquire_connection(self) - > bool:
        """获取连接"""
        if self.active_connections > = self.max_connections:
            return False

        self.active_connections + = 1
        self.connection_stats['acquired'] + = 1
        return True

    async def release_connection(self) - > None:
        """释放连接"""
        if self.active_connections > 0:
            self.active_connections - = 1
            self.connection_stats['released'] + = 1

    def get_stats(self) - > Dict[str, int]:
        """获取连接统计"""
        return {
            'active': self.active_connections,
            'max': self.max_connections,
            'acquired': self.connection_stats['acquired'],
            'released': self.connection_stats['released']
        }


class MessageBatcher:
    """消息批处理器"""

    def __init__(
        self,
        batch_size: int = 100,
        batch_timeout: float = 1.0,
        processor: Optional[Callable] = None
    ):
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.processor = processor
        self.current_batch = []
        self.last_batch_time = time.time()
        self.batch_lock = asyncio.Lock()

    async def add_message(self, message: Any):
        """添加消息到批次"""
        async with self.batch_lock:
            self.current_batch.append(message)

            # 检查是否需要处理批次
            if (len(self.current_batch) > = self.batch_size or
                time.time() - self.last_batch_time > = self.batch_timeout):
                await self._process_batch()

    async def _process_batch(self) - > None:
        """处理当前批次"""
        if not self.current_batch:
            return

        batch_to_process = self.current_batch.copy()
        self.current_batch.clear()
        self.last_batch_time = time.time()

        if self.processor:
            try:
                await self.processor(batch_to_process)
            except Exception as e:
                print(f"Batch processing error: {e}")

    async def flush(self) - > None:
        """强制处理当前批次"""
        async with self.batch_lock:
            await self._process_batch()


class LatencyTracker:
    """延迟跟踪器"""

    def __init__(self, window_size: int = 1000):
        """TODO: 添加文档字符串"""
        self.window_size = window_size
        self.latencies = deque(maxlen = window_size)
        self.lock = threading.Lock()

    def record_latency(self, latency: float):
        """记录延迟"""
        with self.lock:
            self.latencies.append(latency)

    def get_percentiles(self) - > Dict[str, float]:
        """获取延迟百分位数"""
        with self.lock:
            if not self.latencies:
                return {'p50': 0, 'p95': 0, 'p99': 0}

            sorted_latencies = sorted(self.latencies)
            length = len(sorted_latencies)

            return {
                'p50': sorted_latencies[int(length * 0.5)],
                'p95': sorted_latencies[int(length * 0.95)],
                'p99': sorted_latencies[int(length * 0.99)]
            }

    def get_average(self) - > float:
        """获取平均延迟"""
        with self.lock:
            if not self.latencies:
                return 0
            return sum(self.latencies) / len(self.latencies)


class ThroughputCounter:
    """吞吐量计数器"""

    def __init__(self, window_seconds: int = 60):
        """TODO: 添加文档字符串"""
        self.window_seconds = window_seconds
        self.timestamps = deque()
        self.lock = threading.Lock()

    def increment(self) - > None:
        """增加计数"""
        current_time = time.time()
        with self.lock:
            self.timestamps.append(current_time)
            self._cleanup_old_timestamps(current_time)

    def _cleanup_old_timestamps(self, current_time: float):
        """清理过期的时间戳"""
        cutoff_time = current_time - self.window_seconds
        while self.timestamps and self.timestamps[0] < cutoff_time:
            self.timestamps.popleft()

    def get_rate(self) - > float:
        """获取当前速率（每秒）"""
        current_time = time.time()
        with self.lock:
            self._cleanup_old_timestamps(current_time)
            return len(self.timestamps) / self.window_seconds


class PerformanceOptimizer:
    """性能优化器"""

    def __init__(self, metrics_service: MetricsService):
        """TODO: 添加文档字符串"""
        self.metrics_service = metrics_service
        self.memory_manager = MemoryManager()
        self.connection_pool = ConnectionPool()
        self.latency_tracker = LatencyTracker()
        self.throughput_counter = ThroughputCounter()

        # 性能阈值
        self.cpu_threshold = 80.0  # CPU使用率阈值
        self.memory_threshold = 85.0  # 内存使用率阈值
        self.latency_threshold = 1000.0  # 延迟阈值(ms)

        # 优化策略
        self.optimization_strategies = {
            'high_cpu': self._handle_high_cpu,
            'high_memory': self._handle_high_memory,
            'high_latency': self._handle_high_latency,
            'low_throughput': self._handle_low_throughput
        }

        self.executor = ThreadPoolExecutor(max_workers = 4)
        self.running = False

    async def start_monitoring(self) - > None:
        """开始性能监控"""
        self.running = True

        # 启动各种监控任务
        tasks = [
            asyncio.create_task(self._monitor_performance()),
            asyncio.create_task(self.memory_manager.monitor_memory()),
            asyncio.create_task(self._auto_optimize())
        ]

        await asyncio.gather( * tasks)

    async def stop_monitoring(self) - > None:
        """停止性能监控"""
        self.running = False
        self.executor.shutdown(wait = True)

    async def _monitor_performance(self) - > None:
        """监控性能指标"""
        while self.running:
            try:
                metrics = await self._collect_metrics()
                await self._analyze_performance(metrics)
                await asyncio.sleep(10)  # 每10秒收集一次
            except Exception as e:
                print(f"Performance monitoring error: {e}")
                await asyncio.sleep(5)

    async def _collect_metrics(self) - > PerformanceMetrics:
        """收集性能指标"""
        # CPU使用率
        cpu_usage = psutil.cpu_percent(interval = 1)

        # 内存使用情况
        memory = psutil.virtual_memory()
        memory_usage = memory.percent
        memory_available = memory.available / 1024 / 1024  # MB

        # 连接统计
        connection_stats = self.connection_pool.get_stats()
        active_connections = connection_stats['active']

        # 吞吐量
        message_throughput = self.throughput_counter.get_rate()

        # 延迟统计
        latency_stats = self.latency_tracker.get_percentiles()

        return PerformanceMetrics(
            cpu_usage = cpu_usage,
            memory_usage = memory_usage,
            memory_available = memory_available,
            active_connections = active_connections,
            message_throughput = message_throughput,
            latency_p95 = latency_stats['p95'],
            latency_p99 = latency_stats['p99'],
            error_rate = 0.0,  # 需要从错误计数器获取
            timestamp = time.time()
        )

    async def _analyze_performance(self, metrics: PerformanceMetrics):
        """分析性能指标并触发优化"""
        issues = []

        if metrics.cpu_usage > self.cpu_threshold:
            issues.append('high_cpu')

        if metrics.memory_usage > self.memory_threshold:
            issues.append('high_memory')

        if metrics.latency_p95 > self.latency_threshold:
            issues.append('high_latency')

        if metrics.message_throughput < 10:  # 低于10 msg / s
            issues.append('low_throughput')

        # 触发相应的优化策略
        for issue in issues:
            if issue in self.optimization_strategies:
                await self.optimization_strategies[issue](metrics)

    async def _auto_optimize(self) - > None:
        """自动优化"""
        while self.running:
            try:
                # 定期执行优化任务
                await self._optimize_memory()
                await self._optimize_connections()
                await asyncio.sleep(60)  # 每分钟执行一次
            except Exception as e:
                print(f"Auto optimization error: {e}")
                await asyncio.sleep(30)

    async def _handle_high_cpu(self, metrics: PerformanceMetrics):
        """处理高CPU使用率"""
        print(f"High CPU usage detected: {metrics.cpu_usage}%")

        # 减少并发处理
        # 增加批处理大小
        # 启用CPU亲和性

    async def _handle_high_memory(self, metrics: PerformanceMetrics):
        """处理高内存使用率"""
        print(f"High memory usage detected: {metrics.memory_usage}%")

        # 强制垃圾回收
        collected = self.memory_manager.force_gc()
        print(f"Forced GC, collected {collected} objects")

        # 清理缓存
        # 减少缓冲区大小

    async def _handle_high_latency(self, metrics: PerformanceMetrics):
        """处理高延迟"""
        print(f"High latency detected: P95 = {metrics.latency_p95}ms")

        # 增加连接池大小
        # 启用消息压缩
        # 优化序列化

    async def _handle_low_throughput(self, metrics: PerformanceMetrics):
        """处理低吞吐量"""
        print(f"Low throughput detected: {metrics.message_throughput} msg / s")

        # 增加并发度
        # 优化批处理
        # 检查网络连接

    async def _optimize_memory(self) - > None:
        """优化内存使用"""
        if self.memory_manager.should_trigger_gc():
            self.memory_manager.force_gc()

    async def _optimize_connections(self) - > None:
        """优化连接管理"""
        stats = self.connection_pool.get_stats()
        if stats['active'] > stats['max'] * 0.9:
            print("Connection pool near capacity, consider scaling")

    def record_message_processed(self) - > None:
        """记录消息处理"""
        self.throughput_counter.increment()

    def record_latency(self, latency_ms: float):
        """记录延迟"""
        self.latency_tracker.record_latency(latency_ms)

    async def get_performance_summary(self) - > Dict[str, Any]:
        """获取性能摘要"""
        metrics = await self._collect_metrics()
        latency_stats = self.latency_tracker.get_percentiles()
        connection_stats = self.connection_pool.get_stats()

        return {
            'cpu_usage': metrics.cpu_usage,
            'memory_usage': metrics.memory_usage,
            'memory_available_mb': metrics.memory_available,
            'throughput_msg_per_sec': metrics.message_throughput,
            'latency': latency_stats,
            'connections': connection_stats,
            'timestamp': metrics.timestamp
        }