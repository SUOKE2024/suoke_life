#!/usr/bin/env python

"""
æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–å·¥å…·
æä¾›ç³»ç»Ÿæ€§èƒ½ç›‘æ§ã€åˆ†æå’Œä¼˜åŒ–å»ºè®®

åŠŸèƒ½ç‰¹æ€§ï¼š
- å®æ—¶æ€§èƒ½ç›‘æ§
- å†…å­˜ä½¿ç”¨åˆ†æ
- CPUä½¿ç”¨ç‡ç›‘æ§
- ç£ç›˜I/Oç›‘æ§
- ç½‘ç»œæ€§èƒ½ç›‘æ§
- æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
- ä¼˜åŒ–å»ºè®®ç”Ÿæˆ
"""

import asyncio
import json
import logging
import os
import time
from collections import defaultdict, deque
from dataclasses import asdict, dataclass
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import psutil

logger = logging.getLogger(__name__)


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç±»"""

    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    memory_available_mb: float
    disk_read_mb: float
    disk_write_mb: float
    network_sent_mb: float
    network_recv_mb: float
    process_count: int
    thread_count: int
    load_average: Tuple[float, float, float]

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)


@dataclass
class PerformanceAlert:
    """æ€§èƒ½å‘Šè­¦æ•°æ®ç±»"""

    timestamp: float
    level: str  # INFO, WARNING, CRITICAL
    category: str  # CPU, MEMORY, DISK, NETWORK
    message: str
    value: float
    threshold: float
    suggestion: str


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(
        self,
        collection_interval: float = 1.0,
        history_size: int = 3600,
        alert_thresholds: Optional[Dict[str, float]] = None,
    ):
        """
        åˆå§‹åŒ–æ€§èƒ½ç›‘æ§å™¨

        Args:
            collection_interval: æ•°æ®æ”¶é›†é—´éš”(ç§’)
            history_size: å†å²æ•°æ®ä¿å­˜æ•°é‡
            alert_thresholds: å‘Šè­¦é˜ˆå€¼é…ç½®
        """
        self.collection_interval = collection_interval
        self.history_size = history_size

        # é»˜è®¤å‘Šè­¦é˜ˆå€¼
        self.alert_thresholds = alert_thresholds or {
            "cpu_percent": 80.0,
            "memory_percent": 85.0,
            "disk_read_mb": 100.0,
            "disk_write_mb": 100.0,
            "network_sent_mb": 50.0,
            "network_recv_mb": 50.0,
        }

        # æ•°æ®å­˜å‚¨
        self.metrics_history: deque = deque(maxlen=history_size)
        self.alerts_history: deque = deque(maxlen=1000)

        # ç›‘æ§çŠ¶æ€
        self.is_monitoring = False
        self.monitor_task: Optional[asyncio.Task] = None

        # æ€§èƒ½ç»Ÿè®¡
        self.stats = {
            "total_samples": 0,
            "alerts_count": defaultdict(int),
            "peak_values": {},
            "average_values": {},
        }

        # åˆå§‹åŒ–ç½‘ç»œå’Œç£ç›˜è®¡æ•°å™¨
        self._last_network_io = psutil.net_io_counters()
        self._last_disk_io = psutil.disk_io_counters()
        self._last_timestamp = time.time()

    async def start_monitoring(self) -> None:
        """å¼€å§‹ç›‘æ§"""
        if self.is_monitoring:
            logger.warning("æ€§èƒ½ç›‘æ§å·²åœ¨è¿è¡Œ")
            return

        self.is_monitoring = True
        self.monitor_task = asyncio.create_task(self._monitoring_loop())
        logger.info("æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")

    async def stop_monitoring(self) -> None:
        """åœæ­¢ç›‘æ§"""
        if not self.is_monitoring:
            return

        self.is_monitoring = False
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass

        logger.info("æ€§èƒ½ç›‘æ§å·²åœæ­¢")

    async def _monitoring_loop(self) -> None:
        """ç›‘æ§å¾ªç¯"""
        try:
            while self.is_monitoring:
                metrics = await self._collect_metrics()
                self.metrics_history.append(metrics)

                # æ£€æŸ¥å‘Šè­¦
                alerts = self._check_alerts(metrics)
                for alert in alerts:
                    self.alerts_history.append(alert)
                    logger.warning(f"æ€§èƒ½å‘Šè­¦: {alert.message}")

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                self._update_stats(metrics)

                await asyncio.sleep(self.collection_interval)

        except asyncio.CancelledError:
            logger.info("ç›‘æ§å¾ªç¯å·²å–æ¶ˆ")
        except Exception as e:
            logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")

    async def _collect_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        current_time = time.time()

        # CPUå’Œå†…å­˜
        cpu_percent = psutil.cpu_percent(interval=None)
        memory = psutil.virtual_memory()

        # ç£ç›˜I/O
        current_disk_io = psutil.disk_io_counters()
        disk_read_mb = 0.0
        disk_write_mb = 0.0

        if self._last_disk_io and current_disk_io:
            time_delta = current_time - self._last_timestamp
            if time_delta > 0:
                disk_read_mb = (
                    (current_disk_io.read_bytes - self._last_disk_io.read_bytes)
                    / (1024 * 1024)
                    / time_delta
                )
                disk_write_mb = (
                    (current_disk_io.write_bytes - self._last_disk_io.write_bytes)
                    / (1024 * 1024)
                    / time_delta
                )

        # ç½‘ç»œI/O
        current_network_io = psutil.net_io_counters()
        network_sent_mb = 0.0
        network_recv_mb = 0.0

        if self._last_network_io and current_network_io:
            time_delta = current_time - self._last_timestamp
            if time_delta > 0:
                network_sent_mb = (
                    (current_network_io.bytes_sent - self._last_network_io.bytes_sent)
                    / (1024 * 1024)
                    / time_delta
                )
                network_recv_mb = (
                    (current_network_io.bytes_recv - self._last_network_io.bytes_recv)
                    / (1024 * 1024)
                    / time_delta
                )

        # è¿›ç¨‹å’Œçº¿ç¨‹æ•°
        process_count = len(psutil.pids())
        thread_count = sum(
            p.num_threads()
            for p in psutil.process_iter(["num_threads"])
            if p.info["num_threads"]
        )

        # è´Ÿè½½å¹³å‡å€¼
        try:
            load_average = os.getloadavg()
        except (OSError, AttributeError):
            load_average = (0.0, 0.0, 0.0)

        # æ›´æ–°ä¸Šæ¬¡è®°å½•
        self._last_disk_io = current_disk_io
        self._last_network_io = current_network_io
        self._last_timestamp = current_time

        return PerformanceMetrics(
            timestamp=current_time,
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            memory_used_mb=memory.used / (1024 * 1024),
            memory_available_mb=memory.available / (1024 * 1024),
            disk_read_mb=disk_read_mb,
            disk_write_mb=disk_write_mb,
            network_sent_mb=network_sent_mb,
            network_recv_mb=network_recv_mb,
            process_count=process_count,
            thread_count=thread_count,
            load_average=load_average,
        )

    def _check_alerts(self, metrics: PerformanceMetrics) -> List[PerformanceAlert]:
        """æ£€æŸ¥å‘Šè­¦æ¡ä»¶"""
        alerts = []

        # CPUå‘Šè­¦
        if metrics.cpu_percent > self.alert_thresholds["cpu_percent"]:
            alerts.append(
                PerformanceAlert(
                    timestamp=metrics.timestamp,
                    level="WARNING" if metrics.cpu_percent < 90 else "CRITICAL",
                    category="CPU",
                    message=f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics.cpu_percent:.1f}%",
                    value=metrics.cpu_percent,
                    threshold=self.alert_thresholds["cpu_percent"],
                    suggestion="è€ƒè™‘ä¼˜åŒ–CPUå¯†é›†å‹ä»»åŠ¡æˆ–å¢åŠ CPUèµ„æº",
                )
            )

        # å†…å­˜å‘Šè­¦
        if metrics.memory_percent > self.alert_thresholds["memory_percent"]:
            alerts.append(
                PerformanceAlert(
                    timestamp=metrics.timestamp,
                    level="WARNING" if metrics.memory_percent < 95 else "CRITICAL",
                    category="MEMORY",
                    message=f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.memory_percent:.1f}%",
                    value=metrics.memory_percent,
                    threshold=self.alert_thresholds["memory_percent"],
                    suggestion="è€ƒè™‘é‡Šæ”¾å†…å­˜æˆ–å¢åŠ å†…å­˜èµ„æº",
                )
            )

        # ç£ç›˜I/Oå‘Šè­¦
        if metrics.disk_read_mb > self.alert_thresholds["disk_read_mb"]:
            alerts.append(
                PerformanceAlert(
                    timestamp=metrics.timestamp,
                    level="WARNING",
                    category="DISK",
                    message=f"ç£ç›˜è¯»å–é€Ÿåº¦è¿‡é«˜: {metrics.disk_read_mb:.1f} MB/s",
                    value=metrics.disk_read_mb,
                    threshold=self.alert_thresholds["disk_read_mb"],
                    suggestion="æ£€æŸ¥ç£ç›˜I/Oå¯†é›†å‹æ“ä½œ",
                )
            )

        if metrics.disk_write_mb > self.alert_thresholds["disk_write_mb"]:
            alerts.append(
                PerformanceAlert(
                    timestamp=metrics.timestamp,
                    level="WARNING",
                    category="DISK",
                    message=f"ç£ç›˜å†™å…¥é€Ÿåº¦è¿‡é«˜: {metrics.disk_write_mb:.1f} MB/s",
                    value=metrics.disk_write_mb,
                    threshold=self.alert_thresholds["disk_write_mb"],
                    suggestion="æ£€æŸ¥ç£ç›˜I/Oå¯†é›†å‹æ“ä½œ",
                )
            )

        # ç½‘ç»œI/Oå‘Šè­¦
        if metrics.network_sent_mb > self.alert_thresholds["network_sent_mb"]:
            alerts.append(
                PerformanceAlert(
                    timestamp=metrics.timestamp,
                    level="WARNING",
                    category="NETWORK",
                    message=f"ç½‘ç»œå‘é€é€Ÿåº¦è¿‡é«˜: {metrics.network_sent_mb:.1f} MB/s",
                    value=metrics.network_sent_mb,
                    threshold=self.alert_thresholds["network_sent_mb"],
                    suggestion="æ£€æŸ¥ç½‘ç»œå¯†é›†å‹æ“ä½œ",
                )
            )

        if metrics.network_recv_mb > self.alert_thresholds["network_recv_mb"]:
            alerts.append(
                PerformanceAlert(
                    timestamp=metrics.timestamp,
                    level="WARNING",
                    category="NETWORK",
                    message=f"ç½‘ç»œæ¥æ”¶é€Ÿåº¦è¿‡é«˜: {metrics.network_recv_mb:.1f} MB/s",
                    value=metrics.network_recv_mb,
                    threshold=self.alert_thresholds["network_recv_mb"],
                    suggestion="æ£€æŸ¥ç½‘ç»œå¯†é›†å‹æ“ä½œ",
                )
            )

        return alerts

    def _update_stats(self, metrics: PerformanceMetrics) -> None:
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats["total_samples"] += 1

        # æ›´æ–°å³°å€¼
        metrics_dict = metrics.to_dict()
        for key, value in metrics_dict.items():
            if isinstance(value, (int, float)) and key != "timestamp":
                if key not in self.stats["peak_values"]:
                    self.stats["peak_values"][key] = value
                else:
                    self.stats["peak_values"][key] = max(
                        self.stats["peak_values"][key], value
                    )

    def get_current_metrics(self) -> Optional[PerformanceMetrics]:
        """è·å–å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        if self.metrics_history:
            return self.metrics_history[-1]
        return None

    def get_metrics_history(
        self, duration_minutes: int = 60
    ) -> List[PerformanceMetrics]:
        """è·å–å†å²æ€§èƒ½æŒ‡æ ‡"""
        if not self.metrics_history:
            return []

        cutoff_time = time.time() - (duration_minutes * 60)
        return [m for m in self.metrics_history if m.timestamp >= cutoff_time]

    def get_alerts_history(self, duration_minutes: int = 60) -> List[PerformanceAlert]:
        """è·å–å†å²å‘Šè­¦"""
        if not self.alerts_history:
            return []

        cutoff_time = time.time() - (duration_minutes * 60)
        return [a for a in self.alerts_history if a.timestamp >= cutoff_time]

    def generate_performance_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not self.metrics_history:
            return {"error": "æ²¡æœ‰æ€§èƒ½æ•°æ®"}

        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        recent_metrics = self.get_metrics_history(60)  # æœ€è¿‘1å°æ—¶
        if not recent_metrics:
            return {"error": "æ²¡æœ‰æœ€è¿‘çš„æ€§èƒ½æ•°æ®"}

        # è½¬æ¢ä¸ºDataFrameè¿›è¡Œåˆ†æ
        df = pd.DataFrame([m.to_dict() for m in recent_metrics])

        report = {
            "summary": {
                "total_samples": len(recent_metrics),
                "time_range": {
                    "start": datetime.fromtimestamp(df["timestamp"].min()).isoformat(),
                    "end": datetime.fromtimestamp(df["timestamp"].max()).isoformat(),
                },
            },
            "cpu": {
                "average": float(df["cpu_percent"].mean()),
                "peak": float(df["cpu_percent"].max()),
                "min": float(df["cpu_percent"].min()),
                "std": float(df["cpu_percent"].std()),
            },
            "memory": {
                "average_percent": float(df["memory_percent"].mean()),
                "peak_percent": float(df["memory_percent"].max()),
                "average_used_mb": float(df["memory_used_mb"].mean()),
                "peak_used_mb": float(df["memory_used_mb"].max()),
            },
            "disk_io": {
                "average_read_mb": float(df["disk_read_mb"].mean()),
                "peak_read_mb": float(df["disk_read_mb"].max()),
                "average_write_mb": float(df["disk_write_mb"].mean()),
                "peak_write_mb": float(df["disk_write_mb"].max()),
            },
            "network_io": {
                "average_sent_mb": float(df["network_sent_mb"].mean()),
                "peak_sent_mb": float(df["network_sent_mb"].max()),
                "average_recv_mb": float(df["network_recv_mb"].mean()),
                "peak_recv_mb": float(df["network_recv_mb"].max()),
            },
            "alerts": {
                "total_count": len(self.get_alerts_history(60)),
                "by_category": dict(self.stats["alerts_count"]),
            },
            "recommendations": self._generate_recommendations(df),
        }

        return report

    def _generate_recommendations(self, df: pd.DataFrame) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # CPUä¼˜åŒ–å»ºè®®
        avg_cpu = df["cpu_percent"].mean()
        if avg_cpu > 70:
            recommendations.append(
                "CPUä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–CPUå¯†é›†å‹ä»»åŠ¡æˆ–è€ƒè™‘å¢åŠ CPUèµ„æº"
            )
        elif avg_cpu < 20:
            recommendations.append("CPUä½¿ç”¨ç‡è¾ƒä½ï¼Œå¯ä»¥è€ƒè™‘å¢åŠ å¹¶å‘å¤„ç†èƒ½åŠ›")

        # å†…å­˜ä¼˜åŒ–å»ºè®®
        avg_memory = df["memory_percent"].mean()
        if avg_memory > 80:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼æˆ–å¢åŠ å†…å­˜èµ„æº")

        # ç£ç›˜I/Oä¼˜åŒ–å»ºè®®
        avg_disk_read = df["disk_read_mb"].mean()
        avg_disk_write = df["disk_write_mb"].mean()
        if avg_disk_read > 50 or avg_disk_write > 50:
            recommendations.append("ç£ç›˜I/Oè¾ƒé«˜ï¼Œå»ºè®®ä½¿ç”¨ç¼“å­˜æˆ–ä¼˜åŒ–æ•°æ®è®¿é—®æ¨¡å¼")

        # ç½‘ç»œI/Oä¼˜åŒ–å»ºè®®
        avg_network_sent = df["network_sent_mb"].mean()
        avg_network_recv = df["network_recv_mb"].mean()
        if avg_network_sent > 20 or avg_network_recv > 20:
            recommendations.append("ç½‘ç»œI/Oè¾ƒé«˜ï¼Œå»ºè®®ä¼˜åŒ–ç½‘ç»œè¯·æ±‚æˆ–ä½¿ç”¨è¿æ¥æ± ")

        if not recommendations:
            recommendations.append("ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")

        return recommendations

    def export_metrics(self, filepath: str, format: str = "json") -> None:
        """å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡"""
        if not self.metrics_history:
            logger.warning("æ²¡æœ‰æ€§èƒ½æ•°æ®å¯å¯¼å‡º")
            return

        data = [m.to_dict() for m in self.metrics_history]

        if format.lower() == "json":
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        elif format.lower() == "csv":
            df = pd.DataFrame(data)
            df.to_csv(filepath, index=False)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")

        logger.info(f"æ€§èƒ½æ•°æ®å·²å¯¼å‡ºåˆ°: {filepath}")

    def create_performance_charts(self, output_dir: str) -> None:
        """åˆ›å»ºæ€§èƒ½å›¾è¡¨"""
        if not self.metrics_history:
            logger.warning("æ²¡æœ‰æ€§èƒ½æ•°æ®å¯ç»˜åˆ¶")
            return

        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame([m.to_dict() for m in self.metrics_history])
        df["datetime"] = pd.to_datetime(df["timestamp"], unit="s")

        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle("ç³»ç»Ÿæ€§èƒ½ç›‘æ§å›¾è¡¨", fontsize=16)

        # CPUä½¿ç”¨ç‡
        axes[0, 0].plot(df["datetime"], df["cpu_percent"], "b-", linewidth=1)
        axes[0, 0].set_title("CPUä½¿ç”¨ç‡ (%)")
        axes[0, 0].set_ylabel("ç™¾åˆ†æ¯”")
        axes[0, 0].grid(True, alpha=0.3)
        axes[0, 0].axhline(
            y=self.alert_thresholds["cpu_percent"], color="r", linestyle="--", alpha=0.7
        )

        # å†…å­˜ä½¿ç”¨ç‡
        axes[0, 1].plot(df["datetime"], df["memory_percent"], "g-", linewidth=1)
        axes[0, 1].set_title("å†…å­˜ä½¿ç”¨ç‡ (%)")
        axes[0, 1].set_ylabel("ç™¾åˆ†æ¯”")
        axes[0, 1].grid(True, alpha=0.3)
        axes[0, 1].axhline(
            y=self.alert_thresholds["memory_percent"],
            color="r",
            linestyle="--",
            alpha=0.7,
        )

        # ç£ç›˜I/O
        axes[1, 0].plot(
            df["datetime"], df["disk_read_mb"], "r-", linewidth=1, label="è¯»å–"
        )
        axes[1, 0].plot(
            df["datetime"], df["disk_write_mb"], "orange", linewidth=1, label="å†™å…¥"
        )
        axes[1, 0].set_title("ç£ç›˜I/O (MB/s)")
        axes[1, 0].set_ylabel("MB/s")
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)

        # ç½‘ç»œI/O
        axes[1, 1].plot(
            df["datetime"], df["network_sent_mb"], "purple", linewidth=1, label="å‘é€"
        )
        axes[1, 1].plot(
            df["datetime"], df["network_recv_mb"], "brown", linewidth=1, label="æ¥æ”¶"
        )
        axes[1, 1].set_title("ç½‘ç»œI/O (MB/s)")
        axes[1, 1].set_ylabel("MB/s")
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()

        # ä¿å­˜å›¾è¡¨
        chart_path = output_path / "performance_charts.png"
        plt.savefig(chart_path, dpi=300, bbox_inches="tight")
        plt.close()

        logger.info(f"æ€§èƒ½å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_path}")


class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""

    def __init__(self, monitor: PerformanceMonitor):
        self.monitor = monitor

    def analyze_performance_bottlenecks(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        report = self.monitor.generate_performance_report()
        if "error" in report:
            return report

        bottlenecks = {
            "cpu_bottlenecks": [],
            "memory_bottlenecks": [],
            "disk_bottlenecks": [],
            "network_bottlenecks": [],
            "overall_score": 0,
        }

        # CPUç“¶é¢ˆåˆ†æ
        cpu_avg = report["cpu"]["average"]
        cpu_peak = report["cpu"]["peak"]

        if cpu_avg > 80:
            bottlenecks["cpu_bottlenecks"].append(
                {
                    "severity": "high",
                    "issue": f"CPUå¹³å‡ä½¿ç”¨ç‡è¿‡é«˜: {cpu_avg:.1f}%",
                    "suggestion": "è€ƒè™‘ä¼˜åŒ–ç®—æ³•ã€ä½¿ç”¨å¼‚æ­¥å¤„ç†æˆ–å¢åŠ CPUèµ„æº",
                }
            )
        elif cpu_peak > 95:
            bottlenecks["cpu_bottlenecks"].append(
                {
                    "severity": "medium",
                    "issue": f"CPUå³°å€¼ä½¿ç”¨ç‡è¿‡é«˜: {cpu_peak:.1f}%",
                    "suggestion": "æ£€æŸ¥CPUå¯†é›†å‹ä»»åŠ¡çš„è°ƒåº¦",
                }
            )

        # å†…å­˜ç“¶é¢ˆåˆ†æ
        memory_avg = report["memory"]["average_percent"]
        memory_peak = report["memory"]["peak_percent"]

        if memory_avg > 85:
            bottlenecks["memory_bottlenecks"].append(
                {
                    "severity": "high",
                    "issue": f"å†…å­˜å¹³å‡ä½¿ç”¨ç‡è¿‡é«˜: {memory_avg:.1f}%",
                    "suggestion": "æ£€æŸ¥å†…å­˜æ³„æ¼ã€ä¼˜åŒ–æ•°æ®ç»“æ„æˆ–å¢åŠ å†…å­˜",
                }
            )
        elif memory_peak > 95:
            bottlenecks["memory_bottlenecks"].append(
                {
                    "severity": "medium",
                    "issue": f"å†…å­˜å³°å€¼ä½¿ç”¨ç‡è¿‡é«˜: {memory_peak:.1f}%",
                    "suggestion": "ä¼˜åŒ–å†…å­˜ä½¿ç”¨æ¨¡å¼",
                }
            )

        # ç£ç›˜I/Oç“¶é¢ˆåˆ†æ
        disk_read_avg = report["disk_io"]["average_read_mb"]
        disk_write_avg = report["disk_io"]["average_write_mb"]

        if disk_read_avg > 100 or disk_write_avg > 100:
            bottlenecks["disk_bottlenecks"].append(
                {
                    "severity": "medium",
                    "issue": f"ç£ç›˜I/Oè¾ƒé«˜ (è¯»: {disk_read_avg:.1f}, å†™: {disk_write_avg:.1f} MB/s)",
                    "suggestion": "ä½¿ç”¨ç¼“å­˜ã€æ‰¹é‡æ“ä½œæˆ–SSDå­˜å‚¨",
                }
            )

        # ç½‘ç»œI/Oç“¶é¢ˆåˆ†æ
        network_sent_avg = report["network_io"]["average_sent_mb"]
        network_recv_avg = report["network_io"]["average_recv_mb"]

        if network_sent_avg > 50 or network_recv_avg > 50:
            bottlenecks["network_bottlenecks"].append(
                {
                    "severity": "medium",
                    "issue": f"ç½‘ç»œI/Oè¾ƒé«˜ (å‘é€: {network_sent_avg:.1f}, æ¥æ”¶: {network_recv_avg:.1f} MB/s)",
                    "suggestion": "ä¼˜åŒ–ç½‘ç»œè¯·æ±‚ã€ä½¿ç”¨è¿æ¥æ± æˆ–CDN",
                }
            )

        # è®¡ç®—æ€»ä½“æ€§èƒ½è¯„åˆ† (0-100)
        cpu_score = max(0, 100 - cpu_avg)
        memory_score = max(0, 100 - memory_avg)
        disk_score = max(0, 100 - min(disk_read_avg + disk_write_avg, 100))
        network_score = max(0, 100 - min(network_sent_avg + network_recv_avg, 100))

        bottlenecks["overall_score"] = int(
            (cpu_score + memory_score + disk_score + network_score) / 4
        )

        return bottlenecks

    def generate_optimization_plan(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–è®¡åˆ’"""
        bottlenecks = self.analyze_performance_bottlenecks()

        if "error" in bottlenecks:
            return bottlenecks

        plan = {
            "priority_actions": [],
            "medium_term_actions": [],
            "long_term_actions": [],
            "estimated_impact": {},
        }

        # é«˜ä¼˜å…ˆçº§è¡ŒåŠ¨
        for category in ["cpu_bottlenecks", "memory_bottlenecks"]:
            for bottleneck in bottlenecks[category]:
                if bottleneck["severity"] == "high":
                    plan["priority_actions"].append(
                        {
                            "category": category.replace("_bottlenecks", ""),
                            "action": bottleneck["suggestion"],
                            "impact": "high",
                        }
                    )

        # ä¸­æœŸè¡ŒåŠ¨
        for category in ["disk_bottlenecks", "network_bottlenecks"]:
            for bottleneck in bottlenecks[category]:
                plan["medium_term_actions"].append(
                    {
                        "category": category.replace("_bottlenecks", ""),
                        "action": bottleneck["suggestion"],
                        "impact": "medium",
                    }
                )

        # é•¿æœŸè¡ŒåŠ¨
        if bottlenecks["overall_score"] < 70:
            plan["long_term_actions"].extend(
                [
                    {
                        "category": "architecture",
                        "action": "è€ƒè™‘å¾®æœåŠ¡æ¶æ„é‡æ„",
                        "impact": "high",
                    },
                    {
                        "category": "infrastructure",
                        "action": "è¯„ä¼°ç¡¬ä»¶å‡çº§éœ€æ±‚",
                        "impact": "high",
                    },
                ]
            )

        # é¢„ä¼°å½±å“
        plan["estimated_impact"] = {
            "performance_improvement": f"{min(30, 100 - bottlenecks['overall_score'])}%",
            "resource_savings": "10-25%",
            "response_time_improvement": "15-40%",
        }

        return plan


async def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ€§èƒ½ç›‘æ§åŠŸèƒ½"""
    print("ğŸš€ ç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡ - æ€§èƒ½ç›‘æ§å·¥å…·")
    print("=" * 50)

    # åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨
    monitor = PerformanceMonitor(
        collection_interval=1.0,
        history_size=3600,
    )

    # åˆ›å»ºæ€§èƒ½ä¼˜åŒ–å™¨
    optimizer = PerformanceOptimizer(monitor)

    try:
        # å¯åŠ¨ç›‘æ§
        await monitor.start_monitoring()

        # è¿è¡Œä¸€æ®µæ—¶é—´æ”¶é›†æ•°æ®
        print("ğŸ“Š å¼€å§‹æ”¶é›†æ€§èƒ½æ•°æ®...")
        await asyncio.sleep(10)

        # ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“ˆ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
        report = monitor.generate_performance_report()
        print(json.dumps(report, indent=2, ensure_ascii=False))

        # åˆ†æç“¶é¢ˆ
        print("\nğŸ” åˆ†ææ€§èƒ½ç“¶é¢ˆ...")
        bottlenecks = optimizer.analyze_performance_bottlenecks()
        print(json.dumps(bottlenecks, indent=2, ensure_ascii=False))

        # ç”Ÿæˆä¼˜åŒ–è®¡åˆ’
        print("\nğŸ’¡ ç”Ÿæˆä¼˜åŒ–è®¡åˆ’...")
        plan = optimizer.generate_optimization_plan()
        print(json.dumps(plan, indent=2, ensure_ascii=False))

        # å¯¼å‡ºæ•°æ®
        print("\nğŸ’¾ å¯¼å‡ºæ€§èƒ½æ•°æ®...")
        monitor.export_metrics("performance_data.json")

        # åˆ›å»ºå›¾è¡¨
        print("\nğŸ“Š åˆ›å»ºæ€§èƒ½å›¾è¡¨...")
        monitor.create_performance_charts("charts")

    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç›‘æ§å·²åœæ­¢")
    finally:
        await monitor.stop_monitoring()


if __name__ == "__main__":
    asyncio.run(main())
