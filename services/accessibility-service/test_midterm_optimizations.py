#!/usr/bin/env python3
"""
ä¸­æœŸä¼˜åŒ–é¡¹ç›®ç»¼åˆæµ‹è¯•è„šæœ¬

æµ‹è¯•ä»¥ä¸‹ä¸­æœŸä¼˜åŒ–åŠŸèƒ½ï¼š
1. æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹
2. è‡ªåŠ¨æ•…éšœæ¢å¤æœºåˆ¶
3. å®¹é‡è§„åˆ’å’Œé¢„æµ‹
4. åˆ†å¸ƒå¼è¿½è¸ªé›†æˆï¼ˆæ¨¡æ‹Ÿï¼‰
"""

import asyncio
import os
import random
import sys
import time
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥æµ‹è¯•æ¨¡å—
try:
    from internal.service.auto_recovery import (
        AutoRecoveryManager,
        FailureEvent,
        FailureType,
        RecoveryAction,
        get_recovery_manager,
    )
    from internal.service.capacity_planning import (
        CapacityPlanner,
        ResourceMetric,
        ResourceType,
        get_capacity_planner,
    )
    from internal.service.ml_anomaly_detection import (
        AnomalySeverity,
        AnomalyType,
        MLAnomalyDetector,
        get_anomaly_detector,
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)


class MidtermOptimizationTester:
    """ä¸­æœŸä¼˜åŒ–æµ‹è¯•å™¨"""

    def __init__(self) -> None:
        self.test_results = []
        self.start_time = datetime.now()

    def log_result(
        self, test_name: str, success: bool, duration: float, details: str = ""
    ):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        self.test_results.append(
            {
                "test_name": test_name,
                "success": success,
                "duration": duration,
                "details": details,
                "timestamp": datetime.now().isoformat(),
            }
        )

        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"{status} {test_name} ({duration:.2f}s)")
        if details:
            print(f"    {details}")

    async def test_ml_anomaly_detection(self) -> bool:
        """æµ‹è¯•æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹"""
        print("\nğŸ” æµ‹è¯•æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹...")

        try:
            start_time = time.time()

            # åˆ›å»ºå¼‚å¸¸æ£€æµ‹å™¨
            detector = MLAnomalyDetector(
                {"statistical_window": 50, "z_threshold": 2.5, "trend_threshold": 0.15}
            )

            detector.start()

            # æ·»åŠ æ­£å¸¸æ•°æ®
            for i in range(100):
                normal_value = 50 + random.gauss(0, 5)
                detector.add_metric("cpu_usage", normal_value)

            # æ³¨å…¥å¼‚å¸¸æ•°æ®
            anomaly_value = 150
            detector.add_metric("cpu_usage", anomaly_value)
            anomalies = detector.detect_anomalies("cpu_usage", anomaly_value)

            # éªŒè¯å¼‚å¸¸æ£€æµ‹
            if not anomalies:
                self.log_result(
                    "MLå¼‚å¸¸æ£€æµ‹", False, time.time() - start_time, "æœªæ£€æµ‹åˆ°å¼‚å¸¸"
                )
                return False

            # æ£€æŸ¥å¼‚å¸¸ç±»å‹
            has_statistical = any(
                a.anomaly_type == AnomalyType.STATISTICAL for a in anomalies
            )

            if not has_statistical:
                self.log_result(
                    "MLå¼‚å¸¸æ£€æµ‹", False, time.time() - start_time, "æœªæ£€æµ‹åˆ°ç»Ÿè®¡å¼‚å¸¸"
                )
                return False

            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = detector.get_anomaly_statistics()
            model_status = detector.get_model_status()

            detector.stop()

            details = (
                f"æ£€æµ‹åˆ°{len(anomalies)}ä¸ªå¼‚å¸¸ï¼Œæ€»å¼‚å¸¸æ•°: {stats['total_anomalies']}"
            )
            self.log_result("MLå¼‚å¸¸æ£€æµ‹", True, time.time() - start_time, details)
            return True

        except Exception as e:
            self.log_result(
                "MLå¼‚å¸¸æ£€æµ‹", False, time.time() - start_time, f"å¼‚å¸¸: {str(e)}"
            )
            return False

    async def test_auto_recovery(self) -> bool:
        """æµ‹è¯•è‡ªåŠ¨æ•…éšœæ¢å¤"""
        print("\nğŸ”§ æµ‹è¯•è‡ªåŠ¨æ•…éšœæ¢å¤...")

        try:
            start_time = time.time()

            # åˆ›å»ºè‡ªåŠ¨æ¢å¤ç®¡ç†å™¨
            recovery_manager = AutoRecoveryManager()

            # æ·»åŠ ç›‘æ§æœåŠ¡
            recovery_manager.add_service("test_service", "python", 8080)

            recovery_manager.start()

            # æ¨¡æ‹Ÿæ•…éšœäº‹ä»¶
            failure_event = FailureEvent(
                timestamp=datetime.now(),
                failure_type=FailureType.HIGH_CPU,
                severity="high",
                description="CPUä½¿ç”¨ç‡è¿‡é«˜: 95%",
                affected_service="test_service",
                metrics={"cpu_percent": 95},
            )

            # å¤„ç†æ•…éšœ
            await recovery_manager._handle_failure(failure_event)

            # ç­‰å¾…æ¢å¤å®Œæˆ
            await asyncio.sleep(2)

            # è·å–æ¢å¤ç»Ÿè®¡
            stats = recovery_manager.get_recovery_statistics()

            recovery_manager.stop()

            # éªŒè¯æ¢å¤ç»“æœ
            if stats["total_failures"] == 0:
                self.log_result(
                    "è‡ªåŠ¨æ•…éšœæ¢å¤", False, time.time() - start_time, "æœªè®°å½•æ•…éšœäº‹ä»¶"
                )
                return False

            details = f"å¤„ç†{stats['total_failures']}ä¸ªæ•…éšœï¼Œæ¢å¤{stats['total_recoveries']}æ¬¡"
            self.log_result("è‡ªåŠ¨æ•…éšœæ¢å¤", True, time.time() - start_time, details)
            return True

        except Exception as e:
            self.log_result(
                "è‡ªåŠ¨æ•…éšœæ¢å¤", False, time.time() - start_time, f"å¼‚å¸¸: {str(e)}"
            )
            return False

    async def test_capacity_planning(self) -> bool:
        """æµ‹è¯•å®¹é‡è§„åˆ’"""
        print("\nğŸ“Š æµ‹è¯•å®¹é‡è§„åˆ’...")

        try:
            start_time = time.time()

            # åˆ›å»ºå®¹é‡è§„åˆ’å™¨
            planner = CapacityPlanner({"linear_window": 50})

            # æ¨¡æ‹Ÿå†å²æ•°æ®
            base_time = datetime.now() - timedelta(days=7)

            for i in range(100):  # 100ä¸ªæ•°æ®ç‚¹
                timestamp = base_time + timedelta(hours=i)

                # æ¨¡æ‹ŸCPUä½¿ç”¨ç‡ï¼ˆæœ‰ä¸Šå‡è¶‹åŠ¿ï¼‰
                cpu_usage = 30 + random.gauss(0, 5) + i * 0.2
                cpu_usage = max(0, min(100, cpu_usage))

                # æ·»åŠ æŒ‡æ ‡
                planner.add_metric(
                    ResourceMetric(
                        timestamp=timestamp,
                        resource_type=ResourceType.CPU,
                        value=cpu_usage,
                        unit="percent",
                    )
                )

            # é¢„æµ‹æœªæ¥èµ„æºä½¿ç”¨
            future_time = datetime.now() + timedelta(days=7)
            predictions = planner.predict_resource_usage(ResourceType.CPU, future_time)

            if not predictions:
                self.log_result(
                    "å®¹é‡è§„åˆ’", False, time.time() - start_time, "æœªç”Ÿæˆé¢„æµ‹ç»“æœ"
                )
                return False

            # ç”Ÿæˆå®¹é‡å»ºè®®
            recommendations = planner.generate_capacity_recommendations(
                timedelta(days=30)
            )

            # è·å–å®¹é‡çŠ¶æ€
            status = planner.get_capacity_status()

            # éªŒè¯ç»“æœ
            has_cpu_prediction = any(
                p.resource_type == ResourceType.CPU for p in predictions
            )
            has_recommendations = len(recommendations) > 0

            if not has_cpu_prediction:
                self.log_result(
                    "å®¹é‡è§„åˆ’", False, time.time() - start_time, "æœªç”ŸæˆCPUé¢„æµ‹"
                )
                return False

            details = f"ç”Ÿæˆ{len(predictions)}ä¸ªé¢„æµ‹ï¼Œ{len(recommendations)}ä¸ªå»ºè®®"
            self.log_result("å®¹é‡è§„åˆ’", True, time.time() - start_time, details)
            return True

        except Exception as e:
            self.log_result(
                "å®¹é‡è§„åˆ’", False, time.time() - start_time, f"å¼‚å¸¸: {str(e)}"
            )
            return False

    async def test_distributed_tracing_simulation(self) -> bool:
        """æµ‹è¯•åˆ†å¸ƒå¼è¿½è¸ªé›†æˆï¼ˆæ¨¡æ‹Ÿï¼‰"""
        print("\nğŸ”— æµ‹è¯•åˆ†å¸ƒå¼è¿½è¸ªé›†æˆï¼ˆæ¨¡æ‹Ÿï¼‰...")

        try:
            start_time = time.time()

            # æ¨¡æ‹Ÿåˆ†å¸ƒå¼è¿½è¸ªåŠŸèƒ½
            trace_data = {
                "trace_id": "trace_12345",
                "spans": [
                    {
                        "span_id": "span_001",
                        "operation": "http_request",
                        "duration": 150,
                        "status": "success",
                    },
                    {
                        "span_id": "span_002",
                        "operation": "database_query",
                        "duration": 80,
                        "status": "success",
                    },
                    {
                        "span_id": "span_003",
                        "operation": "cache_lookup",
                        "duration": 10,
                        "status": "success",
                    },
                ],
                "total_duration": 240,
                "service_map": {
                    "web_service": ["database_service", "cache_service"],
                    "database_service": [],
                    "cache_service": [],
                },
            }

            # æ¨¡æ‹Ÿæ€§èƒ½åˆ†æ
            total_duration = trace_data["total_duration"]
            span_count = len(trace_data["spans"])
            avg_span_duration = (
                sum(span["duration"] for span in trace_data["spans"]) / span_count
            )

            # æ¨¡æ‹Ÿç“¶é¢ˆæ£€æµ‹
            bottleneck_threshold = 100
            bottlenecks = [
                span
                for span in trace_data["spans"]
                if span["duration"] > bottleneck_threshold
            ]

            # éªŒè¯æ¨¡æ‹Ÿç»“æœ
            if span_count == 0:
                self.log_result(
                    "åˆ†å¸ƒå¼è¿½è¸ª", False, time.time() - start_time, "æ— è¿½è¸ªæ•°æ®"
                )
                return False

            details = f"è¿½è¸ª{span_count}ä¸ªspanï¼Œå¹³å‡è€—æ—¶{avg_span_duration:.1f}msï¼Œå‘ç°{len(bottlenecks)}ä¸ªç“¶é¢ˆ"
            self.log_result("åˆ†å¸ƒå¼è¿½è¸ª", True, time.time() - start_time, details)
            return True

        except Exception as e:
            self.log_result(
                "åˆ†å¸ƒå¼è¿½è¸ª", False, time.time() - start_time, f"å¼‚å¸¸: {str(e)}"
            )
            return False

    async def test_integration(self) -> bool:
        """æµ‹è¯•æ¨¡å—é›†æˆ"""
        print("\nğŸ”„ æµ‹è¯•æ¨¡å—é›†æˆ...")

        try:
            start_time = time.time()

            # åˆ›å»ºæ‰€æœ‰æ¨¡å—å®ä¾‹
            anomaly_detector = get_anomaly_detector()
            recovery_manager = get_recovery_manager()
            capacity_planner = get_capacity_planner()

            anomaly_detector.start()
            recovery_manager.start()

            # æ¨¡æ‹Ÿé›†æˆåœºæ™¯ï¼šå®¹é‡é¢„æµ‹è§¦å‘å¼‚å¸¸æ£€æµ‹ï¼Œå¼‚å¸¸æ£€æµ‹è§¦å‘è‡ªåŠ¨æ¢å¤

            # 1. æ·»åŠ å®¹é‡æ•°æ®
            for i in range(50):
                timestamp = datetime.now() - timedelta(minutes=50 - i)
                cpu_usage = 60 + i * 0.5  # é€æ¸å¢é•¿çš„CPUä½¿ç”¨ç‡

                capacity_planner.add_metric(
                    ResourceMetric(
                        timestamp=timestamp,
                        resource_type=ResourceType.CPU,
                        value=cpu_usage,
                        unit="percent",
                    )
                )

                anomaly_detector.add_metric("cpu_usage", cpu_usage, timestamp)

            # 2. æ³¨å…¥é«˜CPUä½¿ç”¨ç‡
            high_cpu_value = 95
            anomalies = anomaly_detector.detect_anomalies("cpu_usage", high_cpu_value)

            # 3. å¦‚æœæ£€æµ‹åˆ°å¼‚å¸¸ï¼Œè§¦å‘è‡ªåŠ¨æ¢å¤
            if anomalies:
                failure_event = FailureEvent(
                    timestamp=datetime.now(),
                    failure_type=FailureType.HIGH_CPU,
                    severity="high",
                    description=f"å¼‚å¸¸æ£€æµ‹è§¦å‘: CPUä½¿ç”¨ç‡{high_cpu_value}%",
                    affected_service="integrated_service",
                    metrics={"cpu_percent": high_cpu_value},
                )

                await recovery_manager._handle_failure(failure_event)

            # 4. ç”Ÿæˆå®¹é‡å»ºè®®
            recommendations = capacity_planner.generate_capacity_recommendations()

            anomaly_detector.stop()
            recovery_manager.stop()

            # éªŒè¯é›†æˆç»“æœ
            anomaly_stats = anomaly_detector.get_anomaly_statistics()
            recovery_stats = recovery_manager.get_recovery_statistics()

            integration_success = (
                anomaly_stats["total_anomalies"] > 0
                and recovery_stats["total_failures"] > 0
                and len(recommendations) > 0
            )

            if not integration_success:
                self.log_result(
                    "æ¨¡å—é›†æˆ", False, time.time() - start_time, "é›†æˆæµç¨‹æœªå®Œæ•´æ‰§è¡Œ"
                )
                return False

            details = f"å¼‚å¸¸{anomaly_stats['total_anomalies']}ä¸ªï¼Œæ¢å¤{recovery_stats['total_recoveries']}æ¬¡ï¼Œå»ºè®®{len(recommendations)}ä¸ª"
            self.log_result("æ¨¡å—é›†æˆ", True, time.time() - start_time, details)
            return True

        except Exception as e:
            self.log_result(
                "æ¨¡å—é›†æˆ", False, time.time() - start_time, f"å¼‚å¸¸: {str(e)}"
            )
            return False

    def print_summary(self) -> None:
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        total_tests = len(self.test_results)
        passed_tests = sum(1 for result in self.test_results if result["success"])
        failed_tests = total_tests - passed_tests

        total_duration = (datetime.now() - self.start_time).total_seconds()

        print("\n" + "=" * 60)
        print("ğŸ“Š ä¸­æœŸä¼˜åŒ–æµ‹è¯•æ€»ç»“")
        print("=" * 60)
        print(f"æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"é€šè¿‡æµ‹è¯•: {passed_tests}")
        print(f"å¤±è´¥æµ‹è¯•: {failed_tests}")
        print(f"æˆåŠŸç‡: {passed_tests/total_tests*100:.1f}%")
        print(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")

        if failed_tests > 0:
            print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
            for result in self.test_results:
                if not result["success"]:
                    print(f"  - {result['test_name']}: {result['details']}")

        print("\nğŸ“‹ è¯¦ç»†ç»“æœ:")
        for result in self.test_results:
            status = "âœ…" if result["success"] else "âŒ"
            print(f"  {status} {result['test_name']}: {result['duration']:.2f}s")

        return passed_tests == total_tests


async def main() -> None:
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä¸­æœŸä¼˜åŒ–é¡¹ç›®æµ‹è¯•...")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    tester = MidtermOptimizationTester()

    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        tester.test_ml_anomaly_detection(),
        tester.test_auto_recovery(),
        tester.test_capacity_planning(),
        tester.test_distributed_tracing_simulation(),
        tester.test_integration(),
    ]

    # å¹¶å‘æ‰§è¡Œæµ‹è¯•
    results = await asyncio.gather(*tests, return_exceptions=True)

    # å¤„ç†å¼‚å¸¸ç»“æœ
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            test_name = [
                "MLå¼‚å¸¸æ£€æµ‹",
                "è‡ªåŠ¨æ•…éšœæ¢å¤",
                "å®¹é‡è§„åˆ’",
                "åˆ†å¸ƒå¼è¿½è¸ª",
                "æ¨¡å—é›†æˆ",
            ][i]
            tester.log_result(test_name, False, 0, f"æµ‹è¯•å¼‚å¸¸: {str(result)}")

    # æ‰“å°æ€»ç»“
    success = tester.print_summary()

    if success:
        print("\nğŸ‰ æ‰€æœ‰ä¸­æœŸä¼˜åŒ–æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
