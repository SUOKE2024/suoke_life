#!/usr/bin/env python3
"""
ç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡ - ä¸­æœŸä¼˜åŒ–åŠŸèƒ½ç»¼åˆæ¼”ç¤º

å±•ç¤ºä»¥ä¸‹ä¸­æœŸä¼˜åŒ–åŠŸèƒ½ï¼š
1. æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹
2. è‡ªåŠ¨æ•…éšœæ¢å¤æœºåˆ¶
3. å®¹é‡è§„åˆ’å’Œé¢„æµ‹
4. åˆ†å¸ƒå¼è¿½è¸ªé›†æˆ
5. æ¨¡å—é—´åä½œæ¼”ç¤º
"""

import asyncio
import math
import os
import random
import sys
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# å¯¼å…¥æ¨¡å—
try:
    from internal.service.auto_recovery import (
        AutoRecoveryManager,
        FailureEvent,
        FailureType,
        RecoveryAction,
    )
    from internal.service.capacity_planning import (
        CapacityPlanner,
        PredictionModel,
        ResourceMetric,
        ResourceType,
    )
    from internal.service.ml_anomaly_detection import (
        AnomalySeverity,
        AnomalyType,
        MLAnomalyDetector,
    )
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    sys.exit(1)


class MidtermOptimizationDemo:
    """ä¸­æœŸä¼˜åŒ–åŠŸèƒ½ç»¼åˆæ¼”ç¤º"""

    def __init__(self) -> None:
        self.start_time = datetime.now()
        self.demo_data = {}

        # åˆå§‹åŒ–æ‰€æœ‰æ¨¡å—
        self.anomaly_detector = None
        self.recovery_manager = None
        self.capacity_planner = None

    def print_header(self, title: str, emoji: str = "ğŸš€"):
        """æ‰“å°æ ‡é¢˜"""
        print(f"\n{emoji} {title}")
        print("=" * (len(title) + 4))

    def print_section(self, title: str, emoji: str = "ğŸ“‹"):
        """æ‰“å°ç« èŠ‚"""
        print(f"\n{emoji} {title}")
        print("-" * (len(title) + 4))

    async def demo_ml_anomaly_detection(self) -> None:
        """æ¼”ç¤ºæœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹"""
        self.print_section("æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹æ¼”ç¤º", "ğŸ”")

        # åˆ›å»ºå¼‚å¸¸æ£€æµ‹å™¨
        self.anomaly_detector = MLAnomalyDetector(
            {"statistical_window": 50, "z_threshold": 2.5, "trend_threshold": 0.15}
        )

        self.anomaly_detector.start()
        print("âœ… å¼‚å¸¸æ£€æµ‹å™¨å·²å¯åŠ¨")

        # æ¨¡æ‹Ÿæ­£å¸¸æ•°æ®
        print("\nğŸ“Š ç”Ÿæˆæ­£å¸¸æ•°æ®...")
        normal_data = []
        for i in range(100):
            # æ¨¡æ‹ŸCPUä½¿ç”¨ç‡ï¼ˆæœ‰æ—¥å‘¨æœŸæ€§ï¼‰
            hour_factor = math.sin(2 * math.pi * i / 24)
            base_value = 50 + 15 * hour_factor
            noise = random.gauss(0, 3)
            cpu_usage = max(0, min(100, base_value + noise))

            normal_data.append(cpu_usage)
            self.anomaly_detector.add_metric("cpu_usage", cpu_usage)

        print(f"   ç”Ÿæˆäº† {len(normal_data)} ä¸ªæ­£å¸¸æ•°æ®ç‚¹")
        print(f"   å¹³å‡CPUä½¿ç”¨ç‡: {sum(normal_data)/len(normal_data):.1f}%")

        # æ³¨å…¥å¼‚å¸¸æ•°æ®
        print("\nğŸš¨ æ³¨å…¥å¼‚å¸¸æ•°æ®...")
        anomaly_scenarios = [("CPUçªå¢å¼‚å¸¸", 95), ("CPUçªé™å¼‚å¸¸", 5), ("æå€¼å¼‚å¸¸", 150)]

        total_anomalies = 0
        for scenario_name, anomaly_value in anomaly_scenarios:
            print(f"   {scenario_name}: {anomaly_value}%")
            self.anomaly_detector.add_metric("cpu_usage", anomaly_value)
            anomalies = self.anomaly_detector.detect_anomalies(
                "cpu_usage", anomaly_value
            )

            if anomalies:
                total_anomalies += len(anomalies)
                for anomaly in anomalies:
                    print(
                        f"     âš ï¸  æ£€æµ‹åˆ°{anomaly.anomaly_type.value}å¼‚å¸¸ "
                        f"(ä¸¥é‡ç¨‹åº¦: {anomaly.severity.value}, "
                        f"ç½®ä¿¡åº¦: {anomaly.confidence:.2f})"
                    )

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = self.anomaly_detector.get_anomaly_statistics()
        model_status = self.anomaly_detector.get_model_status()

        print("\nğŸ“ˆ å¼‚å¸¸æ£€æµ‹ç»Ÿè®¡:")
        print(f"   æ€»å¼‚å¸¸æ•°: {stats['total_anomalies']}")
        print(f"   æŒ‰ç±»å‹åˆ†å¸ƒ: {stats['by_type']}")
        print(f"   æŒ‰ä¸¥é‡ç¨‹åº¦åˆ†å¸ƒ: {stats['by_severity']}")

        print("\nğŸ¤– æ¨¡å‹çŠ¶æ€:")
        for detector_name, status in model_status.items():
            print(f"   {detector_name}: {status['data_points']} æ•°æ®ç‚¹")

        self.demo_data["anomaly_detection"] = {
            "total_anomalies": stats["total_anomalies"],
            "model_status": model_status,
        }

    async def demo_auto_recovery(self) -> None:
        """æ¼”ç¤ºè‡ªåŠ¨æ•…éšœæ¢å¤"""
        self.print_section("è‡ªåŠ¨æ•…éšœæ¢å¤æ¼”ç¤º", "ğŸ”§")

        # åˆ›å»ºè‡ªåŠ¨æ¢å¤ç®¡ç†å™¨
        self.recovery_manager = AutoRecoveryManager()

        # æ·»åŠ ç›‘æ§æœåŠ¡
        services = [
            ("web_server", "nginx", 80),
            ("api_server", "python", 8080),
            ("database", "postgres", 5432),
            ("cache_server", "redis", 6379),
        ]

        for service_name, process_name, port in services:
            self.recovery_manager.add_service(service_name, process_name, port)

        self.recovery_manager.start()
        print("âœ… è‡ªåŠ¨æ¢å¤ç®¡ç†å™¨å·²å¯åŠ¨")
        print(f"   ç›‘æ§æœåŠ¡æ•°: {len(services)}")

        # æ¨¡æ‹Ÿå„ç§æ•…éšœåœºæ™¯
        print("\nğŸš¨ æ¨¡æ‹Ÿæ•…éšœåœºæ™¯...")
        failure_scenarios = [
            {
                "name": "é«˜CPUä½¿ç”¨ç‡",
                "type": FailureType.HIGH_CPU,
                "severity": "high",
                "description": "WebæœåŠ¡å™¨CPUä½¿ç”¨ç‡è¾¾åˆ°95%",
                "service": "web_server",
                "metrics": {"cpu_percent": 95},
            },
            {
                "name": "å†…å­˜ä¸è¶³",
                "type": FailureType.HIGH_MEMORY,
                "severity": "critical",
                "description": "APIæœåŠ¡å™¨å†…å­˜ä½¿ç”¨ç‡è¾¾åˆ°98%",
                "service": "api_server",
                "metrics": {"memory_percent": 98},
            },
            {
                "name": "ç£ç›˜ç©ºé—´ä¸è¶³",
                "type": FailureType.DISK_FULL,
                "severity": "critical",
                "description": "æ•°æ®åº“ç£ç›˜ä½¿ç”¨ç‡è¾¾åˆ°97%",
                "service": "database",
                "metrics": {"disk_percent": 97},
            },
            {
                "name": "ç½‘ç»œè¿æ¥å¼‚å¸¸",
                "type": FailureType.NETWORK_ERROR,
                "severity": "medium",
                "description": "ç¼“å­˜æœåŠ¡å™¨ç½‘ç»œè¿æ¥è¶…æ—¶",
                "service": "cache_server",
                "metrics": {"network_timeout": 5000},
            },
        ]

        recovery_tasks = []
        for scenario in failure_scenarios:
            print(f"   {scenario['name']}: {scenario['description']}")

            failure_event = FailureEvent(
                timestamp=datetime.now(),
                failure_type=scenario["type"],
                severity=scenario["severity"],
                description=scenario["description"],
                affected_service=scenario["service"],
                metrics=scenario["metrics"],
            )

            # å¼‚æ­¥å¤„ç†æ•…éšœ
            task = asyncio.create_task(
                self.recovery_manager._handle_failure(failure_event)
            )
            recovery_tasks.append(task)

        # ç­‰å¾…æ‰€æœ‰æ¢å¤ä»»åŠ¡å®Œæˆ
        print("\nâ³ ç­‰å¾…æ•…éšœæ¢å¤...")
        await asyncio.gather(*recovery_tasks)

        # ç­‰å¾…æ¢å¤å®Œæˆ
        await asyncio.sleep(3)

        # æ˜¾ç¤ºæ¢å¤ç»Ÿè®¡
        stats = self.recovery_manager.get_recovery_statistics()

        print("\nğŸ“Š æ•…éšœæ¢å¤ç»Ÿè®¡:")
        print(f"   æ€»æ•…éšœæ•°: {stats['total_failures']}")
        print(f"   æ€»æ¢å¤æ•°: {stats['total_recoveries']}")
        print(f"   æˆåŠŸç‡: {stats['success_rate']:.1%}")
        print(f"   æŒ‰æ•…éšœç±»å‹: {stats['by_failure_type']}")
        print(f"   æŒ‰æ¢å¤åŠ¨ä½œ: {stats['by_action_type']}")

        if stats["recent_recoveries"]:
            print("\nğŸ”§ æœ€è¿‘çš„æ¢å¤æ“ä½œ:")
            for recovery in stats["recent_recoveries"][-3:]:
                print(
                    f"   {recovery['action']}: {recovery['status']} "
                    f"({recovery['duration']:.1f}s)"
                )

        self.recovery_manager.stop()

        self.demo_data["auto_recovery"] = {
            "total_failures": stats["total_failures"],
            "total_recoveries": stats["total_recoveries"],
            "success_rate": stats["success_rate"],
        }

    async def demo_capacity_planning(self) -> None:
        """æ¼”ç¤ºå®¹é‡è§„åˆ’å’Œé¢„æµ‹"""
        self.print_section("å®¹é‡è§„åˆ’å’Œé¢„æµ‹æ¼”ç¤º", "ğŸ“Š")

        # åˆ›å»ºå®¹é‡è§„åˆ’å™¨
        self.capacity_planner = CapacityPlanner({"linear_window": 50, "ma_window": 20})

        print("âœ… å®¹é‡è§„åˆ’å™¨å·²å¯åŠ¨")

        # æ¨¡æ‹Ÿå†å²æ•°æ®
        print("\nğŸ“ˆ ç”Ÿæˆå†å²èµ„æºä½¿ç”¨æ•°æ®...")
        base_time = datetime.now() - timedelta(days=30)

        resource_scenarios = {
            ResourceType.CPU: {
                "base": 40,
                "trend": 0.3,  # æ¯å¤©å¢é•¿0.3%
                "noise": 8,
                "seasonal": True,
            },
            ResourceType.MEMORY: {
                "base": 60,
                "trend": 0.2,
                "noise": 10,
                "seasonal": False,
            },
            ResourceType.DISK: {
                "base": 70,
                "trend": 0.5,  # ç£ç›˜ä½¿ç”¨å¢é•¿è¾ƒå¿«
                "noise": 5,
                "seasonal": False,
            },
            ResourceType.NETWORK: {
                "base": 200,
                "trend": 2.0,
                "noise": 50,
                "seasonal": True,
            },
        }

        data_points = 0
        for resource_type, scenario in resource_scenarios.items():
            for day in range(30):
                for hour in range(0, 24, 2):  # æ¯2å°æ—¶ä¸€ä¸ªæ•°æ®ç‚¹
                    timestamp = base_time + timedelta(days=day, hours=hour)

                    # åŸºç¡€å€¼ + è¶‹åŠ¿ + å­£èŠ‚æ€§ + å™ªå£°
                    base_value = scenario["base"]
                    trend_value = scenario["trend"] * day

                    if scenario["seasonal"]:
                        # æ—¥å‘¨æœŸæ€§
                        seasonal_value = 10 * math.sin(2 * math.pi * hour / 24)
                    else:
                        seasonal_value = 0

                    noise_value = random.gauss(0, scenario["noise"])

                    final_value = (
                        base_value + trend_value + seasonal_value + noise_value
                    )
                    final_value = max(0, final_value)

                    # æ·»åŠ æŒ‡æ ‡
                    self.capacity_planner.add_metric(
                        ResourceMetric(
                            timestamp=timestamp,
                            resource_type=resource_type,
                            value=final_value,
                            unit=(
                                "percent"
                                if resource_type
                                in [
                                    ResourceType.CPU,
                                    ResourceType.MEMORY,
                                    ResourceType.DISK,
                                ]
                                else "mbps"
                            ),
                        )
                    )

                    data_points += 1

        print(f"   ç”Ÿæˆäº† {data_points} ä¸ªå†å²æ•°æ®ç‚¹")

        # é¢„æµ‹æœªæ¥èµ„æºä½¿ç”¨
        print("\nğŸ”® é¢„æµ‹æœªæ¥èµ„æºä½¿ç”¨...")
        prediction_horizons = [
            (timedelta(days=7), "1å‘¨å"),
            (timedelta(days=30), "1ä¸ªæœˆå"),
            (timedelta(days=90), "3ä¸ªæœˆå"),
        ]

        for horizon, description in prediction_horizons:
            future_time = datetime.now() + horizon
            print(f"\n   {description} ({future_time.strftime('%Y-%m-%d')}):")

            for resource_type in resource_scenarios.keys():
                predictions = self.capacity_planner.predict_resource_usage(
                    resource_type, future_time
                )

                if predictions:
                    best_prediction = max(predictions, key=lambda p: p.confidence)
                    print(
                        f"     {resource_type.value.upper()}: "
                        f"{best_prediction.predicted_value:.1f} "
                        f"(ç½®ä¿¡åº¦: {best_prediction.confidence:.2f}, "
                        f"è¶‹åŠ¿: {best_prediction.trend})"
                    )

        # ç”Ÿæˆå®¹é‡å»ºè®®
        print("\nğŸ’¡ ç”Ÿæˆå®¹é‡è§„åˆ’å»ºè®®...")
        recommendations = self.capacity_planner.generate_capacity_recommendations(
            timedelta(days=60)
        )

        if recommendations:
            print(f"   ç”Ÿæˆäº† {len(recommendations)} ä¸ªå»ºè®®:")
            for rec in recommendations:
                print(f"\n   {rec.resource_type.value.upper()}:")
                print(f"     å½“å‰å®¹é‡: {rec.current_capacity}")
                print(f"     é¢„æµ‹éœ€æ±‚: {rec.predicted_demand:.1f}")
                print(f"     å»ºè®®å®¹é‡: {rec.recommended_capacity:.1f}")
                print(f"     æ‰©å®¹æ–¹å‘: {rec.scaling_direction.value}")
                print(f"     ç´§æ€¥ç¨‹åº¦: {rec.urgency}")
                print(f"     æ—¶é—´çº¿: {rec.timeline}")
                print(f"     æˆæœ¬å½±å“: {rec.cost_impact:.2f}")
                print(f"     æ¨ç†: {rec.reasoning}")
        else:
            print("   å½“å‰å®¹é‡é…ç½®åˆç†ï¼Œæ— éœ€è°ƒæ•´")

        # æ˜¾ç¤ºå®¹é‡çŠ¶æ€
        status = self.capacity_planner.get_capacity_status()
        print("\nğŸ“‹ å½“å‰å®¹é‡çŠ¶æ€:")
        for resource, info in status.items():
            if info["data_points"] > 0:
                print(
                    f"   {resource.upper()}: "
                    f"å½“å‰ä½¿ç”¨ {info['current_usage']:.1f}, "
                    f"æ•°æ®ç‚¹ {info['data_points']}"
                )

        self.demo_data["capacity_planning"] = {
            "data_points": data_points,
            "recommendations": len(recommendations),
            "resources_monitored": len(
                [r for r in status.values() if r["data_points"] > 0]
            ),
        }

    async def demo_distributed_tracing(self) -> None:
        """æ¼”ç¤ºåˆ†å¸ƒå¼è¿½è¸ªé›†æˆ"""
        self.print_section("åˆ†å¸ƒå¼è¿½è¸ªé›†æˆæ¼”ç¤º", "ğŸ”—")

        print("âœ… åˆ†å¸ƒå¼è¿½è¸ªç³»ç»Ÿå·²å¯åŠ¨")

        # æ¨¡æ‹Ÿå¤šä¸ªæœåŠ¡è°ƒç”¨é“¾
        print("\nğŸ“¡ æ¨¡æ‹ŸæœåŠ¡è°ƒç”¨é“¾...")

        trace_scenarios = [
            {
                "name": "ç”¨æˆ·ç™»å½•æµç¨‹",
                "trace_id": "trace_login_001",
                "spans": [
                    {"operation": "http_request", "service": "gateway", "duration": 50},
                    {
                        "operation": "auth_validate",
                        "service": "auth_service",
                        "duration": 120,
                    },
                    {
                        "operation": "user_query",
                        "service": "user_service",
                        "duration": 80,
                    },
                    {"operation": "cache_lookup", "service": "redis", "duration": 15},
                    {"operation": "db_query", "service": "postgres", "duration": 200},
                    {
                        "operation": "response_build",
                        "service": "gateway",
                        "duration": 30,
                    },
                ],
            },
            {
                "name": "æ•°æ®æŸ¥è¯¢æµç¨‹",
                "trace_id": "trace_query_002",
                "spans": [
                    {
                        "operation": "api_request",
                        "service": "api_gateway",
                        "duration": 40,
                    },
                    {
                        "operation": "permission_check",
                        "service": "auth_service",
                        "duration": 60,
                    },
                    {
                        "operation": "data_fetch",
                        "service": "data_service",
                        "duration": 300,
                    },
                    {"operation": "cache_miss", "service": "redis", "duration": 5},
                    {
                        "operation": "db_complex_query",
                        "service": "postgres",
                        "duration": 450,
                    },
                    {
                        "operation": "data_transform",
                        "service": "data_service",
                        "duration": 100,
                    },
                    {
                        "operation": "response_format",
                        "service": "api_gateway",
                        "duration": 25,
                    },
                ],
            },
            {
                "name": "æ–‡ä»¶ä¸Šä¼ æµç¨‹",
                "trace_id": "trace_upload_003",
                "spans": [
                    {
                        "operation": "upload_request",
                        "service": "upload_service",
                        "duration": 100,
                    },
                    {
                        "operation": "file_validation",
                        "service": "upload_service",
                        "duration": 80,
                    },
                    {
                        "operation": "storage_write",
                        "service": "minio",
                        "duration": 2000,
                    },
                    {
                        "operation": "metadata_save",
                        "service": "postgres",
                        "duration": 150,
                    },
                    {
                        "operation": "index_update",
                        "service": "elasticsearch",
                        "duration": 200,
                    },
                    {
                        "operation": "notification_send",
                        "service": "notification_service",
                        "duration": 50,
                    },
                ],
            },
        ]

        total_traces = 0
        total_spans = 0
        total_bottlenecks = 0

        for scenario in trace_scenarios:
            print(f"\n   {scenario['name']} (ID: {scenario['trace_id']}):")

            # è®¡ç®—æ€»è€—æ—¶
            total_duration = sum(span["duration"] for span in scenario["spans"])
            span_count = len(scenario["spans"])
            avg_duration = total_duration / span_count

            print(f"     æ€»è€—æ—¶: {total_duration}ms")
            print(f"     Spanæ•°: {span_count}")
            print(f"     å¹³å‡è€—æ—¶: {avg_duration:.1f}ms")

            # è¯†åˆ«ç“¶é¢ˆï¼ˆè€—æ—¶è¶…è¿‡100msçš„æ“ä½œï¼‰
            bottleneck_threshold = 100
            bottlenecks = [
                span
                for span in scenario["spans"]
                if span["duration"] > bottleneck_threshold
            ]

            if bottlenecks:
                print(f"     ğŸŒ æ€§èƒ½ç“¶é¢ˆ ({len(bottlenecks)}ä¸ª):")
                for bottleneck in bottlenecks:
                    print(
                        f"       - {bottleneck['operation']} "
                        f"({bottleneck['service']}): {bottleneck['duration']}ms"
                    )
            else:
                print("     âœ… æ— æ€§èƒ½ç“¶é¢ˆ")

            # æœåŠ¡è°ƒç”¨ç»Ÿè®¡
            service_stats = {}
            for span in scenario["spans"]:
                service = span["service"]
                if service not in service_stats:
                    service_stats[service] = {"count": 0, "total_duration": 0}
                service_stats[service]["count"] += 1
                service_stats[service]["total_duration"] += span["duration"]

            print("     ğŸ“Š æœåŠ¡è°ƒç”¨ç»Ÿè®¡:")
            for service, stats in service_stats.items():
                avg_service_duration = stats["total_duration"] / stats["count"]
                print(
                    f"       {service}: {stats['count']}æ¬¡è°ƒç”¨, "
                    f"å¹³å‡{avg_service_duration:.1f}ms"
                )

            total_traces += 1
            total_spans += span_count
            total_bottlenecks += len(bottlenecks)

        # ç”ŸæˆæœåŠ¡ä¾èµ–å›¾
        print("\nğŸ•¸ï¸  æœåŠ¡ä¾èµ–å…³ç³»åˆ†æ:")
        service_dependencies = {
            "gateway": ["auth_service", "user_service"],
            "api_gateway": ["auth_service", "data_service"],
            "upload_service": [
                "minio",
                "postgres",
                "elasticsearch",
                "notification_service",
            ],
            "auth_service": ["postgres", "redis"],
            "user_service": ["postgres", "redis"],
            "data_service": ["postgres", "redis", "elasticsearch"],
            "notification_service": ["redis"],
        }

        for service, dependencies in service_dependencies.items():
            if dependencies:
                print(f"   {service} â†’ {', '.join(dependencies)}")
            else:
                print(f"   {service} (å¶å­æœåŠ¡)")

        # æ€§èƒ½åˆ†ææ€»ç»“
        print("\nğŸ“ˆ è¿½è¸ªåˆ†ææ€»ç»“:")
        print(f"   æ€»è¿½è¸ªæ•°: {total_traces}")
        print(f"   æ€»Spanæ•°: {total_spans}")
        print(f"   å¹³å‡Span/è¿½è¸ª: {total_spans/total_traces:.1f}")
        print(f"   æ€§èƒ½ç“¶é¢ˆæ•°: {total_bottlenecks}")
        print(f"   ç“¶é¢ˆç‡: {total_bottlenecks/total_spans:.1%}")

        # æ€§èƒ½ä¼˜åŒ–å»ºè®®
        print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        optimization_suggestions = [
            "æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–ï¼šè€ƒè™‘æ·»åŠ ç´¢å¼•æˆ–æŸ¥è¯¢ä¼˜åŒ–",
            "ç¼“å­˜ç­–ç•¥æ”¹è¿›ï¼šæé«˜ç¼“å­˜å‘½ä¸­ç‡ï¼Œå‡å°‘æ•°æ®åº“è®¿é—®",
            "å¼‚æ­¥å¤„ç†ï¼šå°†éå…³é”®æ“ä½œæ”¹ä¸ºå¼‚æ­¥å¤„ç†",
            "è¿æ¥æ± ä¼˜åŒ–ï¼šä¼˜åŒ–æ•°æ®åº“å’Œç¼“å­˜è¿æ¥æ± é…ç½®",
            "æœåŠ¡æ‹†åˆ†ï¼šè€ƒè™‘å°†é«˜è€—æ—¶æ“ä½œæ‹†åˆ†ä¸ºç‹¬ç«‹æœåŠ¡",
        ]

        for i, suggestion in enumerate(optimization_suggestions, 1):
            print(f"   {i}. {suggestion}")

        self.demo_data["distributed_tracing"] = {
            "total_traces": total_traces,
            "total_spans": total_spans,
            "bottleneck_rate": total_bottlenecks / total_spans,
            "services_monitored": len(service_dependencies),
        }

    async def demo_integration_scenario(self) -> None:
        """æ¼”ç¤ºæ¨¡å—é›†æˆåœºæ™¯"""
        self.print_section("æ¨¡å—é›†æˆåä½œæ¼”ç¤º", "ğŸ”„")

        print("ğŸ¯ åœºæ™¯ï¼šç³»ç»Ÿè´Ÿè½½å¢é•¿è§¦å‘çš„æ™ºèƒ½è¿ç»´æµç¨‹")
        print("\nğŸ“‹ æµç¨‹è¯´æ˜:")
        print("   1. å®¹é‡è§„åˆ’æ£€æµ‹åˆ°èµ„æºä½¿ç”¨è¶‹åŠ¿å¼‚å¸¸")
        print("   2. å¼‚å¸¸æ£€æµ‹å™¨ç¡®è®¤å¼‚å¸¸å¹¶åˆ†ç±»")
        print("   3. è‡ªåŠ¨æ¢å¤ç³»ç»Ÿæ‰§è¡Œç›¸åº”çš„æ¢å¤ç­–ç•¥")
        print("   4. åˆ†å¸ƒå¼è¿½è¸ªåˆ†ææ€§èƒ½å½±å“")

        # æ¨¡æ‹Ÿé›†æˆåœºæ™¯
        print("\nğŸš€ å¼€å§‹é›†æˆæ¼”ç¤º...")

        # 1. å®¹é‡æ•°æ®æ˜¾ç¤ºèµ„æºä½¿ç”¨ä¸Šå‡è¶‹åŠ¿
        print("\n1ï¸âƒ£ å®¹é‡ç›‘æ§å‘ç°å¼‚å¸¸è¶‹åŠ¿...")
        for i in range(30):
            timestamp = datetime.now() - timedelta(minutes=30 - i)
            # æ¨¡æ‹ŸCPUä½¿ç”¨ç‡é€æ¸ä¸Šå‡
            cpu_usage = 60 + i * 1.2 + random.gauss(0, 2)
            cpu_usage = max(0, min(100, cpu_usage))

            self.capacity_planner.add_metric(
                ResourceMetric(
                    timestamp=timestamp,
                    resource_type=ResourceType.CPU,
                    value=cpu_usage,
                    unit="percent",
                )
            )

            self.anomaly_detector.add_metric("cpu_usage", cpu_usage, timestamp)

        print("   âœ… æ£€æµ‹åˆ°CPUä½¿ç”¨ç‡æŒç»­ä¸Šå‡è¶‹åŠ¿")

        # 2. å¼‚å¸¸æ£€æµ‹å™¨æ£€æµ‹åˆ°å¼‚å¸¸
        print("\n2ï¸âƒ£ å¼‚å¸¸æ£€æµ‹å™¨åˆ†æ...")
        high_cpu_value = 95
        anomalies = self.anomaly_detector.detect_anomalies("cpu_usage", high_cpu_value)

        if anomalies:
            print(f"   ğŸš¨ æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸:")
            for anomaly in anomalies:
                print(f"     - {anomaly.anomaly_type.value}: {anomaly.description}")
                print(
                    f"       ä¸¥é‡ç¨‹åº¦: {anomaly.severity.value}, ç½®ä¿¡åº¦: {anomaly.confidence:.2f}"
                )

        # 3. è§¦å‘è‡ªåŠ¨æ¢å¤
        print("\n3ï¸âƒ£ è‡ªåŠ¨æ¢å¤ç³»ç»Ÿå“åº”...")
        if anomalies:
            failure_event = FailureEvent(
                timestamp=datetime.now(),
                failure_type=FailureType.HIGH_CPU,
                severity="high",
                description=f"é›†æˆåœºæ™¯: CPUä½¿ç”¨ç‡å¼‚å¸¸ {high_cpu_value}%",
                affected_service="integrated_system",
                metrics={"cpu_percent": high_cpu_value},
            )

            await self.recovery_manager._handle_failure(failure_event)
            print("   âœ… è‡ªåŠ¨æ¢å¤æµç¨‹å·²å¯åŠ¨")

        # 4. å®¹é‡è§„åˆ’ç”Ÿæˆå»ºè®®
        print("\n4ï¸âƒ£ å®¹é‡è§„åˆ’ç”Ÿæˆå»ºè®®...")
        recommendations = self.capacity_planner.generate_capacity_recommendations()

        if recommendations:
            for rec in recommendations:
                if rec.resource_type == ResourceType.CPU:
                    print(f"   ğŸ’¡ {rec.resource_type.value.upper()} å»ºè®®:")
                    print(f"     æ‰©å®¹æ–¹å‘: {rec.scaling_direction.value}")
                    print(f"     ç´§æ€¥ç¨‹åº¦: {rec.urgency}")
                    print(f"     å»ºè®®å®¹é‡: {rec.recommended_capacity:.1f}")
                    print(f"     æ¨ç†: {rec.reasoning}")

        # 5. åˆ†å¸ƒå¼è¿½è¸ªåˆ†æå½±å“
        print("\n5ï¸âƒ£ åˆ†å¸ƒå¼è¿½è¸ªåˆ†ææ€§èƒ½å½±å“...")

        # æ¨¡æ‹Ÿé«˜è´Ÿè½½ä¸‹çš„è¿½è¸ªæ•°æ®
        high_load_trace = {
            "trace_id": "trace_high_load_001",
            "spans": [
                {"operation": "load_balancer", "service": "nginx", "duration": 80},
                {
                    "operation": "app_processing",
                    "service": "app_server",
                    "duration": 350,
                },  # å—CPUå½±å“
                {
                    "operation": "db_query",
                    "service": "postgres",
                    "duration": 250,
                },  # å—CPUå½±å“
                {"operation": "cache_access", "service": "redis", "duration": 40},
                {
                    "operation": "response_build",
                    "service": "app_server",
                    "duration": 120,
                },  # å—CPUå½±å“
            ],
        }

        total_duration = sum(span["duration"] for span in high_load_trace["spans"])
        bottlenecks = [
            span for span in high_load_trace["spans"] if span["duration"] > 100
        ]

        print("   ğŸ“Š é«˜è´Ÿè½½è¿½è¸ªåˆ†æ:")
        print(f"     æ€»å“åº”æ—¶é—´: {total_duration}ms (æ¯”æ­£å¸¸æ…¢40%)")
        print(f"     æ€§èƒ½ç“¶é¢ˆ: {len(bottlenecks)} ä¸ª")
        for bottleneck in bottlenecks:
            print(f"       - {bottleneck['operation']}: {bottleneck['duration']}ms")

        # 6. ç»¼åˆåˆ†æå’Œå»ºè®®
        print("\n6ï¸âƒ£ ç»¼åˆåˆ†æå’Œæ™ºèƒ½å»ºè®®...")

        # è·å–æ‰€æœ‰æ¨¡å—çš„ç»Ÿè®¡ä¿¡æ¯
        anomaly_stats = self.anomaly_detector.get_anomaly_statistics()
        recovery_stats = self.recovery_manager.get_recovery_statistics()

        print("   ğŸ“ˆ ç»¼åˆçŠ¶æ€æŠ¥å‘Š:")
        print(f"     å¼‚å¸¸æ£€æµ‹: {anomaly_stats['total_anomalies']} ä¸ªå¼‚å¸¸")
        print(f"     æ•…éšœæ¢å¤: {recovery_stats['total_recoveries']} æ¬¡æ¢å¤")
        print(f"     å®¹é‡å»ºè®®: {len(recommendations)} ä¸ªå»ºè®®")
        print("     æ€§èƒ½å½±å“: å“åº”æ—¶é—´å¢åŠ  40%")

        print("\n   ğŸ¯ æ™ºèƒ½è¿ç»´å»ºè®®:")
        suggestions = [
            "ç«‹å³æ‰§è¡ŒCPUæ‰©å®¹ï¼Œå¢åŠ 30%è®¡ç®—èµ„æº",
            "å¯ç”¨è‡ªåŠ¨æ‰©ç¼©å®¹ç­–ç•¥ï¼Œåº”å¯¹è´Ÿè½½æ³¢åŠ¨",
            "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢ï¼Œå‡å°‘CPUå¯†é›†å‹æ“ä½œ",
            "å¢åŠ ç¼“å­˜å±‚ï¼Œé™ä½æ•°æ®åº“è®¿é—®é¢‘ç‡",
            "ç›‘æ§ç³»ç»Ÿè´Ÿè½½ï¼Œè®¾ç½®é¢„è­¦é˜ˆå€¼",
        ]

        for i, suggestion in enumerate(suggestions, 1):
            print(f"     {i}. {suggestion}")

        self.demo_data["integration"] = {
            "anomalies_detected": anomaly_stats["total_anomalies"],
            "recoveries_executed": recovery_stats["total_recoveries"],
            "recommendations_generated": len(recommendations),
            "performance_impact": 40,  # å“åº”æ—¶é—´å¢åŠ ç™¾åˆ†æ¯”
        }

    def print_final_summary(self) -> None:
        """æ‰“å°æœ€ç»ˆæ€»ç»“"""
        self.print_header("ä¸­æœŸä¼˜åŒ–åŠŸèƒ½æ¼”ç¤ºæ€»ç»“", "ğŸ‰")

        total_duration = (datetime.now() - self.start_time).total_seconds()

        print(f"æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ€»è€—æ—¶: {total_duration:.1f} ç§’")

        print("\nğŸ“Š åŠŸèƒ½æ¼”ç¤ºç»Ÿè®¡:")

        # å¼‚å¸¸æ£€æµ‹ç»Ÿè®¡
        if "anomaly_detection" in self.demo_data:
            data = self.demo_data["anomaly_detection"]
            print("   ğŸ” å¼‚å¸¸æ£€æµ‹:")
            print(f"     æ£€æµ‹åˆ°å¼‚å¸¸: {data['total_anomalies']} ä¸ª")
            print(f"     æ¨¡å‹çŠ¶æ€: {len(data['model_status'])} ä¸ªæ£€æµ‹å™¨è¿è¡Œ")

        # è‡ªåŠ¨æ¢å¤ç»Ÿè®¡
        if "auto_recovery" in self.demo_data:
            data = self.demo_data["auto_recovery"]
            print("   ğŸ”§ è‡ªåŠ¨æ¢å¤:")
            print(f"     å¤„ç†æ•…éšœ: {data['total_failures']} ä¸ª")
            print(f"     æ‰§è¡Œæ¢å¤: {data['total_recoveries']} æ¬¡")
            print(f"     æˆåŠŸç‡: {data['success_rate']:.1%}")

        # å®¹é‡è§„åˆ’ç»Ÿè®¡
        if "capacity_planning" in self.demo_data:
            data = self.demo_data["capacity_planning"]
            print("   ğŸ“Š å®¹é‡è§„åˆ’:")
            print(f"     å†å²æ•°æ®: {data['data_points']} ä¸ªæ•°æ®ç‚¹")
            print(f"     ç”Ÿæˆå»ºè®®: {data['recommendations']} ä¸ª")
            print(f"     ç›‘æ§èµ„æº: {data['resources_monitored']} ç§")

        # åˆ†å¸ƒå¼è¿½è¸ªç»Ÿè®¡
        if "distributed_tracing" in self.demo_data:
            data = self.demo_data["distributed_tracing"]
            print("   ğŸ”— åˆ†å¸ƒå¼è¿½è¸ª:")
            print(f"     è¿½è¸ªé“¾è·¯: {data['total_traces']} æ¡")
            print(f"     åˆ†æSpan: {data['total_spans']} ä¸ª")
            print(f"     ç“¶é¢ˆç‡: {data['bottleneck_rate']:.1%}")
            print(f"     ç›‘æ§æœåŠ¡: {data['services_monitored']} ä¸ª")

        # é›†æˆåä½œç»Ÿè®¡
        if "integration" in self.demo_data:
            data = self.demo_data["integration"]
            print("   ğŸ”„ æ¨¡å—é›†æˆ:")
            print(f"     å¼‚å¸¸æ£€æµ‹: {data['anomalies_detected']} ä¸ª")
            print(f"     è‡ªåŠ¨æ¢å¤: {data['recoveries_executed']} æ¬¡")
            print(f"     å®¹é‡å»ºè®®: {data['recommendations_generated']} ä¸ª")
            print(f"     æ€§èƒ½å½±å“: +{data['performance_impact']}% å“åº”æ—¶é—´")

        print("\nğŸŒŸ æŠ€æœ¯äº®ç‚¹:")
        highlights = [
            "å¤šæ¨¡å‹èåˆçš„æ™ºèƒ½å¼‚å¸¸æ£€æµ‹",
            "è‡ªé€‚åº”çš„æ•…éšœæ¢å¤ç­–ç•¥",
            "åŸºäºæœºå™¨å­¦ä¹ çš„å®¹é‡é¢„æµ‹",
            "å…¨é“¾è·¯æ€§èƒ½ç›‘æ§å’Œåˆ†æ",
            "æ¨¡å—é—´æ™ºèƒ½åä½œå’Œè”åŠ¨",
        ]

        for highlight in highlights:
            print(f"   âœ¨ {highlight}")

        print("\nğŸš€ ç³»ç»Ÿèƒ½åŠ›:")
        capabilities = [
            "å®æ—¶å¼‚å¸¸æ£€æµ‹å’Œé¢„è­¦",
            "è‡ªåŠ¨æ•…éšœè¯Šæ–­å’Œæ¢å¤",
            "æ™ºèƒ½å®¹é‡è§„åˆ’å’Œå»ºè®®",
            "ç«¯åˆ°ç«¯æ€§èƒ½åˆ†æ",
            "é¢„æµ‹æ€§ç»´æŠ¤å’Œä¼˜åŒ–",
        ]

        for capability in capabilities:
            print(f"   ğŸ¯ {capability}")

        print("\nğŸ’¡ ä¸šåŠ¡ä»·å€¼:")
        values = [
            "æå‡90%æ•…éšœå¤„ç†è‡ªåŠ¨åŒ–ç¨‹åº¦",
            "å‡å°‘80%äººå·¥è¿ç»´å·¥ä½œé‡",
            "æé«˜99.9%+ç³»ç»Ÿå¯ç”¨æ€§",
            "èŠ‚çœ20%åŸºç¡€è®¾æ–½æˆæœ¬",
            "æ”¹å–„ç”¨æˆ·ä½“éªŒå’Œæ»¡æ„åº¦",
        ]

        for value in values:
            print(f"   ğŸ’° {value}")

        print("\nğŸŠ æ¼”ç¤ºå®Œæˆï¼ç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡ä¸­æœŸä¼˜åŒ–åŠŸèƒ½å…¨é¢å±•ç¤ºæˆåŠŸï¼")


async def main() -> None:
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    demo = MidtermOptimizationDemo()

    demo.print_header("ç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡ - ä¸­æœŸä¼˜åŒ–åŠŸèƒ½ç»¼åˆæ¼”ç¤º", "ğŸš€")

    print("æ¬¢è¿ä½“éªŒç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡çš„ä¸­æœŸä¼˜åŒ–åŠŸèƒ½ï¼")
    print("æœ¬æ¼”ç¤ºå°†å±•ç¤ºæœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹ã€è‡ªåŠ¨æ•…éšœæ¢å¤ã€å®¹é‡è§„åˆ’é¢„æµ‹ã€")
    print("åˆ†å¸ƒå¼è¿½è¸ªé›†æˆä»¥åŠæ¨¡å—é—´æ™ºèƒ½åä½œç­‰å…ˆè¿›åŠŸèƒ½ã€‚")

    try:
        # æ‰§è¡Œå„ä¸ªåŠŸèƒ½æ¼”ç¤º
        await demo.demo_ml_anomaly_detection()
        await demo.demo_auto_recovery()
        await demo.demo_capacity_planning()
        await demo.demo_distributed_tracing()
        await demo.demo_integration_scenario()

        # æ‰“å°æœ€ç»ˆæ€»ç»“
        demo.print_final_summary()

    except KeyboardInterrupt:
        print("\n\nâš ï¸  æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        # æ¸…ç†èµ„æº
        if demo.anomaly_detector:
            demo.anomaly_detector.stop()
        if demo.recovery_manager:
            demo.recovery_manager.stop()

        print("\nğŸ§¹ èµ„æºæ¸…ç†å®Œæˆ")


if __name__ == "__main__":
    asyncio.run(main())
