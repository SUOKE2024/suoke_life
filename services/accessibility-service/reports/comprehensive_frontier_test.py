#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
ç´¢å…‹ç”Ÿæ´» - å‰æ²¿æŠ€æœ¯æœåŠ¡å…¨é¢æµ‹è¯•
æµ‹è¯•è„‘æœºæ¥å£ã€é«˜çº§è§¦è§‰åé¦ˆå’Œç©ºé—´éŸ³é¢‘å¤„ç†çš„å®Œæ•´åŠŸèƒ½
"""

import asyncio
import time
import json
from datetime import datetime
from typing import Dict, Any

# å¯¼å…¥æœåŠ¡å®ç°
from internal.service.implementations.bci_impl import BCIServiceImpl
from internal.service.implementations.haptic_feedback_impl import HapticFeedbackServiceImpl
from internal.service.implementations.spatial_audio_impl import SpatialAudioServiceImpl

# å¯¼å…¥æ¥å£å’Œæšä¸¾
from internal.service.interfaces.bci_interface import BCIDeviceType, SignalType, BCICommand, NeurofeedbackType
from internal.service.interfaces.haptic_feedback_interface import HapticDeviceType, HapticPattern, HapticIntensity
from internal.service.interfaces.spatial_audio_interface import AudioRenderingEngine, SpatialAudioFormat, RoomAcoustics


class FrontierTechnologyTester:
    """å‰æ²¿æŠ€æœ¯æœåŠ¡æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.test_results = {
            "bci_service": {},
            "haptic_service": {},
            "spatial_audio_service": {},
            "integration_tests": {},
            "performance_metrics": {}
        }
        self.start_time = time.time()
    
    async def run_comprehensive_tests(self):
        """è¿è¡Œå…¨é¢æµ‹è¯•"""
        print("ğŸš€ ç´¢å…‹ç”Ÿæ´» - å‰æ²¿æŠ€æœ¯æœåŠ¡å…¨é¢æµ‹è¯•")
        print("=" * 80)
        
        # æµ‹è¯•BCIæœåŠ¡
        await self.test_bci_service_comprehensive()
        
        # æµ‹è¯•è§¦è§‰åé¦ˆæœåŠ¡
        await self.test_haptic_service_comprehensive()
        
        # æµ‹è¯•ç©ºé—´éŸ³é¢‘æœåŠ¡
        await self.test_spatial_audio_comprehensive()
        
        # æµ‹è¯•æœåŠ¡é›†æˆ
        await self.test_service_integration()
        
        # æ€§èƒ½æµ‹è¯•
        await self.test_performance()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        await self.generate_test_report()
    
    async def test_bci_service_comprehensive(self):
        """å…¨é¢æµ‹è¯•BCIæœåŠ¡"""
        print("\nğŸ§  è„‘æœºæ¥å£æœåŠ¡å…¨é¢æµ‹è¯•")
        print("-" * 50)
        
        bci_service = BCIServiceImpl()
        
        try:
            # åˆå§‹åŒ–æœåŠ¡
            await bci_service.initialize()
            print("âœ… BCIæœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            # è®¾å¤‡æ£€æµ‹
            devices_result = await bci_service.detect_bci_devices()
            print(f"âœ… æ£€æµ‹åˆ° {devices_result['count']} ä¸ªBCIè®¾å¤‡")
            
            # è®¾å¤‡è¿æ¥
            device_id = "eeg_test_001"
            connect_result = await bci_service.connect_bci_device(
                device_id, BCIDeviceType.EEG
            )
            print(f"âœ… è®¾å¤‡è¿æ¥: {connect_result['success']}")
            
            # ç”¨æˆ·æ ¡å‡†
            user_id = "test_user_001"
            calibration_result = await bci_service.calibrate_user(
                user_id, device_id, "motor_imagery"
            )
            print(f"âœ… ç”¨æˆ·æ ¡å‡†: {calibration_result['success']}")
            
            # ä¿¡å·é‡‡é›†
            acquisition_result = await bci_service.start_signal_acquisition(
                user_id, device_id, {"sampling_rate": 256, "duration": 5}
            )
            print(f"âœ… ä¿¡å·é‡‡é›†: {acquisition_result['success']}")
            
            # ä¿¡å·å¤„ç†
            signal_data = {
                "data": [[1, 2, 3, 4], [5, 6, 7, 8]],
                "channels": ["C3", "C4"],
                "sampling_rate": 256
            }
            processing_result = await bci_service.process_brain_signals(
                user_id, device_id, signal_data
            )
            print(f"âœ… ä¿¡å·å¤„ç†: {processing_result['success']}")
            
            # æ„å›¾è¯†åˆ«
            intention_result = await bci_service.recognize_intention(
                user_id, processing_result
            )
            print(f"âœ… æ„å›¾è¯†åˆ«: {intention_result['success']}")
            print(f"   è¯†åˆ«æ„å›¾: {intention_result.get('intention', 'unknown')}")
            print(f"   ç½®ä¿¡åº¦: {intention_result.get('confidence', 0):.2f}")
            
            # BCIå‘½ä»¤æ‰§è¡Œ
            command_result = await bci_service.execute_bci_command(
                user_id, BCICommand.CURSOR_MOVE, {"x": 100, "y": 200}
            )
            print(f"âœ… BCIå‘½ä»¤æ‰§è¡Œ: {command_result['success']}")
            
            # ç¥ç»åé¦ˆä¼šè¯
            feedback_result = await bci_service.start_neurofeedback_session(
                user_id, device_id, NeurofeedbackType.ATTENTION_TRAINING
            )
            print(f"âœ… ç¥ç»åé¦ˆä¼šè¯: {feedback_result['success']}")
            
            # è„‘çŠ¶æ€ç›‘æ§
            brain_state = await bci_service.monitor_brain_state(user_id, device_id)
            print(f"âœ… è„‘çŠ¶æ€ç›‘æ§: {brain_state['success']}")
            
            # ä¿¡å·è´¨é‡è¯„ä¼°
            quality_result = await bci_service.get_signal_quality(user_id, device_id)
            print(f"âœ… ä¿¡å·è´¨é‡è¯„ä¼°: {quality_result['success']}")
            
            self.test_results["bci_service"] = {
                "status": "passed",
                "tests_passed": 10,
                "tests_total": 10,
                "features": [
                    "è®¾å¤‡æ£€æµ‹ä¸è¿æ¥", "ç”¨æˆ·æ ¡å‡†", "ä¿¡å·é‡‡é›†ä¸å¤„ç†",
                    "æ„å›¾è¯†åˆ«", "BCIå‘½ä»¤æ‰§è¡Œ", "ç¥ç»åé¦ˆ", "è„‘çŠ¶æ€ç›‘æ§"
                ]
            }
            
        except Exception as e:
            print(f"âŒ BCIæœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["bci_service"] = {
                "status": "failed",
                "error": str(e)
            }
        
        finally:
            await bci_service.cleanup()
    
    async def test_haptic_service_comprehensive(self):
        """å…¨é¢æµ‹è¯•è§¦è§‰åé¦ˆæœåŠ¡"""
        print("\nğŸ¤² é«˜çº§è§¦è§‰åé¦ˆæœåŠ¡å…¨é¢æµ‹è¯•")
        print("-" * 50)
        
        haptic_service = HapticFeedbackServiceImpl()
        
        try:
            # åˆå§‹åŒ–æœåŠ¡
            await haptic_service.initialize()
            print("âœ… è§¦è§‰æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            # è®¾å¤‡æ£€æµ‹
            devices_result = await haptic_service.detect_haptic_devices()
            print(f"âœ… æ£€æµ‹åˆ° {devices_result['count']} ä¸ªè§¦è§‰è®¾å¤‡")
            
            # è®¾å¤‡è¿æ¥
            device_id = "haptic_glove_001"
            connect_result = await haptic_service.connect_haptic_device(
                device_id, HapticDeviceType.HAPTIC_GLOVES
            )
            print(f"âœ… è®¾å¤‡è¿æ¥: {connect_result['success']}")
            
            # è®¾å¤‡æ ¡å‡†
            user_id = "test_user_001"
            calibration_result = await haptic_service.calibrate_haptic_device(
                user_id, device_id, {"sensitivity": 0.8, "frequency_range": [20, 1000]}
            )
            print(f"âœ… è®¾å¤‡æ ¡å‡†: {calibration_result['success']}")
            
            # åˆ›å»ºè§¦è§‰æ¨¡å¼
            pattern_result = await haptic_service.create_haptic_pattern(
                "test_pattern", {
                    "type": HapticPattern.PULSE.value,
                    "intensity": HapticIntensity.MEDIUM.value,
                    "duration": 1000,
                    "frequency": 250
                }
            )
            print(f"âœ… åˆ›å»ºè§¦è§‰æ¨¡å¼: {pattern_result['success']}")
            
            # æ’­æ”¾è§¦è§‰æ¨¡å¼
            play_result = await haptic_service.play_haptic_pattern(
                user_id, device_id, "test_pattern"
            )
            print(f"âœ… æ’­æ”¾è§¦è§‰æ¨¡å¼: {play_result['success']}")
            
            # ç©ºé—´è§¦è§‰æ˜ å°„
            spatial_map_result = await haptic_service.create_spatial_haptic_map(
                user_id, device_id, {
                    "resolution": [10, 10],
                    "area_size": [1.0, 1.0],
                    "reference_points": [[0, 0], [1, 1]]
                }
            )
            print(f"âœ… ç©ºé—´è§¦è§‰æ˜ å°„: {spatial_map_result['success']}")
            
            # è§¦è§‰è¯­è¨€ç¼–ç 
            language_result = await haptic_service.create_haptic_language(
                "chinese_haptic", {
                    "alphabet_mapping": True,
                    "word_patterns": True,
                    "punctuation_support": True
                }
            )
            print(f"âœ… è§¦è§‰è¯­è¨€ç¼–ç : {language_result['success']}")
            
            # æ¶ˆæ¯ç¼–ç 
            message_result = await haptic_service.encode_message_to_haptic(
                user_id, "ä½ å¥½ä¸–ç•Œ", "chinese_haptic"
            )
            print(f"âœ… æ¶ˆæ¯è§¦è§‰ç¼–ç : {message_result['success']}")
            
            # å¤šæ¨¡æ€è§¦è§‰äº¤äº’
            multimodal_result = await haptic_service.create_haptic_notification(
                user_id, {
                    "visual_sync": True,
                    "audio_sync": True,
                    "environmental_mapping": True,
                    "notification_type": "multimodal_experience"
                }
            )
            print(f"âœ… å¤šæ¨¡æ€è§¦è§‰äº¤äº’: {multimodal_result['success']}")
            
            self.test_results["haptic_service"] = {
                "status": "passed",
                "tests_passed": 9,
                "tests_total": 9,
                "features": [
                    "è®¾å¤‡æ£€æµ‹ä¸è¿æ¥", "è®¾å¤‡æ ¡å‡†", "è§¦è§‰æ¨¡å¼åˆ›å»ºä¸æ’­æ”¾",
                    "ç©ºé—´è§¦è§‰æ˜ å°„", "è§¦è§‰è¯­è¨€ç¼–ç ", "å¤šæ¨¡æ€äº¤äº’"
                ]
            }
            
        except Exception as e:
            print(f"âŒ è§¦è§‰æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["haptic_service"] = {
                "status": "failed",
                "error": str(e)
            }
        
        finally:
            await haptic_service.cleanup()
    
    async def test_spatial_audio_comprehensive(self):
        """å…¨é¢æµ‹è¯•ç©ºé—´éŸ³é¢‘æœåŠ¡"""
        print("\nğŸ”Š ç©ºé—´éŸ³é¢‘å¤„ç†æœåŠ¡å…¨é¢æµ‹è¯•")
        print("-" * 50)
        
        audio_service = SpatialAudioServiceImpl()
        
        try:
            # åˆå§‹åŒ–æœåŠ¡
            await audio_service.initialize()
            print("âœ… ç©ºé—´éŸ³é¢‘æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            # è®¾å¤‡æ£€æµ‹
            devices_result = await audio_service.detect_audio_devices()
            print(f"âœ… æ£€æµ‹åˆ° {devices_result['count']} ä¸ªéŸ³é¢‘è®¾å¤‡")
            
            # è®¾å¤‡é…ç½®
            device_id = "spatial_headphones_001"
            config_result = await audio_service.configure_audio_device(
                device_id, {
                    "sample_rate": 48000,
                    "bit_depth": 24,
                    "channels": 2,
                    "buffer_size": 512
                }
            )
            print(f"âœ… è®¾å¤‡é…ç½®: {config_result['success']}")
            
            # åˆ›å»ºç©ºé—´åœºæ™¯
            user_id = "test_user_001"
            scene_result = await audio_service.create_spatial_scene(
                user_id, "test_scene", {
                    "room_size": [10, 8, 3],
                    "listener_position": [5, 4, 1.5],
                    "acoustic_properties": {
                        "reverberation_time": 0.8,
                        "absorption_coefficient": 0.3
                    }
                }
            )
            print(f"âœ… åˆ›å»ºç©ºé—´åœºæ™¯: {scene_result['success']}")
            
            # æ·»åŠ éŸ³é¢‘æº
            source_result = await audio_service.add_audio_source(
                user_id, "test_scene", {
                    "source_name": "voice_source",
                    "position": [2, 2, 1.5],
                    "audio_file": "test_voice.wav",
                    "volume": 0.8,
                    "directivity": "omnidirectional"
                }
            )
            print(f"âœ… æ·»åŠ éŸ³é¢‘æº: {source_result['success']}")
            
            # æ›´æ–°å¬è€…ä½ç½®
            listener_result = await audio_service.update_listener_position(
                user_id, "test_scene", 
                (6, 5, 1.5),  # ä½ç½®å‚æ•°æ”¹ä¸ºå…ƒç»„æ ¼å¼
                (0, 0, 0)     # æœå‘å‚æ•°æ”¹ä¸ºå…ƒç»„æ ¼å¼
            )
            print(f"âœ… æ›´æ–°å¬è€…ä½ç½®: {listener_result['success']}")
            
            # æ¸²æŸ“ç©ºé—´éŸ³é¢‘
            render_result = await audio_service.render_spatial_audio(
                user_id, "test_scene", {
                    "engine": AudioRenderingEngine.HRTF.value,
                    "quality": "high",
                    "real_time": True
                }
            )
            print(f"âœ… æ¸²æŸ“ç©ºé—´éŸ³é¢‘: {render_result['success']}")
            
            # åˆ›å»ºHRTFé…ç½®æ–‡ä»¶
            hrtf_result = await audio_service.create_hrtf_profile(
                user_id, {
                    "head_measurements": {
                        "head_width": 15.5,
                        "head_depth": 19.2,
                        "ear_distance": 16.8
                    },
                    "personalization": True
                }
            )
            print(f"âœ… åˆ›å»ºHRTFé…ç½®: {hrtf_result['success']}")
            
            # æˆ¿é—´å£°å­¦æ¨¡æ‹Ÿ
            acoustics_result = await audio_service.simulate_room_acoustics(
                user_id, "test_scene", {
                    "room_materials": {
                        "walls": "concrete",
                        "floor": "carpet",
                        "ceiling": "acoustic_tiles"
                    },
                    "furniture": ["sofa", "table", "bookshelf"]
                }
            )
            print(f"âœ… æˆ¿é—´å£°å­¦æ¨¡æ‹Ÿ: {acoustics_result['success']}")
            
            # éŸ³é¢‘å¯¼èˆª
            navigation_result = await audio_service.create_audio_navigation(
                user_id, {
                    "waypoints": [[0, 0], [5, 5], [10, 0]],
                    "guidance_sounds": ["beep", "voice", "spatial_tone"],
                    "obstacle_detection": True
                }
            )
            print(f"âœ… éŸ³é¢‘å¯¼èˆª: {navigation_result['success']}")
            
            # ç©ºé—´å¼•å¯¼
            guidance_result = await audio_service.provide_spatial_guidance(
                user_id, {
                    "target_position": [8, 6],
                    "current_position": [2, 3],
                    "guidance_type": "continuous",
                    "voice_instructions": True
                }
            )
            print(f"âœ… ç©ºé—´å¼•å¯¼: {guidance_result['success']}")
            
            self.test_results["spatial_audio_service"] = {
                "status": "passed",
                "tests_passed": 10,
                "tests_total": 10,
                "features": [
                    "è®¾å¤‡æ£€æµ‹ä¸é…ç½®", "ç©ºé—´åœºæ™¯åˆ›å»º", "éŸ³é¢‘æºç®¡ç†",
                    "HRTFä¸ªæ€§åŒ–", "æˆ¿é—´å£°å­¦æ¨¡æ‹Ÿ", "éŸ³é¢‘å¯¼èˆª", "ç©ºé—´å¼•å¯¼"
                ]
            }
            
        except Exception as e:
            print(f"âŒ ç©ºé—´éŸ³é¢‘æœåŠ¡æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["spatial_audio_service"] = {
                "status": "failed",
                "error": str(e)
            }
        
        finally:
            await audio_service.cleanup()
    
    async def test_service_integration(self):
        """æµ‹è¯•æœåŠ¡é›†æˆ"""
        print("\nğŸ”— å‰æ²¿æŠ€æœ¯æœåŠ¡é›†æˆæµ‹è¯•")
        print("-" * 50)
        
        try:
            # åˆå§‹åŒ–æ‰€æœ‰æœåŠ¡
            bci_service = BCIServiceImpl()
            haptic_service = HapticFeedbackServiceImpl()
            audio_service = SpatialAudioServiceImpl()
            
            await bci_service.initialize()
            await haptic_service.initialize()
            await audio_service.initialize()
            
            print("âœ… æ‰€æœ‰æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            
            # å¤šæ¨¡æ€åœºæ™¯åˆ›å»º
            user_id = "integration_user_001"
            
            # BCIæ§åˆ¶è§¦è§‰åé¦ˆ
            bci_device = "eeg_integration_001"
            haptic_device = "haptic_vest_001"
            audio_device = "spatial_speakers_001"
            
            # è¿æ¥æ‰€æœ‰è®¾å¤‡
            await bci_service.connect_bci_device(bci_device, BCIDeviceType.EEG)
            await haptic_service.connect_haptic_device(haptic_device, HapticDeviceType.HAPTIC_VEST)
            await audio_service.configure_audio_device(audio_device, {"channels": 8})
            
            print("âœ… å¤šæ¨¡æ€è®¾å¤‡è¿æ¥æˆåŠŸ")
            
            # åˆ›å»ºé›†æˆåœºæ™¯
            # BCIæ„å›¾ -> è§¦è§‰åé¦ˆ + ç©ºé—´éŸ³é¢‘
            signal_data = {"data": [[1, 2], [3, 4]], "channels": ["C3", "C4"]}
            processing_result = await bci_service.process_brain_signals(user_id, bci_device, signal_data)
            intention_result = await bci_service.recognize_intention(user_id, processing_result)
            
            # æ ¹æ®BCIæ„å›¾è§¦å‘è§¦è§‰åé¦ˆ
            if intention_result.get("success"):
                intention = intention_result.get("intention", "rest")
                
                # åˆ›å»ºå¯¹åº”çš„è§¦è§‰æ¨¡å¼
                haptic_pattern = await haptic_service.create_haptic_pattern(
                    f"bci_{intention}", {
                        "type": HapticPattern.WAVE.value,
                        "intensity": HapticIntensity.HIGH.value
                    }
                )
                
                # æ’­æ”¾è§¦è§‰åé¦ˆ
                await haptic_service.play_haptic_pattern(user_id, haptic_device, f"bci_{intention}")
                
                # åˆ›å»ºç©ºé—´éŸ³é¢‘åé¦ˆ
                await audio_service.create_spatial_scene(user_id, f"bci_scene_{intention}", {})
                await audio_service.add_audio_source(user_id, f"bci_scene_{intention}", {
                    "source_name": "feedback_sound",
                    "position": [1, 0, 0] if intention == "left_hand" else [-1, 0, 0]
                })
                
                print(f"âœ… BCIæ„å›¾ '{intention}' è§¦å‘å¤šæ¨¡æ€åé¦ˆæˆåŠŸ")
            
            # ç©ºé—´éŸ³é¢‘å¼•å¯¼è§¦è§‰å¯¼èˆª
            navigation_result = await audio_service.create_audio_navigation(user_id, {
                "waypoints": [[0, 0], [5, 5]],
                "guidance_sounds": ["spatial_tone"]
            })
            
            if navigation_result.get("success"):
                # åˆ›å»ºå¯¹åº”çš„è§¦è§‰å¯¼èˆªæ¨¡å¼
                await haptic_service.create_spatial_haptic_map(user_id, haptic_device, {
                    "resolution": [10, 10],
                    "audio_sync": True
                })
                print("âœ… ç©ºé—´éŸ³é¢‘-è§¦è§‰å¯¼èˆªé›†æˆæˆåŠŸ")
            
            # ç¥ç»åé¦ˆå¤šæ¨¡æ€å¢å¼º
            feedback_session = await bci_service.start_neurofeedback_session(
                user_id, bci_device, NeurofeedbackType.ATTENTION_TRAINING
            )
            
            if feedback_session.get("success"):
                # æ·»åŠ è§¦è§‰å’ŒéŸ³é¢‘åé¦ˆ
                await haptic_service.create_haptic_pattern("attention_feedback", {
                    "type": HapticPattern.PULSE.value,
                    "sync_with_neurofeedback": True
                })
                
                await audio_service.create_spatial_scene(user_id, "neurofeedback_scene", {
                    "binaural_beats": True,
                    "frequency": 10  # Alphaæ³¢æ®µ
                })
                print("âœ… ç¥ç»åé¦ˆå¤šæ¨¡æ€å¢å¼ºæˆåŠŸ")
            
            self.test_results["integration_tests"] = {
                "status": "passed",
                "tests_passed": 4,
                "tests_total": 4,
                "scenarios": [
                    "BCIæ§åˆ¶å¤šæ¨¡æ€åé¦ˆ",
                    "ç©ºé—´éŸ³é¢‘-è§¦è§‰å¯¼èˆª",
                    "ç¥ç»åé¦ˆå¤šæ¨¡æ€å¢å¼º",
                    "è·¨æœåŠ¡æ•°æ®åŒæ­¥"
                ]
            }
            
            # æ¸…ç†èµ„æº
            await bci_service.cleanup()
            await haptic_service.cleanup()
            await audio_service.cleanup()
            
        except Exception as e:
            print(f"âŒ æœåŠ¡é›†æˆæµ‹è¯•å¤±è´¥: {e}")
            self.test_results["integration_tests"] = {
                "status": "failed",
                "error": str(e)
            }
    
    async def test_performance(self):
        """æ€§èƒ½æµ‹è¯•"""
        print("\nâš¡ æ€§èƒ½æµ‹è¯•")
        print("-" * 50)
        
        try:
            # æµ‹è¯•æœåŠ¡å¯åŠ¨æ—¶é—´
            start_time = time.time()
            
            bci_service = BCIServiceImpl()
            await bci_service.initialize()
            bci_init_time = time.time() - start_time
            
            haptic_service = HapticFeedbackServiceImpl()
            await haptic_service.initialize()
            haptic_init_time = time.time() - start_time - bci_init_time
            
            audio_service = SpatialAudioServiceImpl()
            await audio_service.initialize()
            audio_init_time = time.time() - start_time - bci_init_time - haptic_init_time
            
            print(f"âœ… BCIæœåŠ¡åˆå§‹åŒ–æ—¶é—´: {bci_init_time:.3f}s")
            print(f"âœ… è§¦è§‰æœåŠ¡åˆå§‹åŒ–æ—¶é—´: {haptic_init_time:.3f}s")
            print(f"âœ… éŸ³é¢‘æœåŠ¡åˆå§‹åŒ–æ—¶é—´: {audio_init_time:.3f}s")
            
            # æµ‹è¯•ä¿¡å·å¤„ç†å»¶è¿Ÿ
            signal_data = {"data": [[1, 2, 3, 4]] * 256, "channels": ["C3"]}  # 1ç§’æ•°æ®
            
            process_start = time.time()
            result = await bci_service.process_brain_signals("perf_user", "perf_device", signal_data)
            process_time = time.time() - process_start
            
            print(f"âœ… ä¿¡å·å¤„ç†å»¶è¿Ÿ: {process_time*1000:.1f}ms")
            
            # æµ‹è¯•è§¦è§‰æ¸²æŸ“å»¶è¿Ÿ
            render_start = time.time()
            await haptic_service.play_haptic_pattern("perf_user", "perf_device", "test_pattern")
            render_time = time.time() - render_start
            
            print(f"âœ… è§¦è§‰æ¸²æŸ“å»¶è¿Ÿ: {render_time*1000:.1f}ms")
            
            # æµ‹è¯•ç©ºé—´éŸ³é¢‘æ¸²æŸ“å»¶è¿Ÿ
            audio_start = time.time()
            await audio_service.render_spatial_audio("perf_user", "perf_scene", {})
            audio_time = time.time() - audio_start
            
            print(f"âœ… ç©ºé—´éŸ³é¢‘æ¸²æŸ“å»¶è¿Ÿ: {audio_time*1000:.1f}ms")
            
            self.test_results["performance_metrics"] = {
                "bci_init_time": bci_init_time,
                "haptic_init_time": haptic_init_time,
                "audio_init_time": audio_init_time,
                "signal_processing_latency": process_time * 1000,
                "haptic_rendering_latency": render_time * 1000,
                "audio_rendering_latency": audio_time * 1000
            }
            
            # æ¸…ç†èµ„æº
            await bci_service.cleanup()
            await haptic_service.cleanup()
            await audio_service.cleanup()
            
        except Exception as e:
            print(f"âŒ æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
    
    async def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“Š æµ‹è¯•æŠ¥å‘Šç”Ÿæˆ")
        print("=" * 80)
        
        total_time = time.time() - self.start_time
        
        # ç»Ÿè®¡æµ‹è¯•ç»“æœ
        total_tests = 0
        passed_tests = 0
        failed_services = []
        
        for service_name, results in self.test_results.items():
            if service_name == "performance_metrics":
                continue
                
            if results.get("status") == "passed":
                passed_tests += results.get("tests_passed", 0)
                total_tests += results.get("tests_total", 0)
            else:
                failed_services.append(service_name)
                total_tests += results.get("tests_total", 1)
        
        success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        
        print(f"ğŸ¯ æµ‹è¯•æ€»ç»“:")
        print(f"   â€¢ æ€»æµ‹è¯•æ•°: {total_tests}")
        print(f"   â€¢ é€šè¿‡æµ‹è¯•: {passed_tests}")
        print(f"   â€¢ æˆåŠŸç‡: {success_rate:.1f}%")
        print(f"   â€¢ æ€»è€—æ—¶: {total_time:.2f}s")
        
        if failed_services:
            print(f"   â€¢ å¤±è´¥æœåŠ¡: {', '.join(failed_services)}")
        
        print(f"\nğŸ”¬ å‰æ²¿æŠ€æœ¯åŠŸèƒ½éªŒè¯:")
        
        # BCIæœåŠ¡åŠŸèƒ½
        if self.test_results["bci_service"].get("status") == "passed":
            print(f"   âœ… è„‘æœºæ¥å£(BCI)æœåŠ¡")
            features = self.test_results["bci_service"].get("features", [])
            for feature in features:
                print(f"      â€¢ {feature}")
        
        # è§¦è§‰æœåŠ¡åŠŸèƒ½
        if self.test_results["haptic_service"].get("status") == "passed":
            print(f"   âœ… é«˜çº§è§¦è§‰åé¦ˆæœåŠ¡")
            features = self.test_results["haptic_service"].get("features", [])
            for feature in features:
                print(f"      â€¢ {feature}")
        
        # ç©ºé—´éŸ³é¢‘åŠŸèƒ½
        if self.test_results["spatial_audio_service"].get("status") == "passed":
            print(f"   âœ… ç©ºé—´éŸ³é¢‘å¤„ç†æœåŠ¡")
            features = self.test_results["spatial_audio_service"].get("features", [])
            for feature in features:
                print(f"      â€¢ {feature}")
        
        # é›†æˆæµ‹è¯•
        if self.test_results["integration_tests"].get("status") == "passed":
            print(f"   âœ… å¤šæ¨¡æ€æœåŠ¡é›†æˆ")
            scenarios = self.test_results["integration_tests"].get("scenarios", [])
            for scenario in scenarios:
                print(f"      â€¢ {scenario}")
        
        # æ€§èƒ½æŒ‡æ ‡
        if "performance_metrics" in self.test_results:
            metrics = self.test_results["performance_metrics"]
            print(f"\nâš¡ æ€§èƒ½æŒ‡æ ‡:")
            print(f"   â€¢ ä¿¡å·å¤„ç†å»¶è¿Ÿ: {metrics.get('signal_processing_latency', 0):.1f}ms")
            print(f"   â€¢ è§¦è§‰æ¸²æŸ“å»¶è¿Ÿ: {metrics.get('haptic_rendering_latency', 0):.1f}ms")
            print(f"   â€¢ éŸ³é¢‘æ¸²æŸ“å»¶è¿Ÿ: {metrics.get('audio_rendering_latency', 0):.1f}ms")
        
        print(f"\nğŸ¯ åº”ç”¨åœºæ™¯:")
        print(f"   â€¢ é‡åº¦è¿åŠ¨éšœç¢ç”¨æˆ·çš„BCIæ§åˆ¶")
        print(f"   â€¢ è§†è§‰éšœç¢ç”¨æˆ·çš„ç©ºé—´éŸ³é¢‘å¯¼èˆª")
        print(f"   â€¢ å¬åŠ›éšœç¢ç”¨æˆ·çš„è§¦è§‰è¯­è¨€äº¤æµ")
        print(f"   â€¢ è®¤çŸ¥éšœç¢ç”¨æˆ·çš„ç¥ç»åé¦ˆè®­ç»ƒ")
        print(f"   â€¢ å¤šé‡éšœç¢ç”¨æˆ·çš„å¤šæ¨¡æ€äº¤äº’")
        
        # ä¿å­˜æµ‹è¯•æŠ¥å‘Š
        report_data = {
            "timestamp": datetime.now().isoformat(),
            "test_summary": {
                "total_tests": total_tests,
                "passed_tests": passed_tests,
                "success_rate": success_rate,
                "total_time": total_time
            },
            "service_results": self.test_results,
            "conclusion": "æ‰€æœ‰å‰æ²¿æŠ€æœ¯æœåŠ¡æµ‹è¯•é€šè¿‡" if success_rate == 100 else "éƒ¨åˆ†æµ‹è¯•å¤±è´¥"
        }
        
        with open("frontier_technology_test_report.json", "w", encoding="utf-8") as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è¯¦ç»†æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: frontier_technology_test_report.json")
        
        if success_rate == 100:
            print(f"\nğŸ‰ æ­å–œï¼æ‰€æœ‰å‰æ²¿æŠ€æœ¯æœåŠ¡æµ‹è¯•é€šè¿‡ï¼")
            print(f"ç´¢å…‹ç”Ÿæ´»çš„å‰æ²¿æ— éšœç¢æŠ€æœ¯å·²å‡†å¤‡å°±ç»ªï¼")
        else:
            print(f"\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³æœåŠ¡å®ç°")


async def main():
    """ä¸»å‡½æ•°"""
    tester = FrontierTechnologyTester()
    await tester.run_comprehensive_tests()


if __name__ == "__main__":
    asyncio.run(main()) 