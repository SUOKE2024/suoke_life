"""
å®¹é‡è§„åˆ’å’Œé¢„æµ‹æ¨¡å—

å®ç°åŸºäºå†å²æ•°æ®çš„å®¹é‡é¢„æµ‹ï¼ŒåŒ…æ‹¬ï¼š
- èµ„æºä½¿ç”¨è¶‹åŠ¿åˆ†æ
- å®¹é‡é¢„æµ‹ç®—æ³•
- æ‰©å®¹å»ºè®®ç”Ÿæˆ
- æˆæœ¬ä¼˜åŒ–åˆ†æ
"""

import logging
import threading
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any

logger = logging.getLogger(__name__)


class ResourceType(Enum):
    """èµ„æºç±»å‹æšä¸¾"""

    CPU = "cpu"
    MEMORY = "memory"
    DISK = "disk"
    NETWORK = "network"


class PredictionModel(Enum):
    """é¢„æµ‹æ¨¡å‹æšä¸¾"""

    LINEAR = "linear"
    MOVING_AVERAGE = "moving_average"


class ScalingDirection(Enum):
    """æ‰©å®¹æ–¹å‘æšä¸¾"""

    SCALE_UP = "scale_up"
    SCALE_DOWN = "scale_down"
    MAINTAIN = "maintain"


@dataclass
class ResourceMetric:
    """èµ„æºæŒ‡æ ‡"""

    timestamp: datetime
    resource_type: ResourceType
    value: float
    unit: str
    metadata: dict[str, Any] = field(default_factory=dict)


@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœ"""

    resource_type: ResourceType
    model_type: PredictionModel
    predicted_value: float
    confidence: float
    prediction_time: datetime
    target_time: datetime
    trend: str
    context: dict[str, Any] = field(default_factory=dict)


@dataclass
class CapacityRecommendation:
    """å®¹é‡å»ºè®®"""

    resource_type: ResourceType
    current_capacity: float
    predicted_demand: float
    recommended_capacity: float
    scaling_direction: ScalingDirection
    urgency: str
    cost_impact: float
    timeline: str
    reasoning: str
    context: dict[str, Any] = field(default_factory=dict)


class LinearPredictor:
    """çº¿æ€§é¢„æµ‹å™¨"""

    def __init__(self, window_size: int = 100):
        self.window_size = window_size
        self.data_buffer = deque(maxlen=window_size)

    def add_data(self, timestamp: datetime, value: float) -> None:
        """æ·»åŠ æ•°æ®ç‚¹"""
        self.data_buffer.append((timestamp, value))

    def predict(self, target_time: datetime) -> PredictionResult | None:
        """çº¿æ€§é¢„æµ‹"""
        if len(self.data_buffer) < 10:
            return None

        # è½¬æ¢æ—¶é—´æˆ³ä¸ºæ•°å€¼
        base_time = self.data_buffer[0][0]
        x_data = []
        y_data = []

        for timestamp, value in self.data_buffer:
            x = (timestamp - base_time).total_seconds()
            x_data.append(x)
            y_data.append(value)

        x_array = np.array(x_data)
        y_array = np.array(y_data)

        # çº¿æ€§å›å½’
        n = len(x_array)
        slope = (n * np.sum(x_array * y_array) - np.sum(x_array) * np.sum(y_array)) / (
            n * np.sum(x_array**2) - np.sum(x_array) ** 2
        )
        intercept = (np.sum(y_array) - slope * np.sum(x_array)) / n

        # é¢„æµ‹ç›®æ ‡æ—¶é—´çš„å€¼
        target_x = (target_time - base_time).total_seconds()
        predicted_value = slope * target_x + intercept

        # è®¡ç®—ç½®ä¿¡åº¦
        y_pred = slope * x_array + intercept
        ss_res = np.sum((y_array - y_pred) ** 2)
        ss_tot = np.sum((y_array - np.mean(y_array)) ** 2)
        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
        confidence = max(0, min(1, r_squared))

        # åˆ¤æ–­è¶‹åŠ¿
        if slope > 0.01:
            trend = "increasing"
        elif slope < -0.01:
            trend = "decreasing"
        else:
            trend = "stable"

        return PredictionResult(
            resource_type=ResourceType.CPU,
            model_type=PredictionModel.LINEAR,
            predicted_value=max(0, predicted_value),
            confidence=confidence,
            prediction_time=datetime.now(),
            target_time=target_time,
            trend=trend,
            context={
                "slope": slope,
                "intercept": intercept,
                "r_squared": r_squared,
                "data_points": len(self.data_buffer),
            },
        )


class CapacityPlanner:
    """å®¹é‡è§„åˆ’å™¨"""

    def __init__(self, config: dict[str, Any] | None = None):
        self.config = config or {}
        self.predictors = {}
        self.resource_data = defaultdict(lambda: deque(maxlen=1000))
        self.capacity_limits = {}
        self.lock = threading.Lock()

        # åˆå§‹åŒ–é¢„æµ‹å™¨
        self._initialize_predictors()

        # è®¾ç½®é»˜è®¤å®¹é‡é™åˆ¶
        self._initialize_capacity_limits()

    def _initialize_predictors(self) -> None:
        """åˆå§‹åŒ–é¢„æµ‹å™¨"""
        for resource_type in ResourceType:
            self.predictors[resource_type] = {
                PredictionModel.LINEAR: LinearPredictor(
                    window_size=self.config.get("linear_window", 100)
                )
            }

    def _initialize_capacity_limits(self) -> None:
        """åˆå§‹åŒ–å®¹é‡é™åˆ¶"""
        self.capacity_limits = {
            ResourceType.CPU: {"max": 100, "warning": 80, "critical": 95},
            ResourceType.MEMORY: {"max": 100, "warning": 80, "critical": 95},
            ResourceType.DISK: {"max": 100, "warning": 85, "critical": 95},
            ResourceType.NETWORK: {"max": 1000, "warning": 800, "critical": 950},
        }

    def add_metric(self, metric: ResourceMetric) -> None:
        """æ·»åŠ èµ„æºæŒ‡æ ‡"""
        with self.lock:
            self.resource_data[metric.resource_type].append(metric)

            # æ›´æ–°é¢„æµ‹å™¨
            for predictor in self.predictors[metric.resource_type].values():
                predictor.add_data(metric.timestamp, metric.value)

    def predict_resource_usage(
        self, resource_type: ResourceType, target_time: datetime
    ) -> list[PredictionResult]:
        """é¢„æµ‹èµ„æºä½¿ç”¨æƒ…å†µ"""
        results = []

        with self.lock:
            for pred_model, predictor in self.predictors[resource_type].items():
                result = predictor.predict(target_time)
                if result:
                    result.resource_type = resource_type
                    results.append(result)

        return results

    def generate_capacity_recommendations(
        self, time_horizon: timedelta = timedelta(days=30)
    ) -> list[CapacityRecommendation]:
        """ç”Ÿæˆå®¹é‡å»ºè®®"""
        recommendations = []
        target_time = datetime.now() + time_horizon

        for resource_type in ResourceType:
            # è·å–é¢„æµ‹ç»“æœ
            predictions = self.predict_resource_usage(resource_type, target_time)

            if not predictions:
                continue

            # é€‰æ‹©æœ€å¯ä¿¡çš„é¢„æµ‹
            best_prediction = max(predictions, key=lambda p: p.confidence)

            # è·å–å½“å‰å®¹é‡
            current_capacity = self.capacity_limits[resource_type]["max"]
            predicted_demand = best_prediction.predicted_value

            # ç”Ÿæˆå»ºè®®
            recommendation = self._generate_recommendation(
                resource_type, current_capacity, predicted_demand, best_prediction
            )

            if recommendation:
                recommendations.append(recommendation)

        return recommendations

    def _generate_recommendation(
        self,
        resource_type: ResourceType,
        current_capacity: float,
        predicted_demand: float,
        prediction: PredictionResult,
    ) -> CapacityRecommendation | None:
        """ç”Ÿæˆå•ä¸ªèµ„æºçš„å®¹é‡å»ºè®®"""
        limits = self.capacity_limits[resource_type]
        warning_threshold = limits["warning"]
        critical_threshold = limits["critical"]

        # è®¡ç®—ä½¿ç”¨ç‡
        usage_rate = predicted_demand / current_capacity if current_capacity > 0 else 0

        # ç¡®å®šæ‰©å®¹æ–¹å‘å’Œå»ºè®®å®¹é‡
        if usage_rate > critical_threshold / 100:
            scaling_direction = ScalingDirection.SCALE_UP
            recommended_capacity = predicted_demand * 1.3
            urgency = "critical"
            timeline = "ç«‹å³"
        elif usage_rate > warning_threshold / 100:
            scaling_direction = ScalingDirection.SCALE_UP
            recommended_capacity = predicted_demand * 1.2
            urgency = "high"
            timeline = "1-2å‘¨å†…"
        elif usage_rate < 0.5:
            scaling_direction = ScalingDirection.SCALE_DOWN
            recommended_capacity = predicted_demand * 1.5
            urgency = "low"
            timeline = "1-3ä¸ªæœˆå†…"
        else:
            scaling_direction = ScalingDirection.MAINTAIN
            recommended_capacity = current_capacity
            urgency = "low"
            timeline = "æ— éœ€è°ƒæ•´"

        # è®¡ç®—æˆæœ¬å½±å“
        capacity_change = recommended_capacity - current_capacity
        cost_impact = capacity_change * 0.1

        # ç”Ÿæˆæ¨ç†è¯´æ˜
        reasoning = self._generate_reasoning(
            resource_type, usage_rate, prediction, scaling_direction
        )

        return CapacityRecommendation(
            resource_type=resource_type,
            current_capacity=current_capacity,
            predicted_demand=predicted_demand,
            recommended_capacity=recommended_capacity,
            scaling_direction=scaling_direction,
            urgency=urgency,
            cost_impact=cost_impact,
            timeline=timeline,
            reasoning=reasoning,
            context={
                "usage_rate": usage_rate,
                "prediction_confidence": prediction.confidence,
                "trend": prediction.trend,
                "model_type": prediction.model_type.value,
            },
        )

    def _generate_reasoning(
        self,
        resource_type: ResourceType,
        usage_rate: float,
        prediction: PredictionResult,
        scaling_direction: ScalingDirection,
    ) -> str:
        """ç”Ÿæˆæ¨ç†è¯´æ˜"""
        resource_name = resource_type.value.upper()
        trend_desc = {"increasing": "ä¸Šå‡", "decreasing": "ä¸‹é™", "stable": "ç¨³å®š"}.get(
            prediction.trend, "æœªçŸ¥"
        )

        confidence_desc = (
            "é«˜"
            if prediction.confidence > 0.8
            else "ä¸­" if prediction.confidence > 0.5 else "ä½"
        )

        if scaling_direction == ScalingDirection.SCALE_UP:
            return (
                f"{resource_name}ä½¿ç”¨ç‡é¢„è®¡è¾¾åˆ°{usage_rate:.1%}ï¼Œå‘ˆ{trend_desc}è¶‹åŠ¿ã€‚"
                f"åŸºäº{prediction.model_type.value}æ¨¡å‹é¢„æµ‹ï¼ˆç½®ä¿¡åº¦ï¼š{confidence_desc}ï¼‰ï¼Œ"
                f"å»ºè®®æ‰©å®¹ä»¥é¿å…æ€§èƒ½ç“¶é¢ˆã€‚"
            )
        elif scaling_direction == ScalingDirection.SCALE_DOWN:
            return (
                f"{resource_name}ä½¿ç”¨ç‡é¢„è®¡ä»…ä¸º{usage_rate:.1%}ï¼Œå‘ˆ{trend_desc}è¶‹åŠ¿ã€‚"
                f"åŸºäº{prediction.model_type.value}æ¨¡å‹é¢„æµ‹ï¼ˆç½®ä¿¡åº¦ï¼š{confidence_desc}ï¼‰ï¼Œ"
                f"å¯è€ƒè™‘ç¼©å®¹ä»¥ä¼˜åŒ–æˆæœ¬ã€‚"
            )
        else:
            return (
                f"{resource_name}ä½¿ç”¨ç‡é¢„è®¡ä¸º{usage_rate:.1%}ï¼Œå‘ˆ{trend_desc}è¶‹åŠ¿ã€‚"
                f"åŸºäº{prediction.model_type.value}æ¨¡å‹é¢„æµ‹ï¼ˆç½®ä¿¡åº¦ï¼š{confidence_desc}ï¼‰ï¼Œ"
                f"å½“å‰å®¹é‡é…ç½®åˆç†ã€‚"
            )

    def get_capacity_status(self) -> dict[str, Any]:
        """è·å–å®¹é‡çŠ¶æ€"""
        with self.lock:
            status = {}

            for resource_type in ResourceType:
                resource_data = list(self.resource_data[resource_type])

                if not resource_data:
                    status[resource_type.value] = {
                        "current_usage": 0,
                        "data_points": 0,
                        "last_update": None,
                    }
                    continue

                # è·å–æœ€æ–°æ•°æ®
                latest_metric = resource_data[-1]
                current_usage = latest_metric.value

                status[resource_type.value] = {
                    "current_usage": current_usage,
                    "data_points": len(resource_data),
                    "last_update": latest_metric.timestamp.isoformat(),
                }

            return status


# å…¨å±€å®¹é‡è§„åˆ’å™¨å®ä¾‹
_global_capacity_planner: CapacityPlanner | None = None


def get_capacity_planner(config: dict[str, Any] | None = None) -> CapacityPlanner:
    """è·å–å…¨å±€å®¹é‡è§„åˆ’å™¨å®ä¾‹"""
    global _global_capacity_planner

    if _global_capacity_planner is None:
        _global_capacity_planner = CapacityPlanner(config)

    return _global_capacity_planner


if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    import random

    # åˆ›å»ºå®¹é‡è§„åˆ’å™¨
    planner = CapacityPlanner({"linear_window": 50})

    print("ğŸ“Š å®¹é‡è§„åˆ’ç³»ç»Ÿæ¼”ç¤º...")

    # æ¨¡æ‹Ÿå†å²æ•°æ®
    base_time = datetime.now() - timedelta(days=7)

    for i in range(168):  # ä¸€å‘¨çš„å°æ—¶æ•°æ®
        timestamp = base_time + timedelta(hours=i)

        # æ¨¡æ‹ŸCPUä½¿ç”¨ç‡
        cpu_usage = 30 + random.gauss(0, 5) + i * 0.1
        cpu_usage = max(0, min(100, cpu_usage))

        # æ·»åŠ æŒ‡æ ‡
        planner.add_metric(
            ResourceMetric(
                timestamp=timestamp,
                resource_type=ResourceType.CPU,
                value=cpu_usage,
                unit="percent",
            )
        )

    print("âœ… å†å²æ•°æ®åŠ è½½å®Œæˆ")

    # é¢„æµ‹æœªæ¥ä¸€å‘¨çš„èµ„æºä½¿ç”¨
    future_time = datetime.now() + timedelta(days=7)

    print(f"\nğŸ”® é¢„æµ‹ {future_time.strftime('%Y-%m-%d %H:%M')} çš„èµ„æºä½¿ç”¨:")

    predictions = planner.predict_resource_usage(ResourceType.CPU, future_time)

    for pred in predictions:
        print(
            f"  {pred.model_type.value}: {pred.predicted_value:.1f}% "
            f"(ç½®ä¿¡åº¦: {pred.confidence:.2f}, è¶‹åŠ¿: {pred.trend})"
        )

    # ç”Ÿæˆå®¹é‡å»ºè®®
    print("\nğŸ’¡ å®¹é‡è§„åˆ’å»ºè®®:")
    recommendations = planner.generate_capacity_recommendations(timedelta(days=30))

    for rec in recommendations:
        print(f"\n{rec.resource_type.value.upper()}:")
        print(f"  å½“å‰å®¹é‡: {rec.current_capacity}")
        print(f"  é¢„æµ‹éœ€æ±‚: {rec.predicted_demand:.1f}")
        print(f"  å»ºè®®å®¹é‡: {rec.recommended_capacity:.1f}")
        print(f"  æ‰©å®¹æ–¹å‘: {rec.scaling_direction.value}")
        print(f"  ç´§æ€¥ç¨‹åº¦: {rec.urgency}")
        print(f"  æ—¶é—´çº¿: {rec.timeline}")
        print(f"  æ¨ç†: {rec.reasoning}")

    print("\nâœ… å®¹é‡è§„åˆ’æ¼”ç¤ºå®Œæˆ")
