"""
æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹æ¨¡å—

å®ç°åŸºäºå†å²æ•°æ®çš„æ™ºèƒ½å¼‚å¸¸æ£€æµ‹ï¼ŒåŒ…æ‹¬ï¼š
- æ™ºèƒ½é˜ˆå€¼è®¡ç®—
- å¼‚å¸¸æ¨¡å¼è¯†åˆ«
- é¢„æµ‹æ€§ç»´æŠ¤
- è‡ªé€‚åº”å­¦ä¹ 
"""

import asyncio
import logging
import threading
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any

logger = logging.getLogger(__name__)


class AnomalyType(Enum):
    """å¼‚å¸¸ç±»å‹æšä¸¾"""

    STATISTICAL = "statistical"  # ç»Ÿè®¡å¼‚å¸¸
    PATTERN = "pattern"  # æ¨¡å¼å¼‚å¸¸
    TREND = "trend"  # è¶‹åŠ¿å¼‚å¸¸
    SEASONAL = "seasonal"  # å­£èŠ‚æ€§å¼‚å¸¸
    OUTLIER = "outlier"  # ç¦»ç¾¤ç‚¹å¼‚å¸¸


class AnomalySeverity(Enum):
    """å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""

    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"


@dataclass
class AnomalyResult:
    """å¼‚å¸¸æ£€æµ‹ç»“æœ"""

    timestamp: datetime
    metric_name: str
    value: float
    anomaly_type: AnomalyType
    severity: AnomalySeverity
    confidence: float
    threshold: float
    description: str
    context: dict[str, Any] = field(default_factory=dict)


@dataclass
class MetricData:
    """æŒ‡æ ‡æ•°æ®"""

    timestamp: datetime
    value: float
    metadata: dict[str, Any] = field(default_factory=dict)


class StatisticalDetector:
    """ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹å™¨"""

    def __init__(self, window_size: int = 100, z_threshold: float = 3.0):
        self.window_size = window_size
        self.z_threshold = z_threshold
        self.data_buffer = deque(maxlen=window_size)

    def add_data(self, value: float) -> None:
        """æ·»åŠ æ•°æ®ç‚¹"""
        self.data_buffer.append(value)

    def detect(self, value: float) -> AnomalyResult | None:
        """æ£€æµ‹ç»Ÿè®¡å¼‚å¸¸"""
        if len(self.data_buffer) < 10:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
            return None

        data_array = np.array(self.data_buffer)
        mean = np.mean(data_array)
        std = np.std(data_array)

        if std == 0:  # é¿å…é™¤é›¶é”™è¯¯
            return None

        z_score = abs(value - mean) / std

        if z_score > self.z_threshold:
            severity = self._calculate_severity(z_score)
            confidence = min(z_score / self.z_threshold, 1.0)

            return AnomalyResult(
                timestamp=datetime.now(),
                metric_name="statistical_metric",
                value=value,
                anomaly_type=AnomalyType.STATISTICAL,
                severity=severity,
                confidence=confidence,
                threshold=mean + self.z_threshold * std,
                description=f"ç»Ÿè®¡å¼‚å¸¸: Z-score={z_score:.2f}, é˜ˆå€¼={self.z_threshold}",
                context={
                    "z_score": z_score,
                    "mean": mean,
                    "std": std,
                    "window_size": len(self.data_buffer),
                },
            )
        return None

    def _calculate_severity(self, z_score: float) -> AnomalySeverity:
        """è®¡ç®—å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if z_score > 5:
            return AnomalySeverity.CRITICAL
        elif z_score > 4:
            return AnomalySeverity.HIGH
        elif z_score > 3:
            return AnomalySeverity.MEDIUM
        else:
            return AnomalySeverity.LOW


class TrendDetector:
    """è¶‹åŠ¿å¼‚å¸¸æ£€æµ‹å™¨"""

    def __init__(self, window_size: int = 50, trend_threshold: float = 0.1):
        self.window_size = window_size
        self.trend_threshold = trend_threshold
        self.data_buffer = deque(maxlen=window_size)

    def add_data(self, value: float) -> None:
        """æ·»åŠ æ•°æ®ç‚¹"""
        self.data_buffer.append(value)

    def detect(self) -> AnomalyResult | None:
        """æ£€æµ‹è¶‹åŠ¿å¼‚å¸¸"""
        if len(self.data_buffer) < self.window_size:
            return None

        # è®¡ç®—çº¿æ€§å›å½’æ–œç‡
        x = np.arange(len(self.data_buffer))
        y = np.array(self.data_buffer)

        # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•è®¡ç®—æ–œç‡
        n = len(x)
        slope = (n * np.sum(x * y) - np.sum(x) * np.sum(y)) / (
            n * np.sum(x**2) - np.sum(x) ** 2
        )

        # è®¡ç®—ç›¸å¯¹æ–œç‡
        mean_value = np.mean(y)
        if mean_value != 0:
            relative_slope = abs(slope) / abs(mean_value)
        else:
            relative_slope = abs(slope)

        if relative_slope > self.trend_threshold:
            severity = self._calculate_severity(relative_slope)
            confidence = min(relative_slope / self.trend_threshold, 1.0)

            trend_direction = "ä¸Šå‡" if slope > 0 else "ä¸‹é™"

            return AnomalyResult(
                timestamp=datetime.now(),
                metric_name="trend_metric",
                value=y[-1],
                anomaly_type=AnomalyType.TREND,
                severity=severity,
                confidence=confidence,
                threshold=self.trend_threshold,
                description=f"è¶‹åŠ¿å¼‚å¸¸: {trend_direction}è¶‹åŠ¿ï¼Œæ–œç‡={slope:.4f}",
                context={
                    "slope": slope,
                    "relative_slope": relative_slope,
                    "trend_direction": trend_direction,
                    "window_size": len(self.data_buffer),
                },
            )
        return None

    def _calculate_severity(self, relative_slope: float) -> AnomalySeverity:
        """è®¡ç®—å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        if relative_slope > 0.5:
            return AnomalySeverity.CRITICAL
        elif relative_slope > 0.3:
            return AnomalySeverity.HIGH
        elif relative_slope > 0.2:
            return AnomalySeverity.MEDIUM
        else:
            return AnomalySeverity.LOW


class MLAnomalyDetector:
    """æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹ä¸»ç±»"""

    def __init__(self, config: dict[str, Any] | None = None):
        self.config = config or {}
        self.detectors = {}
        self.anomaly_history = deque(maxlen=1000)
        self.metrics_data = defaultdict(lambda: deque(maxlen=1000))
        self.lock = threading.Lock()

        # åˆå§‹åŒ–æ£€æµ‹å™¨
        self._initialize_detectors()

        # å¯åŠ¨åå°è®­ç»ƒä»»åŠ¡
        self.training_thread = None
        self.is_running = False

    def _initialize_detectors(self) -> None:
        """åˆå§‹åŒ–å„ç§æ£€æµ‹å™¨"""
        # ç»Ÿè®¡æ£€æµ‹å™¨
        self.detectors["statistical"] = StatisticalDetector(
            window_size=self.config.get("statistical_window", 100),
            z_threshold=self.config.get("z_threshold", 3.0),
        )

        # è¶‹åŠ¿æ£€æµ‹å™¨
        self.detectors["trend"] = TrendDetector(
            window_size=self.config.get("trend_window", 50),
            trend_threshold=self.config.get("trend_threshold", 0.1),
        )

        logger.info("æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")

    def start(self) -> None:
        """å¯åŠ¨å¼‚å¸¸æ£€æµ‹æœåŠ¡"""
        self.is_running = True
        logger.info("æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹æœåŠ¡å·²å¯åŠ¨")

    def stop(self) -> None:
        """åœæ­¢å¼‚å¸¸æ£€æµ‹æœåŠ¡"""
        self.is_running = False
        logger.info("æœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹æœåŠ¡å·²åœæ­¢")

    def add_metric(
        self, metric_name: str, value: float, timestamp: datetime | None = None
    ) -> None:
        """æ·»åŠ æŒ‡æ ‡æ•°æ®"""
        if timestamp is None:
            timestamp = datetime.now()

        with self.lock:
            # å­˜å‚¨æŒ‡æ ‡æ•°æ®
            metric_data = MetricData(timestamp=timestamp, value=value)
            self.metrics_data[metric_name].append(metric_data)

            # æ›´æ–°å„æ£€æµ‹å™¨çš„æ•°æ®
            self.detectors["statistical"].add_data(value)
            self.detectors["trend"].add_data(value)

    def detect_anomalies(
        self, metric_name: str, value: float, timestamp: datetime | None = None
    ) -> list[AnomalyResult]:
        """æ£€æµ‹å¼‚å¸¸"""
        if timestamp is None:
            timestamp = datetime.now()

        anomalies = []

        with self.lock:
            # ç»Ÿè®¡å¼‚å¸¸æ£€æµ‹
            stat_anomaly = self.detectors["statistical"].detect(value)
            if stat_anomaly:
                stat_anomaly.metric_name = metric_name
                stat_anomaly.timestamp = timestamp
                anomalies.append(stat_anomaly)

            # è¶‹åŠ¿å¼‚å¸¸æ£€æµ‹
            trend_anomaly = self.detectors["trend"].detect()
            if trend_anomaly:
                trend_anomaly.metric_name = metric_name
                trend_anomaly.timestamp = timestamp
                trend_anomaly.value = value
                anomalies.append(trend_anomaly)

        # è®°å½•å¼‚å¸¸å†å²
        for anomaly in anomalies:
            self.anomaly_history.append(anomaly)

        return anomalies

    def get_anomaly_statistics(self) -> dict[str, Any]:
        """è·å–å¼‚å¸¸ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            total_anomalies = len(self.anomaly_history)

            if total_anomalies == 0:
                return {
                    "total_anomalies": 0,
                    "by_type": {},
                    "by_severity": {},
                    "recent_anomalies": [],
                }

            # æŒ‰ç±»å‹ç»Ÿè®¡
            by_type = defaultdict(int)
            by_severity = defaultdict(int)

            for anomaly in self.anomaly_history:
                by_type[anomaly.anomaly_type.value] += 1
                by_severity[anomaly.severity.value] += 1

            # æœ€è¿‘çš„å¼‚å¸¸
            recent_anomalies = list(self.anomaly_history)[-10:]

            return {
                "total_anomalies": total_anomalies,
                "by_type": dict(by_type),
                "by_severity": dict(by_severity),
                "recent_anomalies": [
                    {
                        "timestamp": anomaly.timestamp.isoformat(),
                        "metric_name": anomaly.metric_name,
                        "type": anomaly.anomaly_type.value,
                        "severity": anomaly.severity.value,
                        "confidence": anomaly.confidence,
                        "description": anomaly.description,
                    }
                    for anomaly in recent_anomalies
                ],
            }

    def get_model_status(self) -> dict[str, Any]:
        """è·å–æ¨¡å‹çŠ¶æ€"""
        with self.lock:
            return {
                "statistical_detector": {
                    "data_points": len(self.detectors["statistical"].data_buffer),
                    "window_size": self.detectors["statistical"].window_size,
                    "z_threshold": self.detectors["statistical"].z_threshold,
                },
                "trend_detector": {
                    "data_points": len(self.detectors["trend"].data_buffer),
                    "window_size": self.detectors["trend"].window_size,
                    "trend_threshold": self.detectors["trend"].trend_threshold,
                },
            }


# å…¨å±€å¼‚å¸¸æ£€æµ‹å™¨å®ä¾‹
_global_detector: MLAnomalyDetector | None = None


def get_anomaly_detector(config: dict[str, Any] | None = None) -> MLAnomalyDetector:
    """è·å–å…¨å±€å¼‚å¸¸æ£€æµ‹å™¨å®ä¾‹"""
    global _global_detector

    if _global_detector is None:
        _global_detector = MLAnomalyDetector(config)

    return _global_detector


async def detect_anomalies_async(
    metric_name: str, value: float, timestamp: datetime | None = None
) -> list[AnomalyResult]:
    """å¼‚æ­¥å¼‚å¸¸æ£€æµ‹"""
    detector = get_anomaly_detector()

    # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œæ£€æµ‹
    loop = asyncio.get_event_loop()
    return await loop.run_in_executor(
        None, detector.detect_anomalies, metric_name, value, timestamp
    )


if __name__ == "__main__":
    # ç¤ºä¾‹ä½¿ç”¨
    import random

    # åˆ›å»ºå¼‚å¸¸æ£€æµ‹å™¨
    detector = MLAnomalyDetector(
        {"statistical_window": 50, "z_threshold": 2.5, "trend_threshold": 0.15}
    )

    detector.start()

    try:
        # æ¨¡æ‹Ÿæ­£å¸¸æ•°æ®
        print("ğŸ” å¼€å§‹å¼‚å¸¸æ£€æµ‹æ¼”ç¤º...")

        for i in range(100):
            # ç”Ÿæˆæ­£å¸¸æ•°æ®
            normal_value = 50 + random.gauss(0, 5)
            detector.add_metric("cpu_usage", normal_value)

            # æ¯10ä¸ªæ•°æ®ç‚¹æ£€æµ‹ä¸€æ¬¡
            if i % 10 == 0:
                anomalies = detector.detect_anomalies("cpu_usage", normal_value)
                if anomalies:
                    print(f"æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸")

        # æ³¨å…¥å¼‚å¸¸æ•°æ®
        print("\nğŸš¨ æ³¨å…¥å¼‚å¸¸æ•°æ®...")
        anomaly_value = 150  # æ˜æ˜¾å¼‚å¸¸çš„å€¼
        detector.add_metric("cpu_usage", anomaly_value)
        anomalies = detector.detect_anomalies("cpu_usage", anomaly_value)

        print(f"æ£€æµ‹åˆ° {len(anomalies)} ä¸ªå¼‚å¸¸:")
        for anomaly in anomalies:
            print(f"  - {anomaly.anomaly_type.value}: {anomaly.description}")

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š å¼‚å¸¸ç»Ÿè®¡ä¿¡æ¯:")
        stats = detector.get_anomaly_statistics()
        print(f"  æ€»å¼‚å¸¸æ•°: {stats['total_anomalies']}")
        print(f"  æŒ‰ç±»å‹: {stats['by_type']}")
        print(f"  æŒ‰ä¸¥é‡ç¨‹åº¦: {stats['by_severity']}")

        # æ˜¾ç¤ºæ¨¡å‹çŠ¶æ€
        print("\nğŸ¤– æ¨¡å‹çŠ¶æ€:")
        status = detector.get_model_status()
        for detector_name, detector_status in status.items():
            print(f"  {detector_name}: {detector_status}")

    finally:
        detector.stop()
        print("\nâœ… å¼‚å¸¸æ£€æµ‹æ¼”ç¤ºå®Œæˆ")
