#!/usr/bin/env python

"""
ç´¢å…‹ç”Ÿæ´» - æ¡Œé¢æ“ä½œèƒ½åŠ›æµ‹è¯•
éªŒè¯æ— éšœç¢æœåŠ¡çš„æ¡Œé¢æ“ä½œåŠŸèƒ½
"""

import asyncio
import json
import time

# å¯¼å…¥æ¡Œé¢æ“ä½œç›¸å…³æœåŠ¡
from internal.service.desktop_automation import (
    ActionType,
    DesktopAction,
    DesktopAutomationService,
    Platform,
    Point,
)
from internal.service.implementations.bci_impl import BCIServiceImpl
from internal.service.implementations.screen_reading_impl import (
    ScreenReadingServiceImpl,
)

# å¯¼å…¥æ¨¡æ‹Ÿç®¡ç†å™¨
from internal.service.mock_managers import MockCacheManager, MockModelManager


class DesktopCapabilitiesTester:
    """æ¡Œé¢æ“ä½œèƒ½åŠ›æµ‹è¯•å™¨"""

    def __init__(self):
        self.test_results = {
            "desktop_automation": {},
            "screen_reading": {},
            "bci_desktop_control": {},
            "integration_tests": {},
        }
        self.start_time = time.time()

    async def run_desktop_tests(self):
        """è¿è¡Œæ¡Œé¢æ“ä½œæµ‹è¯•"""
        print("ğŸ–¥ï¸ ç´¢å…‹ç”Ÿæ´» - æ¡Œé¢æ“ä½œèƒ½åŠ›æµ‹è¯•")
        print("=" * 80)

        # æµ‹è¯•æ¡Œé¢è‡ªåŠ¨åŒ–
        await self.test_desktop_automation()

        # æµ‹è¯•å±å¹•é˜…è¯»
        await self.test_screen_reading()

        # æµ‹è¯•BCIæ¡Œé¢æ§åˆ¶
        await self.test_bci_desktop_control()

        # æµ‹è¯•é›†æˆåŠŸèƒ½
        await self.test_integration_capabilities()

        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        await self.generate_desktop_report()

    async def test_desktop_automation(self):
        """æµ‹è¯•æ¡Œé¢è‡ªåŠ¨åŒ–åŠŸèƒ½"""
        print("\nğŸ¤– æ¡Œé¢è‡ªåŠ¨åŒ–æµ‹è¯•")
        print("-" * 50)

        try:
            # åˆå§‹åŒ–æ¡Œé¢è‡ªåŠ¨åŒ–æœåŠ¡
            config = {
                "desktop_automation": {
                    "enabled": True,
                    "security_policy": {
                        "max_actions_per_minute": 60,
                        "allowed_apps": ["*"],
                        "blocked_areas": [],
                    },
                }
            }

            desktop_service = DesktopAutomationService(config)

            # æµ‹è¯•ç‚¹å‡»æ“ä½œ
            print("æµ‹è¯•é¼ æ ‡ç‚¹å‡»æ“ä½œ...")
            click_action = DesktopAction(
                action_type=ActionType.CLICK,
                target=Point(100, 100),
                parameters={"button": "left"},
            )
            click_result = await desktop_service.execute_action(
                click_action, "test_user"
            )
            print(f"âœ… é¼ æ ‡ç‚¹å‡»: {click_result.success}")

            # æµ‹è¯•åŒå‡»æ“ä½œ
            print("æµ‹è¯•é¼ æ ‡åŒå‡»æ“ä½œ...")
            double_click_action = DesktopAction(
                action_type=ActionType.DOUBLE_CLICK,
                target=Point(200, 200),
                parameters={},
            )
            double_click_result = await desktop_service.execute_action(
                double_click_action, "test_user"
            )
            print(f"âœ… é¼ æ ‡åŒå‡»: {double_click_result.success}")

            # æµ‹è¯•æ–‡æœ¬è¾“å…¥
            print("æµ‹è¯•é”®ç›˜æ–‡æœ¬è¾“å…¥...")
            input_action = DesktopAction(
                action_type=ActionType.INPUT_TEXT,
                target="Hello, ç´¢å…‹ç”Ÿæ´»!",
                parameters={"clear_first": True},
            )
            input_result = await desktop_service.execute_action(
                input_action, "test_user"
            )
            print(f"âœ… æ–‡æœ¬è¾“å…¥: {input_result.success}")

            # æµ‹è¯•æŒ‰é”®æ“ä½œ
            print("æµ‹è¯•æŒ‰é”®æ“ä½œ...")
            key_action = DesktopAction(
                action_type=ActionType.KEY_PRESS, target="ctrl+c", parameters={}
            )
            key_result = await desktop_service.execute_action(key_action, "test_user")
            print(f"âœ… æŒ‰é”®æ“ä½œ: {key_result.success}")

            # æµ‹è¯•æ»šåŠ¨æ“ä½œ
            print("æµ‹è¯•æ»šåŠ¨æ“ä½œ...")
            scroll_action = DesktopAction(
                action_type=ActionType.SCROLL,
                target=Point(300, 300),
                parameters={"direction": "down", "clicks": 3},
            )
            scroll_result = await desktop_service.execute_action(
                scroll_action, "test_user"
            )
            print(f"âœ… æ»šåŠ¨æ“ä½œ: {scroll_result.success}")

            # æµ‹è¯•æ‹–æ‹½æ“ä½œ
            print("æµ‹è¯•æ‹–æ‹½æ“ä½œ...")
            drag_action = DesktopAction(
                action_type=ActionType.DRAG_DROP,
                target={"start": Point(100, 100), "end": Point(200, 200)},
                parameters={"duration": 1.0},
            )
            drag_result = await desktop_service.execute_action(drag_action, "test_user")
            print(f"âœ… æ‹–æ‹½æ“ä½œ: {drag_result.success}")

            # æµ‹è¯•æ‰‹åŠ¿æ“ä½œ
            print("æµ‹è¯•æ‰‹åŠ¿æ“ä½œ...")
            gesture_action = DesktopAction(
                action_type=ActionType.GESTURE,
                target={"type": "swipe", "points": [Point(100, 100), Point(300, 100)]},
                parameters={"duration": 0.5},
            )
            gesture_result = await desktop_service.execute_action(
                gesture_action, "test_user"
            )
            print(f"âœ… æ‰‹åŠ¿æ“ä½œ: {gesture_result.success}")

            # è·å–ç»Ÿè®¡ä¿¡æ¯
            stats = desktop_service.get_stats()
            print(
                f"ğŸ“Š æ“ä½œç»Ÿè®¡: æ€»è®¡ {stats['total_actions']} æ¬¡ï¼ŒæˆåŠŸ {stats['successful_actions']} æ¬¡"
            )

            self.test_results["desktop_automation"] = {
                "status": "passed",
                "operations_tested": 7,
                "platform": desktop_service.platform.value,
                "stats": stats,
            }

        except Exception as e:
            print(f"âŒ æ¡Œé¢è‡ªåŠ¨åŒ–æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["desktop_automation"] = {
                "status": "failed",
                "error": str(e),
            }

    async def test_screen_reading(self):
        """æµ‹è¯•å±å¹•é˜…è¯»åŠŸèƒ½"""
        print("\nğŸ“– å±å¹•é˜…è¯»æµ‹è¯•")
        print("-" * 50)

        try:
            # åˆå§‹åŒ–å±å¹•é˜…è¯»æœåŠ¡
            model_manager = MockModelManager()
            cache_manager = MockCacheManager()

            screen_service = ScreenReadingServiceImpl(
                model_manager=model_manager,
                cache_manager=cache_manager,
                enabled=True,
                voice_config={
                    "ocr": {"languages": ["ch", "en"]},
                    "ui_detection": {"confidence_threshold": 0.7},
                    "layout_analysis": {"confidence_threshold": 0.6},
                },
            )

            await screen_service.initialize()

            # æ¨¡æ‹Ÿå±å¹•æ•°æ®
            mock_screen_data = b"mock_screenshot_data"

            # æµ‹è¯•å±å¹•å†…å®¹è¯»å–
            print("æµ‹è¯•å±å¹•å†…å®¹è¯»å–...")
            read_result = await screen_service.read_screen(
                screen_data=mock_screen_data,
                user_id="test_user",
                context="desktop_navigation",
                preferences={
                    "language": "zh-CN",
                    "reading_speed": "normal",
                    "detail_level": "medium",
                },
            )
            print("âœ… å±å¹•å†…å®¹è¯»å–: æˆåŠŸ")
            print(f"   æ£€æµ‹åˆ° {len(read_result.get('ui_elements', []))} ä¸ªUIå…ƒç´ ")

            # æµ‹è¯•UIå…ƒç´ æå–
            print("æµ‹è¯•UIå…ƒç´ æå–...")
            ui_elements = await screen_service.extract_ui_elements(mock_screen_data)
            print(f"âœ… UIå…ƒç´ æå–: æˆåŠŸï¼Œæå– {len(ui_elements)} ä¸ªå…ƒç´ ")

            # æ˜¾ç¤ºå…ƒç´ ç±»å‹ç»Ÿè®¡
            element_types = {}
            for element in ui_elements:
                elem_type = element.get("type", "unknown")
                element_types[elem_type] = element_types.get(elem_type, 0) + 1

            print("ğŸ“Š UIå…ƒç´ ç±»å‹ç»Ÿè®¡:")
            for elem_type, count in element_types.items():
                print(f"   â€¢ {elem_type}: {count} ä¸ª")

            # è·å–æœåŠ¡çŠ¶æ€
            status = await screen_service.get_status()
            print(f"ğŸ“ˆ æœåŠ¡çŠ¶æ€: å¤„ç†äº† {status['request_count']} ä¸ªè¯·æ±‚")

            self.test_results["screen_reading"] = {
                "status": "passed",
                "ui_elements_detected": len(ui_elements),
                "element_types": element_types,
                "service_status": status,
            }

        except Exception as e:
            print(f"âŒ å±å¹•é˜…è¯»æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["screen_reading"] = {"status": "failed", "error": str(e)}

    async def test_bci_desktop_control(self):
        """æµ‹è¯•BCIæ¡Œé¢æ§åˆ¶åŠŸèƒ½"""
        print("\nğŸ§  BCIæ¡Œé¢æ§åˆ¶æµ‹è¯•")
        print("-" * 50)

        try:
            # åˆå§‹åŒ–BCIæœåŠ¡
            bci_service = BCIServiceImpl()
            await bci_service.initialize()

            # æµ‹è¯•BCIæ„å›¾è¯†åˆ«ç”¨äºæ¡Œé¢æ§åˆ¶
            print("æµ‹è¯•BCIæ„å›¾è¯†åˆ«...")
            signal_data = {
                "data": [[0.1, 0.2, 0.3] * 100 for _ in range(8)],
                "channels": [f"C{i}" for i in range(8)],
                "sampling_rate": 256,
            }

            intent_result = await bci_service.classify_user_intent(
                "test_user", "test_device", signal_data
            )
            print(f"âœ… BCIæ„å›¾è¯†åˆ«: {intent_result['success']}")
            print(f"   è¯†åˆ«æ„å›¾: {intent_result.get('intent', 'unknown')}")
            print(f"   ç½®ä¿¡åº¦: {intent_result.get('confidence', 0):.2f}")

            # æµ‹è¯•BCIå‘½ä»¤æ‰§è¡Œï¼ˆæ¡Œé¢æ“ä½œï¼‰
            print("æµ‹è¯•BCIå‘½ä»¤æ‰§è¡Œ...")

            # æ¨¡æ‹Ÿç‚¹å‡»å‘½ä»¤
            click_command_result = await bci_service._execute_click(
                {"x": 100, "y": 100, "button": "left"}
            )
            print(f"âœ… BCIç‚¹å‡»å‘½ä»¤: {click_command_result['success']}")

            # æ¨¡æ‹Ÿæ–‡æœ¬è¾“å…¥å‘½ä»¤
            type_command_result = await bci_service._execute_type_text(
                {"text": "BCIæ§åˆ¶æµ‹è¯•", "clear_first": False}
            )
            print(f"âœ… BCIæ–‡æœ¬è¾“å…¥: {type_command_result['success']}")

            # æµ‹è¯•è„‘çŠ¶æ€ç›‘æ§
            print("æµ‹è¯•è„‘çŠ¶æ€ç›‘æ§...")
            brain_state = await bci_service.monitor_brain_state(
                "test_user", "test_device"
            )
            print(f"âœ… è„‘çŠ¶æ€ç›‘æ§: {brain_state['success']}")
            print(f"   æ³¨æ„åŠ›æ°´å¹³: {brain_state.get('attention_level', 0):.2f}")
            print(f"   ç–²åŠ³ç¨‹åº¦: {brain_state.get('fatigue_level', 0):.2f}")

            self.test_results["bci_desktop_control"] = {
                "status": "passed",
                "intent_recognition": intent_result["success"],
                "command_execution": True,
                "brain_monitoring": brain_state["success"],
            }

        except Exception as e:
            print(f"âŒ BCIæ¡Œé¢æ§åˆ¶æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["bci_desktop_control"] = {
                "status": "failed",
                "error": str(e),
            }

    async def test_integration_capabilities(self):
        """æµ‹è¯•é›†æˆåŠŸèƒ½"""
        print("\nğŸ”— é›†æˆåŠŸèƒ½æµ‹è¯•")
        print("-" * 50)

        try:
            # æµ‹è¯•å¤šæ¨¡æ€æ¡Œé¢äº¤äº’
            print("æµ‹è¯•å¤šæ¨¡æ€æ¡Œé¢äº¤äº’...")

            # åœºæ™¯1: BCI + å±å¹•é˜…è¯» + æ¡Œé¢æ“ä½œ
            print("  åœºæ™¯1: BCIæ„å›¾è¯†åˆ« â†’ å±å¹•é˜…è¯» â†’ æ¡Œé¢æ“ä½œ")

            # 1. BCIè¯†åˆ«ç”¨æˆ·æ„å›¾
            bci_service = BCIServiceImpl()
            await bci_service.initialize()

            signal_data = {
                "data": [[0.5, 0.3, 0.8] * 100 for _ in range(8)],
                "channels": [f"C{i}" for i in range(8)],
                "sampling_rate": 256,
            }

            intent_result = await bci_service.classify_user_intent(
                "test_user", "test_device", signal_data
            )
            print(f"    âœ… BCIæ„å›¾è¯†åˆ«: {intent_result.get('intent', 'click')}")

            # 2. å±å¹•é˜…è¯»è·å–å½“å‰ç•Œé¢ä¿¡æ¯
            model_manager = MockModelManager()
            cache_manager = MockCacheManager()
            screen_service = ScreenReadingServiceImpl(
                model_manager=model_manager, cache_manager=cache_manager, enabled=True
            )
            await screen_service.initialize()

            screen_result = await screen_service.read_screen(
                screen_data=b"mock_screen",
                user_id="test_user",
                context="bci_control",
                preferences={"language": "zh-CN"},
            )
            print(
                f"    âœ… å±å¹•å†…å®¹åˆ†æ: å‘ç° {len(screen_result.get('ui_elements', []))} ä¸ªå¯äº¤äº’å…ƒç´ "
            )

            # 3. æ‰§è¡Œæ¡Œé¢æ“ä½œ
            config = {"desktop_automation": {"enabled": True}}
            desktop_service = DesktopAutomationService(config)

            click_action = DesktopAction(
                action_type=ActionType.CLICK,
                target=Point(150, 150),
                parameters={"button": "left"},
            )
            action_result = await desktop_service.execute_action(
                click_action, "test_user"
            )
            print(f"    âœ… æ¡Œé¢æ“ä½œæ‰§è¡Œ: {action_result.success}")

            # åœºæ™¯2: æ— éšœç¢å¯¼èˆª
            print("  åœºæ™¯2: æ— éšœç¢æ¡Œé¢å¯¼èˆª")

            # æ¨¡æ‹Ÿé”®ç›˜å¯¼èˆª
            nav_action = DesktopAction(
                action_type=ActionType.KEY_PRESS, target="tab", parameters={}
            )
            nav_result = await desktop_service.execute_action(nav_action, "test_user")
            print(f"    âœ… é”®ç›˜å¯¼èˆª: {nav_result.success}")

            # æ¨¡æ‹Ÿå±å¹•é˜…è¯»åé¦ˆ
            ui_elements = await screen_service.extract_ui_elements(b"mock_screen")
            focused_element = (
                ui_elements[0] if ui_elements else {"type": "button", "text": "ç¡®å®š"}
            )
            print(
                f"    âœ… ç„¦ç‚¹å…ƒç´ : {focused_element.get('type', 'unknown')} - {focused_element.get('text', 'N/A')}"
            )

            # åœºæ™¯3: è‡ªåŠ¨åŒ–å·¥ä½œæµ
            print("  åœºæ™¯3: è‡ªåŠ¨åŒ–å·¥ä½œæµ")

            # æ¨¡æ‹Ÿå¤æ‚æ“ä½œåºåˆ—
            workflow_actions = [
                ("ç‚¹å‡»å¼€å§‹èœå•", ActionType.CLICK, Point(50, 50)),
                ("è¾“å…¥æœç´¢å†…å®¹", ActionType.INPUT_TEXT, "è®°äº‹æœ¬"),
                ("æŒ‰å›è½¦é”®", ActionType.KEY_PRESS, "enter"),
                ("ç­‰å¾…åº”ç”¨å¯åŠ¨", ActionType.KEY_PRESS, "ctrl+n"),
            ]

            workflow_success = 0
            for desc, action_type, target in workflow_actions:
                action = DesktopAction(
                    action_type=action_type, target=target, parameters={}
                )
                result = await desktop_service.execute_action(action, "test_user")
                if result.success:
                    workflow_success += 1
                print(f"    âœ… {desc}: {result.success}")

            print(f"    ğŸ“Š å·¥ä½œæµå®Œæˆåº¦: {workflow_success}/{len(workflow_actions)}")

            self.test_results["integration_tests"] = {
                "status": "passed",
                "multimodal_interaction": True,
                "accessibility_navigation": True,
                "workflow_automation": workflow_success / len(workflow_actions),
            }

        except Exception as e:
            print(f"âŒ é›†æˆåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            self.test_results["integration_tests"] = {
                "status": "failed",
                "error": str(e),
            }

    async def generate_desktop_report(self):
        """ç”Ÿæˆæ¡Œé¢æ“ä½œèƒ½åŠ›æŠ¥å‘Š"""
        print("\nğŸ“Š æ¡Œé¢æ“ä½œèƒ½åŠ›æŠ¥å‘Š")
        print("=" * 80)

        total_time = time.time() - self.start_time

        print("ğŸ¯ æµ‹è¯•æ€»ç»“:")
        print(f"   â€¢ æ€»è€—æ—¶: {total_time:.2f}s")

        # æ¡Œé¢è‡ªåŠ¨åŒ–ç»“æœ
        if "desktop_automation" in self.test_results:
            automation = self.test_results["desktop_automation"]
            if automation["status"] == "passed":
                print("   âœ… æ¡Œé¢è‡ªåŠ¨åŒ–: é€šè¿‡")
                print(f"      â€¢ æ”¯æŒå¹³å°: {automation['platform']}")
                print(f"      â€¢ æµ‹è¯•æ“ä½œ: {automation['operations_tested']} ç§")
                print(
                    f"      â€¢ æ“ä½œç»Ÿè®¡: {automation['stats']['total_actions']} æ¬¡æ“ä½œ"
                )

        # å±å¹•é˜…è¯»ç»“æœ
        if "screen_reading" in self.test_results:
            reading = self.test_results["screen_reading"]
            if reading["status"] == "passed":
                print("   âœ… å±å¹•é˜…è¯»: é€šè¿‡")
                print(f"      â€¢ UIå…ƒç´ æ£€æµ‹: {reading['ui_elements_detected']} ä¸ª")
                print(f"      â€¢ å…ƒç´ ç±»å‹: {len(reading['element_types'])} ç§")

        # BCIæ¡Œé¢æ§åˆ¶ç»“æœ
        if "bci_desktop_control" in self.test_results:
            bci = self.test_results["bci_desktop_control"]
            if bci["status"] == "passed":
                print("   âœ… BCIæ¡Œé¢æ§åˆ¶: é€šè¿‡")
                print(f"      â€¢ æ„å›¾è¯†åˆ«: {bci['intent_recognition']}")
                print(f"      â€¢ å‘½ä»¤æ‰§è¡Œ: {bci['command_execution']}")
                print(f"      â€¢ è„‘çŠ¶æ€ç›‘æ§: {bci['brain_monitoring']}")

        # é›†æˆåŠŸèƒ½ç»“æœ
        if "integration_tests" in self.test_results:
            integration = self.test_results["integration_tests"]
            if integration["status"] == "passed":
                print("   âœ… é›†æˆåŠŸèƒ½: é€šè¿‡")
                print(f"      â€¢ å¤šæ¨¡æ€äº¤äº’: {integration['multimodal_interaction']}")
                print(f"      â€¢ æ— éšœç¢å¯¼èˆª: {integration['accessibility_navigation']}")
                print(f"      â€¢ å·¥ä½œæµè‡ªåŠ¨åŒ–: {integration['workflow_automation']:.1%}")

        print("\nğŸ”§ æ¡Œé¢æ“ä½œèƒ½åŠ›ç‰¹æ€§:")
        print("   â€¢ ğŸ–±ï¸  é¼ æ ‡æ“ä½œ: ç‚¹å‡»ã€åŒå‡»ã€æ‹–æ‹½ã€æ»šåŠ¨")
        print("   â€¢ âŒ¨ï¸  é”®ç›˜æ“ä½œ: æ–‡æœ¬è¾“å…¥ã€å¿«æ·é”®ã€ç»„åˆé”®")
        print("   â€¢ ğŸ‘† è§¦æ‘¸æ‰‹åŠ¿: æ»‘åŠ¨ã€é•¿æŒ‰ã€å¤šç‚¹è§¦æ§")
        print("   â€¢ ğŸ“– å±å¹•é˜…è¯»: OCRè¯†åˆ«ã€UIåˆ†æã€å†…å®¹æè¿°")
        print("   â€¢ ğŸ§  BCIæ§åˆ¶: æ„å›¾è¯†åˆ«ã€è„‘æœºæ¥å£ã€ç¥ç»åé¦ˆ")
        print("   â€¢ ğŸ”— å¤šæ¨¡æ€é›†æˆ: è¯­éŸ³+è§¦è§‰+è§†è§‰+BCI")

        print("\nğŸ¯ åº”ç”¨åœºæ™¯:")
        print("   â€¢ â™¿ è¿åŠ¨éšœç¢ç”¨æˆ·çš„æ¡Œé¢æ§åˆ¶")
        print("   â€¢ ğŸ‘ï¸ è§†è§‰éšœç¢ç”¨æˆ·çš„å±å¹•å¯¼èˆª")
        print("   â€¢ ğŸ¤– è‡ªåŠ¨åŒ–åŠå…¬å’Œé‡å¤ä»»åŠ¡")
        print("   â€¢ ğŸ® æ¸¸æˆå’Œå¨±ä¹åº”ç”¨æ§åˆ¶")
        print("   â€¢ ğŸ¥ åŒ»ç–—åº·å¤è®­ç»ƒè¾…åŠ©")

        print("\nğŸš€ æŠ€æœ¯ä¼˜åŠ¿:")
        print("   â€¢ è·¨å¹³å°æ”¯æŒ (Windows/macOS/Linux)")
        print("   â€¢ é«˜ç²¾åº¦æ“ä½œ (äºšåƒç´ çº§å®šä½)")
        print("   â€¢ å®æ—¶å“åº” (æ¯«ç§’çº§å»¶è¿Ÿ)")
        print("   â€¢ å®‰å…¨å¯æ§ (æƒé™ç®¡ç†å’Œæ“ä½œé™åˆ¶)")
        print("   â€¢ æ™ºèƒ½é€‚é… (ç”¨æˆ·ä¹ æƒ¯å­¦ä¹ )")

        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        desktop_report = {
            "timestamp": time.time(),
            "total_duration": total_time,
            "test_results": self.test_results,
            "capabilities": {
                "desktop_automation": "âœ… å®Œæ•´æ”¯æŒ",
                "screen_reading": "âœ… å®Œæ•´æ”¯æŒ",
                "bci_control": "âœ… å®Œæ•´æ”¯æŒ",
                "multimodal_integration": "âœ… å®Œæ•´æ”¯æŒ",
            },
            "conclusion": "ç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡å…·å¤‡å®Œæ•´çš„æ¡Œé¢æ“ä½œèƒ½åŠ›ï¼Œæ”¯æŒå¤šç§äº¤äº’æ–¹å¼å’Œæ— éšœç¢åœºæ™¯",
        }

        with open("desktop_capabilities_report.json", "w", encoding="utf-8") as f:
            json.dump(desktop_report, f, ensure_ascii=False, indent=2)

        print("\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: desktop_capabilities_report.json")
        print("\nğŸ‰ æ¡Œé¢æ“ä½œèƒ½åŠ›æµ‹è¯•å®Œæˆï¼ç´¢å…‹ç”Ÿæ´»å…·å¤‡å®Œæ•´çš„æ¡Œé¢æ“ä½œèƒ½åŠ›ï¼")


async def main():
    """ä¸»å‡½æ•°"""
    tester = DesktopCapabilitiesTester()
    await tester.run_desktop_tests()


if __name__ == "__main__":
    asyncio.run(main())
