# ç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡ - ç§‘å­¦è®¡ç®—åº“ä½¿ç”¨æŒ‡å—

## ğŸ“š æ¦‚è¿°

ç´¢å…‹ç”Ÿæ´»æ— éšœç¢æœåŠ¡é›†æˆäº†å…¨é¢çš„ç§‘å­¦è®¡ç®—åº“æ”¯æŒï¼Œä¸ºAIæ™ºèƒ½ä½“æä¾›å¼ºå¤§çš„æ•°æ®åˆ†æã€æœºå™¨å­¦ä¹ ã€ä¿¡å·å¤„ç†å’Œå¯è§†åŒ–èƒ½åŠ›ã€‚æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨äº†è§£å¦‚ä½•ä½¿ç”¨è¿™äº›åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ç§‘å­¦è®¡ç®—åº“

```bash
# è‡ªåŠ¨å®‰è£…æ‰€æœ‰åº“
python scripts/install_scientific_libraries.py

# åªå®‰è£…æ ¸å¿ƒåº“
python scripts/install_scientific_libraries.py --core-only

# è·³è¿‡ç³»ç»Ÿä¾èµ–å®‰è£…
python scripts/install_scientific_libraries.py --no-system-deps
```

### 2. åŸºæœ¬ä½¿ç”¨

```python
from internal.service.scientific_computing import get_scientific_computing_service

# è·å–æœåŠ¡å®ä¾‹
service = get_scientific_computing_service()

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
status = service.get_service_status()
print(f"å¯ç”¨åº“æ•°é‡: {status['library_count']}")
print(f"è¦†ç›–ç‡: {status['coverage_percentage']:.1f}%")
```

## ğŸ“Š æ ¸å¿ƒåŠŸèƒ½

### 1. æ•°æ®åˆ†æ

#### ä¼ æ„Ÿå™¨æ•°æ®åˆ†æ
```python
# åˆ†æä¼ æ„Ÿå™¨æ•°æ®
sensor_data = [1.2, 1.5, 1.1, 1.8, 1.3, 1.6, 1.4]
result = service.process_data(sensor_data, 'analyze')

print(f"å¹³å‡å€¼: {result['statistics']['mean']}")
print(f"æ ‡å‡†å·®: {result['statistics']['std']}")
print(f"æœ€å°å€¼: {result['statistics']['min']}")
print(f"æœ€å¤§å€¼: {result['statistics']['max']}")
```

#### å¼‚å¸¸æ£€æµ‹
```python
# æ£€æµ‹æ•°æ®ä¸­çš„å¼‚å¸¸å€¼
anomaly_result = service.process_data(
    sensor_data, 
    'detect_anomalies', 
    threshold=2.0
)

print(f"å¼‚å¸¸ç‚¹æ•°é‡: {anomaly_result['results']['anomaly_count']}")
print(f"å¼‚å¸¸æ¯”ä¾‹: {anomaly_result['results']['anomaly_percentage']:.1f}%")
```

### 2. ä¿¡å·å¤„ç†

#### ä¿¡å·æ»¤æ³¢
```python
# ä½é€šæ»¤æ³¢
filtered_result = service.process_data(
    noisy_signal, 
    'filter', 
    filter_type='lowpass', 
    cutoff=0.1
)

# é«˜é€šæ»¤æ³¢
high_pass_result = service.process_data(
    signal_data, 
    'filter', 
    filter_type='highpass', 
    cutoff=0.05
)

# å¸¦é€šæ»¤æ³¢
band_pass_result = service.process_data(
    signal_data, 
    'filter', 
    filter_type='bandpass', 
    cutoff=0.1
)
```

#### é¢‘è°±åˆ†æ
```python
# åˆ†æä¿¡å·é¢‘è°±
spectrum_result = service.process_data(
    audio_signal, 
    'spectrum', 
    sample_rate=44100
)

print(f"ä¸»è¦é¢‘ç‡: {spectrum_result['spectrum_analysis']['dominant_frequency']} Hz")
```

### 3. æœºå™¨å­¦ä¹ 

#### æ•°æ®èšç±»
```python
# K-meansèšç±»
cluster_result = service.process_data(
    feature_data, 
    'cluster', 
    n_clusters=3
)

print(f"èšç±»æ ‡ç­¾: {cluster_result['labels']}")
print(f"èšç±»ä¸­å¿ƒ: {cluster_result['centroids']}")
```

#### åˆ†ç±»å™¨è®­ç»ƒï¼ˆéœ€è¦sklearnï¼‰
```python
from internal.service.scientific_computing import ScientificComputingService
import numpy as np

service = ScientificComputingService()
ml_engine = service.machine_learning

# å‡†å¤‡è®­ç»ƒæ•°æ®
X = np.random.randn(100, 4)  # ç‰¹å¾
y = np.random.randint(0, 3, 100)  # æ ‡ç­¾

# è®­ç»ƒéšæœºæ£®æ—åˆ†ç±»å™¨
result = ml_engine.train_classifier(X, y, model_type='random_forest')
print(f"æ¨¡å‹å‡†ç¡®ç‡: {result['accuracy']:.3f}")
```

### 4. æ•°æ®å¯è§†åŒ–

#### åˆ›å»ºç»˜å›¾æ•°æ®
```python
# çº¿å›¾æ•°æ®
line_plot = service.process_data(
    time_series_data, 
    'plot', 
    plot_type='line'
)

# ç›´æ–¹å›¾æ•°æ®
histogram = service.process_data(
    distribution_data, 
    'plot', 
    plot_type='histogram'
)

# æ•£ç‚¹å›¾æ•°æ®
scatter_plot = service.process_data(
    xy_data, 
    'plot', 
    plot_type='scatter'
)
```

## ğŸ”§ é«˜çº§åŠŸèƒ½

### 1. ç›´æ¥ä½¿ç”¨å¼•æ“

```python
from internal.service.scientific_computing import (
    ScientificComputingManager,
    DataAnalysisEngine,
    SignalProcessingEngine,
    MachineLearningEngine,
    VisualizationEngine
)

# åˆ›å»ºç®¡ç†å™¨
manager = ScientificComputingManager()

# ä½¿ç”¨æ•°æ®åˆ†æå¼•æ“
data_engine = DataAnalysisEngine(manager)
analysis_result = data_engine.analyze_sensor_data(np.array(sensor_data))

# ä½¿ç”¨ä¿¡å·å¤„ç†å¼•æ“
signal_engine = SignalProcessingEngine(manager)
filter_result = signal_engine.filter_signal(signal_array, 'lowpass', 0.1)
```

### 2. æ£€æŸ¥åº“å¯ç”¨æ€§

```python
# æ£€æŸ¥ç‰¹å®šåº“æ˜¯å¦å¯ç”¨
if manager.is_library_available('scipy'):
    print("SciPyå¯ç”¨ï¼Œå¯ä»¥ä½¿ç”¨é«˜çº§ä¿¡å·å¤„ç†åŠŸèƒ½")

if manager.is_library_available('sklearn'):
    print("Scikit-learnå¯ç”¨ï¼Œå¯ä»¥ä½¿ç”¨æœºå™¨å­¦ä¹ åŠŸèƒ½")

# è·å–æ‰€æœ‰å¯ç”¨åº“
available_libs = manager.get_available_libraries()
for lib_name, is_available in available_libs.items():
    status = "âœ…" if is_available else "âŒ"
    print(f"{status} {lib_name}")
```

## ğŸ“¦ æ”¯æŒçš„åº“

### æ ¸å¿ƒç§‘å­¦è®¡ç®—åº“
- **NumPy**: åŸºç¡€æ•°å€¼è®¡ç®—
- **SciPy**: ç§‘å­¦è®¡ç®—å’Œç»Ÿè®¡
- **Pandas**: æ•°æ®å¤„ç†å’Œåˆ†æ
- **Matplotlib**: æ•°æ®å¯è§†åŒ–
- **Seaborn**: ç»Ÿè®¡å¯è§†åŒ–
- **Plotly**: äº¤äº’å¼å¯è§†åŒ–

### æœºå™¨å­¦ä¹ åº“
- **Scikit-learn**: æœºå™¨å­¦ä¹ ç®—æ³•
- **XGBoost**: æ¢¯åº¦æå‡ç®—æ³•
- **LightGBM**: è½»é‡çº§æ¢¯åº¦æå‡
- **TensorFlow**: æ·±åº¦å­¦ä¹ æ¡†æ¶
- **PyTorch**: æ·±åº¦å­¦ä¹ æ¡†æ¶

### è®¡ç®—æœºè§†è§‰åº“
- **OpenCV**: è®¡ç®—æœºè§†è§‰
- **Pillow**: å›¾åƒå¤„ç†
- **Scikit-image**: å›¾åƒå¤„ç†ç®—æ³•
- **MediaPipe**: æ‰‹åŠ¿è¯†åˆ«å’Œå§¿æ€ä¼°è®¡

### éŸ³é¢‘å¤„ç†åº“
- **Librosa**: éŸ³é¢‘åˆ†æ
- **PyAudio**: éŸ³é¢‘å¤„ç†
- **SoundDevice**: éŸ³é¢‘è®¾å¤‡æ¥å£
- **Pydub**: éŸ³é¢‘æ–‡ä»¶å¤„ç†

### ä¿¡å·å¤„ç†åº“
- **FilterPy**: å¡å°”æ›¼æ»¤æ³¢å™¨
- **PyWavelets**: å°æ³¢å˜æ¢
- **AHRS**: å§¿æ€å’Œèˆªå‘å‚è€ƒç³»ç»Ÿ

### åœ°ç†ä¿¡æ¯åº“
- **Geopy**: åœ°ç†ç¼–ç å’Œè·ç¦»è®¡ç®—
- **Shapely**: å‡ ä½•å¯¹è±¡å¤„ç†
- **Folium**: åœ°å›¾å¯è§†åŒ–
- **GeoPandas**: åœ°ç†æ•°æ®å¤„ç†

## ğŸ¯ å®é™…åº”ç”¨åœºæ™¯

### 1. ç›²äººè¾…åŠ©æœåŠ¡

```python
# åˆ†ææ‘„åƒå¤´å›¾åƒæ•°æ®
image_features = extract_image_features(camera_image)
obstacle_analysis = service.process_data(image_features, 'analyze')

# æ£€æµ‹å¼‚å¸¸éšœç¢ç‰©
obstacles = service.process_data(
    depth_data, 
    'detect_anomalies', 
    threshold=1.5
)

# è·¯å¾„è§„åˆ’æ•°æ®å¤„ç†
path_data = calculate_safe_path(obstacles['results'])
```

### 2. è¯­éŸ³è¾…åŠ©æœåŠ¡

```python
# éŸ³é¢‘ä¿¡å·é¢„å¤„ç†
filtered_audio = service.process_data(
    raw_audio, 
    'filter', 
    filter_type='bandpass', 
    cutoff=0.1
)

# è¯­éŸ³ç‰¹å¾æå–
audio_features = extract_mfcc_features(filtered_audio['filtered_signal'])

# è¯­éŸ³è¯†åˆ«å‡†ç¡®ç‡åˆ†æ
recognition_stats = service.process_data(audio_features, 'analyze')
```

### 3. æ‰‹è¯­è¯†åˆ«æœåŠ¡

```python
# æ‰‹åŠ¿è½¨è¿¹æ•°æ®åˆ†æ
gesture_trajectory = capture_hand_trajectory()
trajectory_analysis = service.process_data(gesture_trajectory, 'analyze')

# æ‰‹åŠ¿åˆ†ç±»
gesture_features = extract_gesture_features(trajectory_analysis)
gesture_classification = service.process_data(
    gesture_features, 
    'cluster', 
    n_clusters=10
)
```

### 4. å±å¹•é˜…è¯»æœåŠ¡

```python
# æ–‡æœ¬å¸ƒå±€åˆ†æ
text_positions = extract_text_positions(screen_image)
layout_analysis = service.process_data(text_positions, 'analyze')

# é˜…è¯»é¡ºåºä¼˜åŒ–
reading_order = optimize_reading_sequence(layout_analysis)
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. ä½¿ç”¨NumPyæ•°ç»„
```python
# æ¨èï¼šä½¿ç”¨NumPyæ•°ç»„
import numpy as np
data = np.array(sensor_readings)
result = service.process_data(data.tolist(), 'analyze')

# é¿å…ï¼šä½¿ç”¨Pythonåˆ—è¡¨è¿›è¡Œå¤§é‡è®¡ç®—
```

### 2. æ‰¹é‡å¤„ç†
```python
# æ‰¹é‡å¤„ç†å¤šä¸ªä¼ æ„Ÿå™¨æ•°æ®
sensor_results = {}
for sensor_name, sensor_data in all_sensors.items():
    sensor_results[sensor_name] = service.process_data(sensor_data, 'analyze')
```

### 3. ç¼“å­˜ç»“æœ
```python
# ç¼“å­˜é¢‘ç¹ä½¿ç”¨çš„åˆ†æç»“æœ
from functools import lru_cache

@lru_cache(maxsize=128)
def cached_analysis(data_hash):
    return service.process_data(data, 'analyze')
```

## ğŸ› æ•…éšœæ’é™¤

### 1. åº“å®‰è£…é—®é¢˜

```bash
# æ›´æ–°pip
python -m pip install --upgrade pip

# æ¸…ç†ç¼“å­˜
pip cache purge

# ä½¿ç”¨å›½å†…é•œåƒ
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple/ numpy scipy pandas
```

### 2. å†…å­˜é—®é¢˜

```python
# å¤„ç†å¤§æ•°æ®æ—¶åˆ†å—å¤„ç†
def process_large_dataset(large_data, chunk_size=1000):
    results = []
    for i in range(0, len(large_data), chunk_size):
        chunk = large_data[i:i+chunk_size]
        result = service.process_data(chunk, 'analyze')
        results.append(result)
    return results
```

### 3. æ€§èƒ½é—®é¢˜

```python
# ä½¿ç”¨æ€§èƒ½åˆ†æ
import time

start_time = time.time()
result = service.process_data(data, 'analyze')
processing_time = time.time() - start_time

print(f"å¤„ç†æ—¶é—´: {processing_time:.3f}ç§’")
```

## ğŸ“ˆ æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†
```python
try:
    result = service.process_data(data, 'analyze')
    if result['status'] == 'success':
        # å¤„ç†æˆåŠŸç»“æœ
        process_analysis_result(result['statistics'])
    else:
        # å¤„ç†é”™è¯¯
        logger.error(f"åˆ†æå¤±è´¥: {result['error']}")
except Exception as e:
    logger.error(f"å¤„ç†å¼‚å¸¸: {e}")
```

### 2. æ•°æ®éªŒè¯
```python
def validate_sensor_data(data):
    """éªŒè¯ä¼ æ„Ÿå™¨æ•°æ®"""
    if not data:
        raise ValueError("æ•°æ®ä¸èƒ½ä¸ºç©º")
    
    if len(data) < 10:
        logger.warning("æ•°æ®ç‚¹å¤ªå°‘ï¼Œåˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®")
    
    # æ£€æŸ¥æ•°æ®èŒƒå›´
    if any(abs(x) > 1000 for x in data):
        logger.warning("æ£€æµ‹åˆ°å¼‚å¸¸å¤§çš„æ•°å€¼")
    
    return True

# ä½¿ç”¨éªŒè¯
if validate_sensor_data(sensor_data):
    result = service.process_data(sensor_data, 'analyze')
```

### 3. é…ç½®ç®¡ç†
```python
# é…ç½®ç§‘å­¦è®¡ç®—å‚æ•°
ANALYSIS_CONFIG = {
    'anomaly_threshold': 2.5,
    'filter_cutoff': 0.1,
    'cluster_count': 3,
    'sample_rate': 44100
}

# ä½¿ç”¨é…ç½®
result = service.process_data(
    data, 
    'detect_anomalies', 
    threshold=ANALYSIS_CONFIG['anomaly_threshold']
)
```

## ğŸ”® æœªæ¥æ‰©å±•

### 1. è‡ªå®šä¹‰ç®—æ³•
```python
# æ‰©å±•æ•°æ®åˆ†æå¼•æ“
class CustomDataAnalysisEngine(DataAnalysisEngine):
    def custom_analysis(self, data):
        """è‡ªå®šä¹‰åˆ†æç®—æ³•"""
        # å®ç°è‡ªå®šä¹‰é€»è¾‘
        pass
```

### 2. æ–°åº“é›†æˆ
```python
# æ·»åŠ æ–°çš„ç§‘å­¦è®¡ç®—åº“æ”¯æŒ
def add_new_library_support():
    """æ·»åŠ æ–°åº“æ”¯æŒçš„æ¨¡æ¿"""
    try:
        import new_library
        # é›†æˆæ–°åº“åŠŸèƒ½
        return True
    except ImportError:
        return False
```

## ğŸ“ æ”¯æŒä¸åé¦ˆ

å¦‚æœæ‚¨åœ¨ä½¿ç”¨ç§‘å­¦è®¡ç®—åŠŸèƒ½æ—¶é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹å®‰è£…æŠ¥å‘Šï¼š`scientific_libraries_installation_report.md`
2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯ä¿¡æ¯
3. è¿è¡Œæµ‹è¯•éªŒè¯åŠŸèƒ½ï¼š`python test/test_scientific_computing_enhanced.py`
4. æäº¤é—®é¢˜æŠ¥å‘Šï¼ŒåŒ…å«è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œç¯å¢ƒé…ç½®

---

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¶é—´**: 2024å¹´5æœˆ24æ—¥  
**ç»´æŠ¤å›¢é˜Ÿ**: ç´¢å…‹ç”Ÿæ´»å¼€å‘å›¢é˜Ÿ 