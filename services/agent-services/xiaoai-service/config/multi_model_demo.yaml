# 多模型配置演示
# 只需要添加API KEY即可接入各种大模型

# 服务基础配置
service:
  name: "xiaoai-service"
  version: "0.1.0"

# 多模型配置 - 只需要API KEY！
models:
  # 主要LLM配置
  llm:
    primary_model: "deepseek-chat"      # 可以随时切换
    fallback_model: "gpt-4o-mini"      # 备用模型
    temperature: 0.7
    max_tokens: 2048
    
  # 1. DeepSeek (已配置)
  deepseek:
    api_key: "sk-26ac526b8c3b41c2a39bd80a156aaa68"  # 只需要这个！
    api_base: "https://api.deepseek.com/v1"
    model: "deepseek-chat"
    temperature: 0.7
    max_tokens: 2048
    
  # 2. OpenAI (只需要API KEY)
  openai:
    api_key: "${OPENAI_API_KEY}"                    # 环境变量或直接填入
    api_base: "https://api.openai.com/v1"
    model: "gpt-4o-mini"                           # 或 gpt-4, gpt-3.5-turbo
    temperature: 0.7
    max_tokens: 2048
    
  # 3. 智谱AI (只需要API KEY)
  zhipu:
    api_key: "${ZHIPU_API_KEY}"                    # 只需要这个！
    model: "glm-4"                                 # 或 glm-3-turbo
    temperature: 0.7
    max_tokens: 2048
    
  # 4. 百度文心 (只需要API KEY和SECRET)
  baidu:
    api_key: "${BAIDU_API_KEY}"                    # 只需要这两个！
    secret_key: "${BAIDU_SECRET_KEY}"
    model: "ernie-bot-turbo"                       # 或 ernie-bot-4.0
    temperature: 0.7
    max_tokens: 2048
    
  # 5. 阿里通义千问 (只需要API KEY)
  qwen:
    api_key: "${QWEN_API_KEY}"                     # 只需要这个！
    api_base: "https://dashscope.aliyuncs.com/api/v1"
    model: "qwen-turbo"                            # 或 qwen-max
    temperature: 0.7
    max_tokens: 2048
    
  # 6. 本地模型 (只需要端点)
  local_llm:
    endpoint_url: "http://localhost:11434/v1"      # Ollama端点
    model: "llama3"                                # 或其他本地模型
    temperature: 0.7
    max_tokens: 2048

# 模型切换策略
model_selection:
  # 自动故障转移
  auto_fallback: true
  
  # 负载均衡策略
  load_balance: "round_robin"  # 或 "random", "least_latency"
  
  # 用户偏好模型
  user_preferences:
    default: "deepseek-chat"
    premium_users: "gpt-4"
    
  # 按功能选择模型
  function_routing:
    chat: "deepseek-chat"           # 日常对话
    analysis: "gpt-4"               # 深度分析
    coding: "deepseek-coder"        # 代码生成
    translation: "qwen-turbo"       # 翻译任务

# 开发环境配置
development:
  mock_services: false              # 设为true使用模拟服务
  preferred_model: "deepseek-chat"  # 开发时优先使用的模型
  
# 模型健康监控
monitoring:
  health_check_interval: 60         # 健康检查间隔(秒)
  max_retry_attempts: 3             # 最大重试次数
  timeout_seconds: 30               # 请求超时时间 