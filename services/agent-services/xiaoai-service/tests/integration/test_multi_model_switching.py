"""
test_multi_model_switching - ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ¨¡å—
"""

    import openai
    import time
import asyncio
import os
import sys

#!/usr/bin/env python3
"""
å¤šæ¨¡å‹åˆ‡æ¢æ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•è½»æ¾åœ¨ä¸åŒå¤§æ¨¡å‹ä¹‹é—´åˆ‡æ¢
"""


# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('.')

async def demo_model_switching():
    """æ¼”ç¤ºæ¨¡å‹åˆ‡æ¢åŠŸèƒ½"""
    print("ğŸš€ å¤šæ¨¡å‹åˆ‡æ¢æ¼”ç¤º\n")

    # æµ‹è¯•é—®é¢˜
    test_question = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä¸­åŒ»çš„åŸºæœ¬ç†è®ºã€‚"

    model_configs = [
        {
            "name": "DeepSeek",
            "api_key": "sk-26ac526b8c3b41c2a39bd80a156aaa68",
            "api_base": "https://api.deepseek.com/v1",
            "model": "deepseek-chat",
            "description": "ä¸“ä¸šçš„ä¸­æ–‡å¤§æ¨¡å‹,æ“…é•¿ä¸­åŒ»çŸ¥è¯†"
        },
        {
            "name": "OpenAI GPT-4o-mini",
            "api_key": os.environ.get('OPENAI_API_KEY', ''),
            "api_base": "https://api.openai.com/v1",
            "model": "gpt-4o-mini",
            "description": "OpenAIçš„é«˜æ•ˆæ¨¡å‹"
        },
        {
            "name": "æ™ºè°±GLM-4",
            "api_key": os.environ.get('ZHIPU_API_KEY', ''),
            "api_base": "https://open.bigmodel.cn/api/paas/v4",
            "model": "glm-4",
            "description": "æ™ºè°±AIçš„æ——èˆ°æ¨¡å‹"
        }
    ]

    results = []

    for config in model_configs:
        print(f"ğŸ“Š æµ‹è¯•æ¨¡å‹: {config['name']}")
        print(f"   æè¿°: {config['description']}")

        if not config['api_key']:
            print("   âš ï¸  è·³è¿‡ - æœªé…ç½®API KEY")
            continue

        try:
            response = await call_model_api(config, test_question)

            results.append({
                "model": config['name'],
                "response": response[:200] + "..." if len(response) > 200 else response,
                "length": len(response),
                "success": True
            })

            print("   âœ… è°ƒç”¨æˆåŠŸ")
            print(f"   ğŸ“ å“åº”é•¿åº¦: {len(response)}å­—ç¬¦")
            print(f"   ğŸ’¬ å“åº”é¢„è§ˆ: {response[:100]}...")

        except Exception as e:
            print(f"   âŒ è°ƒç”¨å¤±è´¥: {e}")
            results.append({
                "model": config['name'],
                "error": str(e),
                "success": False
            })

        print()

    # è¾“å‡ºå¯¹æ¯”ç»“æœ
    print("="*60)
    print("ğŸ“‹ å¤šæ¨¡å‹å“åº”å¯¹æ¯”:")
    print("="*60)

    for result in results:
        if result['success']:
            print(f"ğŸ¤– {result['model']}:")
            print(f"   é•¿åº¦: {result['length']}å­—ç¬¦")
            print(f"   å†…å®¹: {result['response']}")
        else:
            print(f"âŒ {result['model']}: {result['error']}")
        print()

async def call_model_api(_config, question):
    """è°ƒç”¨æ¨¡å‹API"""


    client = openai.OpenAI(
        api_key=config['api_key'],
        base_url=config['api_base']
    )

    start_time = time.time()

    response = await asyncio.to_thread(
        client.chat.completions.create,
        model=config['model'],
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­åŒ»å¥åº·åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": question}
        ],
        max_tokens=500,
        temperature=0.7
    )

    processing_time = time.time() - start_time
    content = response.choices[0].message.content

    print(f"   â±ï¸  è€—æ—¶: {processing_time:.2f}ç§’")

    return content

async def demo_intelligent_model_selection():
    """æ¼”ç¤ºæ™ºèƒ½æ¨¡å‹é€‰æ‹©"""
    print("\nğŸ§  æ™ºèƒ½æ¨¡å‹é€‰æ‹©æ¼”ç¤º")
    print("="*40)

    # ä¸åŒç±»å‹çš„ä»»åŠ¡
    tasks = [
        {
            "type": "ä¸­åŒ»å’¨è¯¢",
            "question": "æˆ‘ç»å¸¸å¤±çœ ,ä»ä¸­åŒ»è§’åº¦åº”è¯¥å¦‚ä½•è°ƒç†?",
            "preferred_model": "deepseek-chat",
            "reason": "DeepSeekåœ¨ä¸­æ–‡å’Œä¸­åŒ»çŸ¥è¯†æ–¹é¢è¡¨ç°ä¼˜ç§€"
        },
        {
            "type": "ä»£ç ç”Ÿæˆ",
            "question": "è¯·ç”¨Pythonå†™ä¸€ä¸ªè®¡ç®—æ–æ³¢é‚£å¥‘æ•°åˆ—çš„å‡½æ•°",
            "preferred_model": "deepseek-coder",
            "reason": "DeepSeek Coderä¸“é—¨é’ˆå¯¹ä»£ç ç”Ÿæˆä¼˜åŒ–"
        },
        {
            "type": "åˆ›æ„å†™ä½œ",
            "question": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
            "preferred_model": "gpt-4",
            "reason": "GPT-4åœ¨åˆ›æ„å†™ä½œæ–¹é¢è¡¨ç°å‡ºè‰²"
        },
        {
            "type": "æ•°æ®åˆ†æ",
            "question": "åˆ†æä¸€ä¸‹ç”µå•†è¡Œä¸šçš„å‘å±•è¶‹åŠ¿",
            "preferred_model": "glm-4",
            "reason": "GLM-4åœ¨åˆ†æä»»åŠ¡ä¸Šè¡¨ç°è‰¯å¥½"
        }
    ]

    for task in tasks:
        print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task['type']}")
        print(f"â“ é—®é¢˜: {task['question']}")
        print(f"ğŸ¯ æ¨èæ¨¡å‹: {task['preferred_model']}")
        print(f"ğŸ’¡ é€‰æ‹©ç†ç”±: {task['reason']}")
        print()

async def demo_environment_based_switching():
    """æ¼”ç¤ºåŸºäºç¯å¢ƒçš„æ¨¡å‹åˆ‡æ¢"""
    print("\nğŸ”„ ç¯å¢ƒè‡ªé€‚åº”æ¨¡å‹åˆ‡æ¢æ¼”ç¤º")
    print("="*40)

    environments = [
        {
            "name": "å¼€å‘ç¯å¢ƒ",
            "config": "mock_services: true",
            "model": "æ¨¡æ‹Ÿæ¨¡å‹",
            "advantage": "å¿«é€Ÿå“åº”,æ— APIæˆæœ¬"
        },
        {
            "name": "æµ‹è¯•ç¯å¢ƒ",
            "config": "primary_model: deepseek-chat",
            "model": "DeepSeek",
            "advantage": "çœŸå®APIæµ‹è¯•,æˆæœ¬è¾ƒä½"
        },
        {
            "name": "ç”Ÿäº§ç¯å¢ƒ",
            "config": "primary_model: gpt-4, fallback_model: deepseek-chat",
            "model": "GPT-4 + DeepSeekå¤‡ç”¨",
            "advantage": "æœ€é«˜è´¨é‡,è‡ªåŠ¨æ•…éšœè½¬ç§»"
        }
    ]

    for env in environments:
        print(f"ğŸŒ {env['name']}:")
        print(f"   é…ç½®: {env['config']}")
        print(f"   æ¨¡å‹: {env['model']}")
        print(f"   ä¼˜åŠ¿: {env['advantage']}")
        print()

async def demo_simple_api_key_setup():
    """æ¼”ç¤ºç®€å•çš„API KEYè®¾ç½®"""
    print("\nğŸ”‘ ç®€å•API KEYè®¾ç½®æ¼”ç¤º")
    print("="*40)

    setup_examples = [
        {
            "provider": "DeepSeek",
            "method": "ç¯å¢ƒå˜é‡",
            "command": "export DEEPSEEK_API_KEY='your-api-key'",
            "config": "api_key: ${DEEPSEEK_API_KEY}"
        },
        {
            "provider": "OpenAI",
            "method": "ç›´æ¥é…ç½®",
            "command": "ç›´æ¥åœ¨é…ç½®æ–‡ä»¶ä¸­å¡«å…¥",
            "config": "api_key: 'sk-your-openai-key'"
        },
        {
            "provider": "æ™ºè°±AI",
            "method": "ç¯å¢ƒå˜é‡",
            "command": "export ZHIPU_API_KEY='your-zhipu-key'",
            "config": "api_key: ${ZHIPU_API_KEY}"
        }
    ]

    for example in setup_examples:
        print(f"ğŸ”Œ {example['provider']}:")
        print(f"   æ–¹æ³•: {example['method']}")
        print(f"   å‘½ä»¤: {example['command']}")
        print(f"   é…ç½®: {example['config']}")
        print()

    print("ğŸ’¡ æç¤º: åªéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ API KEY,ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨ç›¸åº”çš„æ¨¡å‹!")

async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸ¯ å¤šæ¨¡å‹æ¥å…¥ä¸åˆ‡æ¢æ¼”ç¤º")
    print("="*60)

    # 1. æ¼”ç¤ºå¤šæ¨¡å‹åˆ‡æ¢
    await demo_model_switching()

    # 2. æ¼”ç¤ºæ™ºèƒ½æ¨¡å‹é€‰æ‹©
    await demo_intelligent_model_selection()

    # 3. æ¼”ç¤ºç¯å¢ƒè‡ªé€‚åº”åˆ‡æ¢
    await demo_environment_based_switching()

    await demo_simple_api_key_setup()

    print("\n" + "="*60)
    print("âœ¨ æ€»ç»“:")
    print("="*60)
    print("âœ… åªéœ€è¦API KEYå³å¯æ¥å…¥ä»»ä½•å¤§æ¨¡å‹")
    print("âœ… æ”¯æŒå¤šæ¨¡å‹å¹¶å­˜å’Œæ™ºèƒ½åˆ‡æ¢")
    print("âœ… è‡ªåŠ¨æ•…éšœè½¬ç§»å’Œè´Ÿè½½å‡è¡¡")
    print("âœ… ç¯å¢ƒè‡ªé€‚åº”é…ç½®")
    print("âœ… é›¶ä»£ç é…ç½®,åªéœ€ä¿®æ”¹YAMLæ–‡ä»¶")

    print("\nğŸš€ ä½¿ç”¨æ–¹æ³•:")
    print("1. åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ API KEY")
    print("2. è®¾ç½®primary_modelæŒ‡å®šä¸»è¦æ¨¡å‹")
    print("3. ç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ¨¡å‹è°ƒç”¨å’Œåˆ‡æ¢")
    print("4. æ”¯æŒå®æ—¶åˆ‡æ¢,æ— éœ€é‡å¯æœåŠ¡")

if __name__ == "__main__":
    asyncio.run(main())
