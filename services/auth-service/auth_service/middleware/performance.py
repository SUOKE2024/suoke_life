"""
performance - ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ¨¡å—
"""

from auth_service.config.settings import get_settings
from collections import defaultdict, deque
from contextlib import asynccontextmanager
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from fastapi import Request, Response
from fastapi.responses import JSONResponse
from typing import Dict, Any, Optional, List
import asyncio
import json
import logging
import psutil
import time

"""
æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–ä¸­é—´ä»¶
æä¾›è¯·æ±‚æ€§èƒ½ç›‘æ§ã€ç¼“å­˜ä¼˜åŒ–ã€æ•°æ®åº“è¿æ¥æ± ç®¡ç†ç­‰åŠŸèƒ½
"""




@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç»“æ„"""
    request_id: str
    endpoint: str
    method: str
    response_time: float
    status_code: int
    request_size: int
    response_size: int
    memory_usage: float
    cpu_usage: float
    db_query_count: int
    db_query_time: float
    cache_hits: int
    cache_misses: int
    timestamp: datetime
    user_id: Optional[str] = None
    ip_address: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        data = asdict(self)
        data['timestamp'] = self.timestamp.isoformat()
        return data


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.settings = get_settings()
        self.logger = logging.getLogger("performance")
        
        # æ€§èƒ½æŒ‡æ ‡å­˜å‚¨
        self.metrics_buffer: deque = deque(maxlen=1000)
        self.endpoint_stats: Dict[str, Dict] = defaultdict(lambda: {
            'total_requests': 0,
            'total_response_time': 0.0,
            'min_response_time': float('inf'),
            'max_response_time': 0.0,
            'error_count': 0,
            'last_reset': datetime.utcnow()
        })
        
        # æ…¢æŸ¥è¯¢é˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰
        self.slow_query_threshold = 1000
        self.slow_request_threshold = 2000
        
        # ç³»ç»Ÿèµ„æºç›‘æ§
        self.system_metrics = {
            'cpu_percent': 0.0,
            'memory_percent': 0.0,
            'disk_usage': 0.0,
            'network_io': {'bytes_sent': 0, 'bytes_recv': 0}
        }
        
        # å¯åŠ¨ç³»ç»Ÿç›‘æ§ä»»åŠ¡
        asyncio.create_task(self._monitor_system_resources())
    
    async def record_metrics(self, metrics: PerformanceMetrics):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        try:
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self.metrics_buffer.append(metrics)
            
            # æ›´æ–°ç«¯ç‚¹ç»Ÿè®¡
            self._update_endpoint_stats(metrics)
            
            # æ£€æŸ¥æ€§èƒ½é—®é¢˜
            await self._check_performance_issues(metrics)
            
            # è®°å½•åˆ°æ—¥å¿—
            self._log_metrics(metrics)
            
        except Exception as e:
            self.logger.error(f"è®°å½•æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _update_endpoint_stats(self, metrics: PerformanceMetrics):
        """æ›´æ–°ç«¯ç‚¹ç»Ÿè®¡ä¿¡æ¯"""
        endpoint_key = f"{metrics.method}:{metrics.endpoint}"
        stats = self.endpoint_stats[endpoint_key]
        
        stats['total_requests'] += 1
        stats['total_response_time'] += metrics.response_time
        stats['min_response_time'] = min(stats['min_response_time'], metrics.response_time)
        stats['max_response_time'] = max(stats['max_response_time'], metrics.response_time)
        
        if metrics.status_code >= 400:
            stats['error_count'] += 1
        
        # è®¡ç®—å¹³å‡å“åº”æ—¶é—´
        stats['avg_response_time'] = stats['total_response_time'] / stats['total_requests']
    
    async def _check_performance_issues(self, metrics: PerformanceMetrics):
        """æ£€æŸ¥æ€§èƒ½é—®é¢˜"""
        issues = []
        
        # æ£€æŸ¥æ…¢è¯·æ±‚
        if metrics.response_time > self.slow_request_threshold:
            issues.append({
                'type': 'slow_request',
                'severity': 'high' if metrics.response_time > 5000 else 'medium',
                'message': f"æ…¢è¯·æ±‚: {metrics.endpoint} å“åº”æ—¶é—´ {metrics.response_time:.2f}ms"
            })
        
        # æ£€æŸ¥æ•°æ®åº“æ…¢æŸ¥è¯¢
        if metrics.db_query_time > self.slow_query_threshold:
            issues.append({
                'type': 'slow_query',
                'severity': 'high',
                'message': f"æ•°æ®åº“æ…¢æŸ¥è¯¢: {metrics.db_query_time:.2f}ms"
            })
        
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        if metrics.memory_usage > 80:
            issues.append({
                'type': 'high_memory',
                'severity': 'critical' if metrics.memory_usage > 90 else 'high',
                'message': f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {metrics.memory_usage:.1f}%"
            })
        
        # æ£€æŸ¥CPUä½¿ç”¨
        if metrics.cpu_usage > 80:
            issues.append({
                'type': 'high_cpu',
                'severity': 'critical' if metrics.cpu_usage > 90 else 'high',
                'message': f"CPUä½¿ç”¨ç‡è¿‡é«˜: {metrics.cpu_usage:.1f}%"
            })
        
        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        total_cache_requests = metrics.cache_hits + metrics.cache_misses
        if total_cache_requests > 0:
            hit_rate = metrics.cache_hits / total_cache_requests
            if hit_rate < 0.5:
                issues.append({
                    'type': 'low_cache_hit_rate',
                    'severity': 'medium',
                    'message': f"ç¼“å­˜å‘½ä¸­ç‡è¿‡ä½: {hit_rate:.1%}"
                })
        
        # å‘é€å‘Šè­¦
        if issues:
            await self._send_performance_alerts(metrics, issues)
    
    def _log_metrics(self, metrics: PerformanceMetrics):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡åˆ°æ—¥å¿—"""
        log_data = metrics.to_dict()
        
        if metrics.response_time > self.slow_request_threshold:
            self.logger.warning(f"SLOW_REQUEST: {json.dumps(log_data, ensure_ascii=False)}")
        else:
            self.logger.info(f"PERFORMANCE_METRICS: {json.dumps(log_data, ensure_ascii=False)}")
    
    async def _send_performance_alerts(self, metrics: PerformanceMetrics, issues: List[Dict]):
        """å‘é€æ€§èƒ½å‘Šè­¦"""
        try:
            for issue in issues:
                alert_message = f"""
ğŸš¨ æ€§èƒ½å‘Šè­¦ - {issue['severity'].upper()}

é—®é¢˜ç±»å‹: {issue['type']}
ç«¯ç‚¹: {metrics.endpoint}
å“åº”æ—¶é—´: {metrics.response_time:.2f}ms
å†…å­˜ä½¿ç”¨: {metrics.memory_usage:.1f}%
CPUä½¿ç”¨: {metrics.cpu_usage:.1f}%
æ—¶é—´: {metrics.timestamp.strftime('%Y-%m-%d %H:%M:%S')}

è¯¦ç»†ä¿¡æ¯: {issue['message']}
                """.strip()
                
                # è¿™é‡Œå¯ä»¥é›†æˆå‘Šè­¦ç³»ç»Ÿ
                self.logger.error(f"PERFORMANCE_ALERT: {alert_message}")
                
        except Exception as e:
            self.logger.error(f"å‘é€æ€§èƒ½å‘Šè­¦å¤±è´¥: {e}")
    
    async def _monitor_system_resources(self):
        """ç›‘æ§ç³»ç»Ÿèµ„æº"""
        while True:
            try:
                # CPUä½¿ç”¨ç‡
                self.system_metrics['cpu_percent'] = psutil.cpu_percent(interval=1)
                
                # å†…å­˜ä½¿ç”¨ç‡
                memory = psutil.virtual_memory()
                self.system_metrics['memory_percent'] = memory.percent
                
                # ç£ç›˜ä½¿ç”¨ç‡
                disk = psutil.disk_usage('/')
                self.system_metrics['disk_usage'] = (disk.used / disk.total) * 100
                
                # ç½‘ç»œIO
                net_io = psutil.net_io_counters()
                self.system_metrics['network_io'] = {
                    'bytes_sent': net_io.bytes_sent,
                    'bytes_recv': net_io.bytes_recv
                }
                
                await asyncio.sleep(30)  # æ¯30ç§’æ›´æ–°ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"ç³»ç»Ÿèµ„æºç›‘æ§å¤±è´¥: {e}")
                await asyncio.sleep(60)
    
    def get_endpoint_stats(self, endpoint: str = None) -> Dict[str, Any]:
        """è·å–ç«¯ç‚¹ç»Ÿè®¡ä¿¡æ¯"""
        if endpoint:
            return self.endpoint_stats.get(endpoint, {})
        return dict(self.endpoint_stats)
    
    def get_system_metrics(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸæŒ‡æ ‡"""
        return self.system_metrics.copy()
    
    def get_recent_metrics(self, limit: int = 100) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„æ€§èƒ½æŒ‡æ ‡"""
        return [metrics.to_dict() for metrics in list(self.metrics_buffer)[-limit:]]


class PerformanceMiddleware:
    """æ€§èƒ½ç›‘æ§ä¸­é—´ä»¶"""
    
    def __init__(self, app):
        self.app = app
        self.monitor = PerformanceMonitor()
        self.settings = get_settings()
        
        # æ•°æ®åº“æŸ¥è¯¢è®¡æ•°å™¨
        self.db_query_count = 0
        self.db_query_time = 0.0
        
        # ç¼“å­˜è®¡æ•°å™¨
        self.cache_hits = 0
        self.cache_misses = 0
    
    async def __call__(self, request: Request, call_next):
        """ä¸­é—´ä»¶å¤„ç†å‡½æ•°"""
        start_time = time.time()
        
        # é‡ç½®è®¡æ•°å™¨
        self.db_query_count = 0
        self.db_query_time = 0.0
        self.cache_hits = 0
        self.cache_misses = 0
        
        # è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        process = psutil.Process()
        memory_before = process.memory_percent()
        cpu_before = process.cpu_percent()
        
        # å¤„ç†è¯·æ±‚
        response = await call_next(request)
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        end_time = time.time()
        response_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
        
        # è·å–è¯·æ±‚å’Œå“åº”å¤§å°
        request_size = int(request.headers.get("Content-Length", 0))
        response_size = int(response.headers.get("Content-Length", 0))
        
        # è·å–ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ
        memory_after = process.memory_percent()
        cpu_after = process.cpu_percent()
        
        # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡
        metrics = PerformanceMetrics(
            request_id=getattr(request.state, 'request_id', 'unknown'),
            endpoint=request.url.path,
            method=request.method,
            response_time=response_time,
            status_code=response.status_code,
            request_size=request_size,
            response_size=response_size,
            memory_usage=memory_after,
            cpu_usage=cpu_after,
            db_query_count=self.db_query_count,
            db_query_time=self.db_query_time,
            cache_hits=self.cache_hits,
            cache_misses=self.cache_misses,
            timestamp=datetime.utcnow(),
            user_id=getattr(request.state, 'user_id', None),
            ip_address=self._get_client_ip(request)
        )
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        await self.monitor.record_metrics(metrics)
        
        # æ·»åŠ æ€§èƒ½å¤´ä¿¡æ¯
        response.headers["X-Response-Time"] = f"{response_time:.2f}ms"
        response.headers["X-DB-Queries"] = str(self.db_query_count)
        response.headers["X-Cache-Status"] = f"hits:{self.cache_hits},misses:{self.cache_misses}"
        
        return response
    
    def _get_client_ip(self, request: Request) -> str:
        """è·å–å®¢æˆ·ç«¯IPåœ°å€"""
        forwarded_for = request.headers.get("X-Forwarded-For")
        if forwarded_for:
            return forwarded_for.split(",")[0].strip()
        
        real_ip = request.headers.get("X-Real-IP")
        if real_ip:
            return real_ip
        
        return request.client.host if request.client else "unknown"


class DatabaseQueryTracker:
    """æ•°æ®åº“æŸ¥è¯¢è·Ÿè¸ªå™¨"""
    
    def __init__(self, middleware: PerformanceMiddleware):
        self.middleware = middleware
    
    @asynccontextmanager
    async     @cache(timeout=300)  # 5åˆ†é’Ÿç¼“å­˜
def track_query(self, query: str):
        """è·Ÿè¸ªæ•°æ®åº“æŸ¥è¯¢"""
        start_time = time.time()
        try:
            yield
        finally:
            end_time = time.time()
            query_time = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’
            
            self.middleware.db_query_count += 1
            self.middleware.db_query_time += query_time
            
            # è®°å½•æ…¢æŸ¥è¯¢
            if query_time > self.middleware.monitor.slow_query_threshold:
                self.middleware.monitor.logger.warning(
                    f"SLOW_QUERY: {query_time:.2f}ms - {query[:200]}..."
                )


class CacheTracker:
    """ç¼“å­˜è·Ÿè¸ªå™¨"""
    
    def __init__(self, middleware: PerformanceMiddleware):
        self.middleware = middleware
    
    def record_hit(self):
        """è®°å½•ç¼“å­˜å‘½ä¸­"""
        self.middleware.cache_hits += 1
    
    def record_miss(self):
        """è®°å½•ç¼“å­˜æœªå‘½ä¸­"""
        self.middleware.cache_misses += 1


# æ€§èƒ½ä¼˜åŒ–è£…é¥°å™¨
def performance_monitor(func):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            end_time = time.time()
            execution_time = (end_time - start_time) * 1000
            
            logger = logging.getLogger("performance")
            logger.info(f"FUNCTION_PERFORMANCE: {func.__name__} - {execution_time:.2f}ms")
    
    return wrapper


def cache_performance(cache_key: str, ttl: int = 300):
    """ç¼“å­˜æ€§èƒ½è£…é¥°å™¨"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            # è¿™é‡Œå¯ä»¥é›†æˆRedisç¼“å­˜
            # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨çœŸå®çš„ç¼“å­˜ç³»ç»Ÿ
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = None  # await redis.get(cache_key)
            
            if cached_result:
                # ç¼“å­˜å‘½ä¸­
                return cached_result
            else:
                # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
                result = await func(*args, **kwargs)
                
                # å­˜å‚¨åˆ°ç¼“å­˜
                # await redis.setex(cache_key, ttl, result)
                
                return result
        
        return wrapper
    return decorator


# æ€§èƒ½åˆ†æå·¥å…·
class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå·¥å…·"""
    
    def __init__(self, monitor: PerformanceMonitor):
        self.monitor = monitor
    
    def analyze_endpoint_performance(self, endpoint: str, hours: int = 24) -> Dict[str, Any]:
        """åˆ†æç«¯ç‚¹æ€§èƒ½"""
        stats = self.monitor.get_endpoint_stats(endpoint)
        
        if not stats or stats['total_requests'] == 0:
            return {"error": "æ²¡æœ‰æ‰¾åˆ°è¯¥ç«¯ç‚¹çš„æ€§èƒ½æ•°æ®"}
        
        analysis = {
            "endpoint": endpoint,
            "total_requests": stats['total_requests'],
            "avg_response_time": stats['avg_response_time'],
            "min_response_time": stats['min_response_time'],
            "max_response_time": stats['max_response_time'],
            "error_rate": stats['error_count'] / stats['total_requests'],
            "performance_grade": self._calculate_performance_grade(stats),
            "recommendations": self._generate_recommendations(stats)
        }
        
        return analysis
    
    def _calculate_performance_grade(self, stats: Dict) -> str:
        """è®¡ç®—æ€§èƒ½ç­‰çº§"""
        avg_time = stats['avg_response_time']
        error_rate = stats['error_count'] / stats['total_requests']
        
        if avg_time < 100 and error_rate < 0.01:
            return "A"
        elif avg_time < 500 and error_rate < 0.05:
            return "B"
        elif avg_time < 1000 and error_rate < 0.1:
            return "C"
        elif avg_time < 2000 and error_rate < 0.2:
            return "D"
        else:
            return "F"
    
    def _generate_recommendations(self, stats: Dict) -> List[str]:
        """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        avg_time = stats['avg_response_time']
        error_rate = stats['error_count'] / stats['total_requests']
        
        if avg_time > 1000:
            recommendations.append("å“åº”æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æˆ–æ·»åŠ ç¼“å­˜")
        
        if error_rate > 0.05:
            recommendations.append("é”™è¯¯ç‡è¿‡é«˜ï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯å¤„ç†é€»è¾‘")
        
        if stats['max_response_time'] > stats['avg_response_time'] * 5:
            recommendations.append("å“åº”æ—¶é—´æ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ")
        
        return recommendations


# å…¨å±€æ€§èƒ½ç›‘æ§å®ä¾‹
performance_monitor_instance = None

def get_performance_monitor() -> PerformanceMonitor:
    """è·å–æ€§èƒ½ç›‘æ§å®ä¾‹"""
    global performance_monitor_instance
    if performance_monitor_instance is None:
        performance_monitor_instance = PerformanceMonitor()
    return performance_monitor_instance 