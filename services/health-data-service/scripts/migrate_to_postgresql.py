"""
migrate_to_postgresql - ç´¢å…‹ç”Ÿæ´»é¡¹ç›®æ¨¡å—
"""

        from ..internal.model.database import Base
    import argparse
from loguru import logger
from psycopg2.extras import RealDictCursor
from sqlalchemy.ext.asyncio import create_async_engine
import asyncio
import os
import psycopg2
import sqlite3
import sys
import yaml

#!/usr/bin/env python

"""
æ•°æ®è¿ç§»è„šæœ¬ï¼šä»SQLiteè¿ç§»åˆ°PostgreSQL
ç”¨äºå°†å¥åº·æ•°æ®æœåŠ¡çš„æ•°æ®ä»SQLiteæ•°æ®åº“è¿ç§»åˆ°PostgreSQLæ•°æ®åº“
"""




class DatabaseMigrator:
    """æ•°æ®åº“è¿ç§»å™¨"""

    def __init__(self, config_path: str = "config/default.yaml"):
        """
        åˆå§‹åŒ–è¿ç§»å™¨

        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.config = None
        self.sqlite_path = None
        self.pg_config = None

    async def load_config(self) -> None:
        """åŠ è½½é…ç½®"""
        try:
            with open(self.config_path, encoding='utf-8') as f:
                self.config = yaml.safe_load(f)

            # è·å–PostgreSQLé…ç½®
            db_config = self.config['database']
            self.pg_config = {
                'host': os.getenv('DB_HOST', db_config.get('host', 'localhost')),
                'port': int(os.getenv('DB_PORT', db_config.get('port', 5432))),
                'database': os.getenv('DB_NAME', db_config.get('database', 'suoke_health_data')),
                'user': os.getenv('DB_USER', db_config.get('username', 'postgres')),
                'password': os.getenv('DB_PASSWORD', db_config.get('password', 'postgres'))
            }

            # è·å–SQLiteè·¯å¾„ï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤è·¯å¾„ï¼‰
            self.sqlite_path = os.getenv('SQLITE_DB_PATH', 'data/health_data.db')

            logger.info(f"é…ç½®åŠ è½½æˆåŠŸï¼ŒPostgreSQL: {self.pg_config['host']}:{self.pg_config['port']}")
            logger.info(f"SQLiteè·¯å¾„: {self.sqlite_path}")

        except Exception as e:
            logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {e}")
            raise

    async def check_prerequisites(self) -> bool:
        """æ£€æŸ¥è¿ç§»å‰ææ¡ä»¶"""
        logger.info("æ£€æŸ¥è¿ç§»å‰ææ¡ä»¶...")

        # æ£€æŸ¥SQLiteæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(self.sqlite_path):
            logger.error(f"SQLiteæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {self.sqlite_path}")
            return False

        # æ£€æŸ¥PostgreSQLè¿æ¥
        try:
            conn = psycopg2.connect(**self.pg_config)
            conn.close()
            logger.info("PostgreSQLè¿æ¥æµ‹è¯•æˆåŠŸ")
        except Exception as e:
            logger.error(f"PostgreSQLè¿æ¥å¤±è´¥: {e}")
            return False

        return True

    async def create_postgresql_database(self) -> None:
        """åˆ›å»ºPostgreSQLæ•°æ®åº“ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰"""
        logger.info("æ£€æŸ¥å¹¶åˆ›å»ºPostgreSQLæ•°æ®åº“...")

        # è¿æ¥åˆ°é»˜è®¤æ•°æ®åº“
        temp_config = self.pg_config.copy()
        temp_config['database'] = 'postgres'

        try:
            conn = psycopg2.connect(**temp_config)
            conn.autocommit = True
            cursor = conn.cursor()

            # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
            cursor.execute(
                "SELECT 1 FROM pg_database WHERE datname = %s",
                (self.pg_config['database'],)
            )

            if not cursor.fetchone():
                # åˆ›å»ºæ•°æ®åº“
                cursor.execute(f'CREATE DATABASE "{self.pg_config["database"]}"')
                logger.info(f"æ•°æ®åº“ {self.pg_config['database']} åˆ›å»ºæˆåŠŸ")
            else:
                logger.info(f"æ•°æ®åº“ {self.pg_config['database']} å·²å­˜åœ¨")

            cursor.close()
            conn.close()

        except Exception as e:
            logger.error(f"åˆ›å»ºPostgreSQLæ•°æ®åº“å¤±è´¥: {e}")
            raise

    async def create_postgresql_tables(self) -> None:
        """åœ¨PostgreSQLä¸­åˆ›å»ºè¡¨ç»“æ„"""
        logger.info("åˆ›å»ºPostgreSQLè¡¨ç»“æ„...")

        # ä½¿ç”¨SQLAlchemyåˆ›å»ºè¡¨

        pg_url = f"postgresql+asyncpg://{self.pg_config['user']}:{self.pg_config['password']}@{self.pg_config['host']}:{self.pg_config['port']}/{self.pg_config['database']}"

        engine = create_async_engine(pg_url)

        try:
            async with engine.begin() as conn:
                await conn.run_sync(Base.metadata.create_all)

            logger.info("PostgreSQLè¡¨ç»“æ„åˆ›å»ºæˆåŠŸ")

        except Exception as e:
            logger.error(f"åˆ›å»ºPostgreSQLè¡¨ç»“æ„å¤±è´¥: {e}")
            raise
        finally:
            await engine.dispose()

    async def migrate_data(self) -> None:
        """è¿ç§»æ•°æ®"""
        logger.info("å¼€å§‹æ•°æ®è¿ç§»...")

        # è¿æ¥SQLite
        sqlite_conn = sqlite3.connect(self.sqlite_path)
        sqlite_conn.row_factory = sqlite3.Row

        # è¿æ¥PostgreSQL
        pg_conn = psycopg2.connect(**self.pg_config)
        pg_cursor = pg_conn.cursor(cursor_factory=RealDictCursor)

        try:
            # è·å–è¦è¿ç§»çš„è¡¨åˆ—è¡¨
            tables_to_migrate = [
                'users',
                'health_data_records',
                'health_insight_records',
                'health_profile_records',
                'system_metrics',
                'audit_logs'
            ]

            for table_name in tables_to_migrate:
                await self._migrate_table(sqlite_conn, pg_conn, pg_cursor, table_name)

            pg_conn.commit()
            logger.info("æ•°æ®è¿ç§»å®Œæˆ")

        except Exception as e:
            pg_conn.rollback()
            logger.error(f"æ•°æ®è¿ç§»å¤±è´¥: {e}")
            raise
        finally:
            sqlite_conn.close()
            pg_cursor.close()
            pg_conn.close()

    async def _migrate_table(
        self,
        sqlite_conn: sqlite3.Connection,
        pg_conn: psycopg2.extensions.connection,
        pg_cursor: psycopg2.extensions.cursor,
        table_name: str
    ) -> None:
        """è¿ç§»å•ä¸ªè¡¨çš„æ•°æ®"""
        logger.info(f"è¿ç§»è¡¨: {table_name}")

        # æ£€æŸ¥SQLiteè¡¨æ˜¯å¦å­˜åœ¨
        sqlite_cursor = sqlite_conn.cursor()
        sqlite_cursor.execute(
            "SELECT name FROM sqlite_master WHERE type='table' AND name=?",
            (table_name,)
        )

        if not sqlite_cursor.fetchone():
            logger.warning(f"SQLiteä¸­ä¸å­˜åœ¨è¡¨: {table_name}")
            return

        # è·å–SQLiteè¡¨æ•°æ®
        sqlite_cursor.execute(f"SELECT * FROM {table_name}")
        rows = sqlite_cursor.fetchall()

        if not rows:
            logger.info(f"è¡¨ {table_name} æ— æ•°æ®ï¼Œè·³è¿‡")
            return

        # è·å–åˆ—å
        column_names = [description[0] for description in sqlite_cursor.description]

        # æ¸…ç©ºPostgreSQLè¡¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
        pg_cursor.execute(f"TRUNCATE TABLE {table_name} RESTART IDENTITY CASCADE")

        # æ‰¹é‡æ’å…¥æ•°æ®
        batch_size = 1000
        total_rows = len(rows)

        for i in range(0, total_rows, batch_size):
            batch = rows[i:i + batch_size]

            # æ„å»ºæ’å…¥è¯­å¥
            placeholders = ', '.join(['%s'] * len(column_names))
            columns = ', '.join(column_names)
            insert_sql = f"INSERT INTO {table_name} ({columns}) VALUES ({placeholders})"

            # å‡†å¤‡æ•°æ®
            batch_data = []
            for row in batch:
                row_data = []
                for value in row:
                    # å¤„ç†ç‰¹æ®Šæ•°æ®ç±»å‹
                    if isinstance(value, str) and value.startswith('{') and value.endswith('}'):
                        # JSONå­—ç¬¦ä¸²ä¿æŒåŸæ ·
                        row_data.append(value)
                    else:
                        row_data.append(value)
                batch_data.append(tuple(row_data))

            # æ‰§è¡Œæ‰¹é‡æ’å…¥
            try:
                pg_cursor.executemany(insert_sql, batch_data)
                logger.info(f"è¡¨ {table_name}: å·²è¿ç§» {min(i + batch_size, total_rows)}/{total_rows} è¡Œ")
            except Exception as e:
                logger.error(f"æ’å…¥æ•°æ®å¤±è´¥ - è¡¨: {table_name}, æ‰¹æ¬¡: {i//batch_size + 1}, é”™è¯¯: {e}")
                raise

        logger.info(f"è¡¨ {table_name} è¿ç§»å®Œæˆï¼Œå…± {total_rows} è¡Œ")

    async def update_sequences(self) -> None:
        """æ›´æ–°PostgreSQLåºåˆ—"""
        logger.info("æ›´æ–°PostgreSQLåºåˆ—...")

        pg_conn = psycopg2.connect(**self.pg_config)
        pg_cursor = pg_conn.cursor()

        try:
            # è·å–æ‰€æœ‰åºåˆ—
            pg_cursor.execute("""
                SELECT schemaname, sequencename, tablename, columnname
                FROM pg_sequences
                JOIN information_schema.columns ON
                    column_default LIKE '%' || sequencename || '%'
                WHERE schemaname = 'public'
            """)

            sequences = pg_cursor.fetchall()

            for _schema, seq_name, table_name, column_name in sequences:
                # è·å–è¡¨ä¸­è¯¥åˆ—çš„æœ€å¤§å€¼
                pg_cursor.execute(f"SELECT MAX({column_name}) FROM {table_name}")
                max_value = pg_cursor.fetchone()[0]

                if max_value is not None:
                    # è®¾ç½®åºåˆ—çš„ä¸‹ä¸€ä¸ªå€¼
                    pg_cursor.execute(f"SELECT setval('{seq_name}', {max_value})")
                    logger.info(f"åºåˆ— {seq_name} æ›´æ–°ä¸º {max_value}")

            pg_conn.commit()
            logger.info("åºåˆ—æ›´æ–°å®Œæˆ")

        except Exception as e:
            pg_conn.rollback()
            logger.error(f"æ›´æ–°åºåˆ—å¤±è´¥: {e}")
            raise
        finally:
            pg_cursor.close()
            pg_conn.close()

    async def verify_migration(self) -> bool:
        """éªŒè¯è¿ç§»ç»“æœ"""
        logger.info("éªŒè¯è¿ç§»ç»“æœ...")

        # è¿æ¥SQLite
        sqlite_conn = sqlite3.connect(self.sqlite_path)
        sqlite_cursor = sqlite_conn.cursor()

        # è¿æ¥PostgreSQL
        pg_conn = psycopg2.connect(**self.pg_config)
        pg_cursor = pg_conn.cursor()

        try:
            # è·å–è¡¨åˆ—è¡¨
            sqlite_cursor.execute(
                "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite_%'"
            )
            tables = [row[0] for row in sqlite_cursor.fetchall()]

            verification_passed = True

            for table_name in tables:
                # è·å–SQLiteè¡¨è¡Œæ•°
                sqlite_cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                sqlite_count = sqlite_cursor.fetchone()[0]

                # è·å–PostgreSQLè¡¨è¡Œæ•°
                try:
                    pg_cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                    pg_count = pg_cursor.fetchone()[0]
                except Exception:
                    pg_count = 0

                if sqlite_count == pg_count:
                    logger.info(f"âœ“ è¡¨ {table_name}: SQLite({sqlite_count}) = PostgreSQL({pg_count})")
                else:
                    logger.error(f"âœ— è¡¨ {table_name}: SQLite({sqlite_count}) â‰  PostgreSQL({pg_count})")
                    verification_passed = False

            return verification_passed

        except Exception as e:
            logger.error(f"éªŒè¯è¿ç§»ç»“æœå¤±è´¥: {e}")
            return False
        finally:
            sqlite_cursor.close()
            sqlite_conn.close()
            pg_cursor.close()
            pg_conn.close()

    async def run_migration(self) -> bool:
        """è¿è¡Œå®Œæ•´çš„è¿ç§»æµç¨‹"""
        try:
            logger.info("å¼€å§‹æ•°æ®åº“è¿ç§»æµç¨‹...")

            # 1. åŠ è½½é…ç½®
            await self.load_config()

            # 2. æ£€æŸ¥å‰ææ¡ä»¶
            if not await self.check_prerequisites():
                return False

            # 3. åˆ›å»ºPostgreSQLæ•°æ®åº“
            await self.create_postgresql_database()

            # 4. åˆ›å»ºè¡¨ç»“æ„
            await self.create_postgresql_tables()

            # 5. è¿ç§»æ•°æ®
            await self.migrate_data()

            # 6. æ›´æ–°åºåˆ—
            await self.update_sequences()

            # 7. éªŒè¯è¿ç§»ç»“æœ
            if await self.verify_migration():
                logger.info("ğŸ‰ æ•°æ®åº“è¿ç§»æˆåŠŸå®Œæˆï¼")
                return True
            else:
                logger.error("âŒ æ•°æ®åº“è¿ç§»éªŒè¯å¤±è´¥ï¼")
                return False

        except Exception as e:
            logger.error(f"æ•°æ®åº“è¿ç§»å¤±è´¥: {e}")
            return False


async def main():
    """ä¸»å‡½æ•°"""

    parser = argparse.ArgumentParser(description="å¥åº·æ•°æ®æœåŠ¡æ•°æ®åº“è¿ç§»å·¥å…·")
    parser.add_argument(
        "--config",
        default="config/default.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--sqlite-path",
        help="SQLiteæ•°æ®åº“æ–‡ä»¶è·¯å¾„ï¼ˆè¦†ç›–é…ç½®æ–‡ä»¶ï¼‰"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ä»…æ£€æŸ¥å‰ææ¡ä»¶ï¼Œä¸æ‰§è¡Œè¿ç§»"
    )

    args = parser.parse_args()

    # è®¾ç½®æ—¥å¿—
    logger.add(
        "logs/migration_{time}.log",
        rotation="10 MB",
        retention="30 days",
        level="INFO"
    )

    migrator = DatabaseMigrator(args.config)

    if args.sqlite_path:
        migrator.sqlite_path = args.sqlite_path

    if args.dry_run:
        await migrator.load_config()
        success = await migrator.check_prerequisites()
        if success:
            logger.info("âœ“ å‰ææ¡ä»¶æ£€æŸ¥é€šè¿‡ï¼Œå¯ä»¥æ‰§è¡Œè¿ç§»")
        else:
            logger.error("âœ— å‰ææ¡ä»¶æ£€æŸ¥å¤±è´¥")
        return success

    success = await migrator.run_migration()

    if success:
        logger.info("\n" + "="*50)
        logger.info("è¿ç§»å®Œæˆï¼è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š")
        logger.info("1. æ›´æ–°ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ï¼ŒæŒ‡å‘PostgreSQLæ•°æ®åº“")
        logger.info("2. é‡å¯å¥åº·æ•°æ®æœåŠ¡")
        logger.info("3. éªŒè¯æœåŠ¡æ­£å¸¸è¿è¡Œ")
        logger.info("4. å¤‡ä»½SQLiteæ–‡ä»¶åå¯ä»¥åˆ é™¤")
        logger.info("="*50)
        sys.exit(0)
    else:
        logger.error("è¿ç§»å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—å¹¶ä¿®å¤é—®é¢˜åé‡è¯•")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
