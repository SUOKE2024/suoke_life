# ç´¢å…‹ç”Ÿæ´»å¹³å°å¾®æœåŠ¡é›†æˆä¼˜åŒ–è®¡åˆ’

## ğŸ¯ ä¼˜åŒ–ç›®æ ‡

åŸºäºç°æœ‰æ¶æ„åˆ†æï¼Œåˆ¶å®šå…¨é¢çš„å¾®æœåŠ¡é—´é›†æˆå’Œå‰ç«¯é›†æˆä¼˜åŒ–ç­–ç•¥ï¼Œæå‡ç³»ç»Ÿçš„å¯é æ€§ã€æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚

## ğŸ“‹ å½“å‰æ¶æ„è¯„ä¼°

### å¾®æœåŠ¡ç»„æˆåˆ†æ
```
æ ¸å¿ƒæœåŠ¡å±‚:
â”œâ”€â”€ api-gateway (APIç½‘å…³) - ç»Ÿä¸€å…¥å£ âœ…
â”œâ”€â”€ auth-service (è®¤è¯æœåŠ¡) - èº«ä»½è®¤è¯ âœ…
â”œâ”€â”€ user-service (ç”¨æˆ·æœåŠ¡) - ç”¨æˆ·ç®¡ç† âœ…
â”œâ”€â”€ health-data-service (å¥åº·æ•°æ®) - æ•°æ®å­˜å‚¨ âœ…
â”œâ”€â”€ blockchain-service (åŒºå—é“¾) - æ•°æ®å®Œæ•´æ€§ âœ…
â””â”€â”€ message-bus (æ¶ˆæ¯æ€»çº¿) - å¼‚æ­¥é€šä¿¡ âš ï¸

æ™ºèƒ½ä½“æœåŠ¡å±‚:
â”œâ”€â”€ xiaoai-service (å°è‰¾) - ä¸­åŒ»è¯Šæ–­ âœ…
â”œâ”€â”€ xiaoke-service (å°å…‹) - æœåŠ¡ç®¡ç† âœ…
â”œâ”€â”€ laoke-service (è€å…‹) - å¥åº·æ•™è‚² âœ…
â””â”€â”€ soer-service (ç´¢å„¿) - ç”Ÿæ´»å»ºè®® âœ…

è¯Šæ–­æœåŠ¡å±‚:
â”œâ”€â”€ look-service (æœ›è¯Š) âœ…
â”œâ”€â”€ listen-service (é—»è¯Š) âœ…
â”œâ”€â”€ inquiry-service (é—®è¯Š) âœ…
â””â”€â”€ palpation-service (åˆ‡è¯Š) âœ…

æ”¯æ’‘æœåŠ¡å±‚:
â”œâ”€â”€ rag-service (RAGæœåŠ¡) - çŸ¥è¯†æ£€ç´¢ âœ…
â”œâ”€â”€ med-knowledge (åŒ»å­¦çŸ¥è¯†) âœ…
â”œâ”€â”€ accessibility-service (æ— éšœç¢) âœ…
â””â”€â”€ corn-maze-service (è¿·å®«æœåŠ¡) âœ…
```

### æ¶æ„ä¼˜åŠ¿
- âœ… æœåŠ¡èŒè´£æ¸…æ™°åˆ†ç¦»
- âœ… APIç½‘å…³ç»Ÿä¸€å…¥å£
- âœ… å¤šåè®®æ”¯æŒï¼ˆREST/gRPCï¼‰
- âœ… å‰ç«¯æ¶æ„æ¸…æ™°ï¼ˆReact Native + Reduxï¼‰
- âœ… è®¤è¯æœåŠ¡é›†ä¸­ç®¡ç†

### å…³é”®é—®é¢˜
- âŒ ç¼ºä¹åŠ¨æ€æœåŠ¡å‘ç°
- âŒ åˆ†å¸ƒå¼äº‹åŠ¡ç®¡ç†ä¸å®Œå–„
- âŒ ç«¯åˆ°ç«¯ç›‘æ§ä¸è¶³
- âŒ é…ç½®ç®¡ç†åˆ†æ•£
- âŒ å®¹é”™æœºåˆ¶éœ€è¦åŠ å¼º

## ğŸš€ ä¼˜åŒ–æ–¹æ¡ˆ

### Phase 1: æœåŠ¡ç½‘æ ¼é›†æˆ (2-3å‘¨)

#### 1.1 IstioæœåŠ¡ç½‘æ ¼éƒ¨ç½²
```yaml
# deploy/istio/istio-config.yaml
apiVersion: install.istio.io/v1alpha1
kind: IstioOperator
metadata:
  name: suoke-life-istio
spec:
  values:
    global:
      meshID: suoke-mesh
      network: suoke-network
    pilot:
      env:
        EXTERNAL_ISTIOD: false
  components:
    pilot:
      k8s:
        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 512Mi
    ingressGateways:
    - name: istio-ingressgateway
      enabled: true
      k8s:
        service:
          type: LoadBalancer
          ports:
          - port: 80
            targetPort: 8080
            name: http2
          - port: 443
            targetPort: 8443
            name: https
```

#### 1.2 æœåŠ¡é—´é€šä¿¡å®‰å…¨
```yaml
# deploy/istio/security-policies.yaml
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: default
  namespace: suoke
spec:
  mtls:
    mode: STRICT
---
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: service-to-service
  namespace: suoke
spec:
  rules:
  - from:
    - source:
        principals: ["cluster.local/ns/suoke/sa/api-gateway"]
    to:
    - operation:
        methods: ["GET", "POST", "PUT", "DELETE"]
  - from:
    - source:
        principals: ["cluster.local/ns/suoke/sa/xiaoai-service"]
    to:
    - operation:
        methods: ["POST"]
        paths: ["/api/v1/diagnosis/*"]
```

### Phase 2: åŠ¨æ€æœåŠ¡å‘ç° (1-2å‘¨)

#### 2.1 Consulé›†æˆå¢å¼º
```python
# services/common/service-registry/enhanced_consul_client.py
import consul
import asyncio
import json
from typing import Dict, List, Optional, Callable
from dataclasses import dataclass
import logging

@dataclass
class ServiceInstance:
    service_id: str
    service_name: str
    address: str
    port: int
    health_status: str
    metadata: Dict[str, str]

class EnhancedConsulClient:
    def __init__(self, consul_host: str = "localhost", consul_port: int = 8500):
        self.consul = consul.Consul(host=consul_host, port=consul_port)
        self.service_cache: Dict[str, List[ServiceInstance]] = {}
        self.watchers: Dict[str, List[Callable]] = {}
        self.logger = logging.getLogger(__name__)
    
    async def register_service(self, service_name: str, service_id: str, 
                              address: str, port: int, health_check_url: str,
                              metadata: Dict[str, str] = None):
        """æ³¨å†ŒæœåŠ¡åˆ°Consul"""
        try:
            check = consul.Check.http(health_check_url, interval="10s", timeout="5s")
            
            self.consul.agent.service.register(
                name=service_name,
                service_id=service_id,
                address=address,
                port=port,
                check=check,
                meta=metadata or {}
            )
            
            self.logger.info(f"æœåŠ¡æ³¨å†ŒæˆåŠŸ: {service_name} ({service_id})")
        except Exception as e:
            self.logger.error(f"æœåŠ¡æ³¨å†Œå¤±è´¥: {e}")
            raise
    
    async def discover_service(self, service_name: str, 
                              healthy_only: bool = True) -> List[ServiceInstance]:
        """å‘ç°æœåŠ¡å®ä¾‹"""
        try:
            _, services = self.consul.health.service(service_name, passing=healthy_only)
            
            instances = []
            for service in services:
                instance = ServiceInstance(
                    service_id=service["Service"]["ID"],
                    service_name=service["Service"]["Service"],
                    address=service["Service"]["Address"],
                    port=service["Service"]["Port"],
                    health_status="healthy" if healthy_only else "unknown",
                    metadata=service["Service"].get("Meta", {})
                )
                instances.append(instance)
            
            # æ›´æ–°ç¼“å­˜
            self.service_cache[service_name] = instances
            
            return instances
            
        except Exception as e:
            self.logger.error(f"æœåŠ¡å‘ç°å¤±è´¥: {e}")
            # è¿”å›ç¼“å­˜çš„å®ä¾‹
            return self.service_cache.get(service_name, [])
    
    async def watch_service(self, service_name: str, callback: Callable):
        """ç›‘å¬æœåŠ¡å˜åŒ–"""
        if service_name not in self.watchers:
            self.watchers[service_name] = []
        self.watchers[service_name].append(callback)
        
        # å¯åŠ¨ç›‘å¬ä»»åŠ¡
        asyncio.create_task(self._watch_service_changes(service_name))
    
    async def _watch_service_changes(self, service_name: str):
        """ç›‘å¬æœåŠ¡å˜åŒ–çš„åå°ä»»åŠ¡"""
        index = None
        while True:
            try:
                index, data = self.consul.health.service(
                    service_name, index=index, wait="30s"
                )
                
                # è·å–æœ€æ–°çš„æœåŠ¡å®ä¾‹
                new_instances = await self.discover_service(service_name)
                
                # é€šçŸ¥æ‰€æœ‰è§‚å¯Ÿè€…
                for callback in self.watchers.get(service_name, []):
                    try:
                        await callback(service_name, new_instances)
                    except Exception as e:
                        self.logger.error(f"æœåŠ¡å˜åŒ–å›è°ƒå¤±è´¥: {e}")
                        
            except Exception as e:
                self.logger.error(f"æœåŠ¡ç›‘å¬å¤±è´¥: {e}")
                await asyncio.sleep(5)
```

#### 2.2 APIç½‘å…³åŠ¨æ€è·¯ç”±å¢å¼º
```python
# services/api-gateway/internal/service/enhanced_dynamic_router.py
import asyncio
import aiohttp
import random
from typing import Dict, List, Optional
from dataclasses import dataclass
from enum import Enum
import time
import logging

class LoadBalanceStrategy(Enum):
    ROUND_ROBIN = "round_robin"
    RANDOM = "random"
    WEIGHTED_ROUND_ROBIN = "weighted_round_robin"
    LEAST_CONNECTIONS = "least_connections"

@dataclass
class ServiceEndpoint:
    address: str
    port: int
    weight: int = 1
    active_connections: int = 0
    last_used: float = 0
    health_score: float = 1.0

class EnhancedDynamicRouter:
    def __init__(self, consul_client, strategy: LoadBalanceStrategy = LoadBalanceStrategy.ROUND_ROBIN):
        self.consul = consul_client
        self.strategy = strategy
        self.service_endpoints: Dict[str, List[ServiceEndpoint]] = {}
        self.round_robin_counters: Dict[str, int] = {}
        self.circuit_breakers: Dict[str, 'CircuitBreaker'] = {}
        self.logger = logging.getLogger(__name__)
    
    async def get_service_endpoint(self, service_name: str) -> Optional[ServiceEndpoint]:
        """è·å–æœåŠ¡ç«¯ç‚¹ï¼ˆå¸¦è´Ÿè½½å‡è¡¡å’Œç†”æ–­ï¼‰"""
        # æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
        circuit_breaker = self.circuit_breakers.get(service_name)
        if circuit_breaker and circuit_breaker.is_open():
            self.logger.warning(f"æœåŠ¡ {service_name} ç†”æ–­å™¨å¼€å¯ï¼Œæ‹’ç»è¯·æ±‚")
            return None
        
        # è·å–å¯ç”¨çš„æœåŠ¡å®ä¾‹
        endpoints = await self._get_healthy_endpoints(service_name)
        if not endpoints:
            self.logger.error(f"æœåŠ¡ {service_name} æ— å¯ç”¨å®ä¾‹")
            return None
        
        # æ ¹æ®è´Ÿè½½å‡è¡¡ç­–ç•¥é€‰æ‹©ç«¯ç‚¹
        endpoint = self._select_endpoint(service_name, endpoints)
        
        if endpoint:
            endpoint.active_connections += 1
            endpoint.last_used = time.time()
        
        return endpoint
    
    async def _get_healthy_endpoints(self, service_name: str) -> List[ServiceEndpoint]:
        """è·å–å¥åº·çš„æœåŠ¡ç«¯ç‚¹"""
        if service_name not in self.service_endpoints:
            await self._refresh_service_endpoints(service_name)
        
        # è¿‡æ»¤å¥åº·çš„ç«¯ç‚¹
        healthy_endpoints = [
            ep for ep in self.service_endpoints.get(service_name, [])
            if ep.health_score > 0.5
        ]
        
        return healthy_endpoints
    
    def _select_endpoint(self, service_name: str, endpoints: List[ServiceEndpoint]) -> Optional[ServiceEndpoint]:
        """æ ¹æ®è´Ÿè½½å‡è¡¡ç­–ç•¥é€‰æ‹©ç«¯ç‚¹"""
        if not endpoints:
            return None
        
        if self.strategy == LoadBalanceStrategy.ROUND_ROBIN:
            return self._round_robin_select(service_name, endpoints)
        elif self.strategy == LoadBalanceStrategy.RANDOM:
            return random.choice(endpoints)
        elif self.strategy == LoadBalanceStrategy.WEIGHTED_ROUND_ROBIN:
            return self._weighted_round_robin_select(service_name, endpoints)
        elif self.strategy == LoadBalanceStrategy.LEAST_CONNECTIONS:
            return min(endpoints, key=lambda ep: ep.active_connections)
        else:
            return endpoints[0]
    
    def _round_robin_select(self, service_name: str, endpoints: List[ServiceEndpoint]) -> ServiceEndpoint:
        """è½®è¯¢é€‰æ‹©"""
        if service_name not in self.round_robin_counters:
            self.round_robin_counters[service_name] = 0
        
        index = self.round_robin_counters[service_name] % len(endpoints)
        self.round_robin_counters[service_name] += 1
        
        return endpoints[index]
    
    def _weighted_round_robin_select(self, service_name: str, endpoints: List[ServiceEndpoint]) -> ServiceEndpoint:
        """åŠ æƒè½®è¯¢é€‰æ‹©"""
        total_weight = sum(ep.weight for ep in endpoints)
        if total_weight == 0:
            return endpoints[0]
        
        # ç®€åŒ–çš„åŠ æƒè½®è¯¢å®ç°
        weighted_endpoints = []
        for ep in endpoints:
            weighted_endpoints.extend([ep] * ep.weight)
        
        return self._round_robin_select(service_name, weighted_endpoints)
    
    async def _refresh_service_endpoints(self, service_name: str):
        """åˆ·æ–°æœåŠ¡ç«¯ç‚¹"""
        try:
            instances = await self.consul.discover_service(service_name)
            endpoints = []
            
            for instance in instances:
                endpoint = ServiceEndpoint(
                    address=instance.address,
                    port=instance.port,
                    weight=int(instance.metadata.get('weight', 1)),
                    health_score=1.0
                )
                endpoints.append(endpoint)
            
            self.service_endpoints[service_name] = endpoints
            self.logger.info(f"åˆ·æ–°æœåŠ¡ç«¯ç‚¹: {service_name}, å®ä¾‹æ•°: {len(endpoints)}")
            
        except Exception as e:
            self.logger.error(f"åˆ·æ–°æœåŠ¡ç«¯ç‚¹å¤±è´¥: {e}")
    
    async def report_request_result(self, service_name: str, endpoint: ServiceEndpoint, 
                                   success: bool, response_time: float):
        """æŠ¥å‘Šè¯·æ±‚ç»“æœï¼Œç”¨äºå¥åº·è¯„åˆ†å’Œç†”æ–­"""
        endpoint.active_connections = max(0, endpoint.active_connections - 1)
        
        # æ›´æ–°å¥åº·è¯„åˆ†
        if success:
            endpoint.health_score = min(1.0, endpoint.health_score + 0.1)
        else:
            endpoint.health_score = max(0.0, endpoint.health_score - 0.2)
        
        # æ›´æ–°ç†”æ–­å™¨
        circuit_breaker = self.circuit_breakers.get(service_name)
        if circuit_breaker:
            if success:
                circuit_breaker.record_success()
            else:
                circuit_breaker.record_failure()
```

### Phase 3: åˆ†å¸ƒå¼äº‹åŠ¡ç®¡ç† (2-3å‘¨)

#### 3.1 Sagaæ¨¡å¼å®ç°
```python
# services/common/distributed-transaction/saga_orchestrator.py
import asyncio
import json
import uuid
from enum import Enum
from typing import List, Dict, Any, Callable, Optional
from dataclasses import dataclass, asdict
import logging
import time

class SagaStepStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    COMPENSATING = "compensating"
    COMPENSATED = "compensated"

@dataclass
class SagaStep:
    step_id: str
    name: str
    action: Callable
    compensation: Callable
    status: SagaStepStatus = SagaStepStatus.PENDING
    result: Any = None
    error: str = None
    started_at: float = None
    completed_at: float = None
    retry_count: int = 0
    max_retries: int = 3

class SagaOrchestrator:
    def __init__(self, saga_id: str = None, event_bus=None):
        self.saga_id = saga_id or str(uuid.uuid4())
        self.steps: List[SagaStep] = []
        self.completed_steps: List[SagaStep] = []
        self.event_bus = event_bus
        self.logger = logging.getLogger(__name__)
        self.status = "created"
        self.created_at = time.time()
        self.completed_at = None
    
    def add_step(self, name: str, action: Callable, compensation: Callable, 
                 max_retries: int = 3) -> 'SagaOrchestrator':
        """æ·»åŠ Sagaæ­¥éª¤"""
        step = SagaStep(
            step_id=str(uuid.uuid4()),
            name=name,
            action=action,
            compensation=compensation,
            max_retries=max_retries
        )
        self.steps.append(step)
        return self
    
    async def execute(self) -> bool:
        """æ‰§è¡ŒSagaäº‹åŠ¡"""
        self.status = "running"
        self.logger.info(f"å¼€å§‹æ‰§è¡ŒSagaäº‹åŠ¡: {self.saga_id}")
        
        try:
            # å‘å¸ƒSagaå¼€å§‹äº‹ä»¶
            await self._publish_event("saga_started", {
                "saga_id": self.saga_id,
                "steps_count": len(self.steps)
            })
            
            for step in self.steps:
                success = await self._execute_step(step)
                if not success:
                    self.logger.error(f"Sagaæ­¥éª¤å¤±è´¥: {step.name}")
                    await self._compensate()
                    self.status = "failed"
                    return False
                
                self.completed_steps.append(step)
            
            self.status = "completed"
            self.completed_at = time.time()
            
            # å‘å¸ƒSagaå®Œæˆäº‹ä»¶
            await self._publish_event("saga_completed", {
                "saga_id": self.saga_id,
                "duration": self.completed_at - self.created_at
            })
            
            self.logger.info(f"Sagaäº‹åŠ¡æ‰§è¡ŒæˆåŠŸ: {self.saga_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"Sagaæ‰§è¡Œå¼‚å¸¸: {e}")
            await self._compensate()
            self.status = "failed"
            return False
    
    async def _execute_step(self, step: SagaStep) -> bool:
        """æ‰§è¡Œå•ä¸ªæ­¥éª¤ï¼ˆå¸¦é‡è¯•ï¼‰"""
        step.status = SagaStepStatus.RUNNING
        step.started_at = time.time()
        
        for attempt in range(step.max_retries + 1):
            try:
                self.logger.info(f"æ‰§è¡Œæ­¥éª¤: {step.name} (å°è¯• {attempt + 1}/{step.max_retries + 1})")
                
                # å‘å¸ƒæ­¥éª¤å¼€å§‹äº‹ä»¶
                await self._publish_event("step_started", {
                    "saga_id": self.saga_id,
                    "step_id": step.step_id,
                    "step_name": step.name,
                    "attempt": attempt + 1
                })
                
                step.result = await step.action()
                step.status = SagaStepStatus.COMPLETED
                step.completed_at = time.time()
                
                # å‘å¸ƒæ­¥éª¤å®Œæˆäº‹ä»¶
                await self._publish_event("step_completed", {
                    "saga_id": self.saga_id,
                    "step_id": step.step_id,
                    "step_name": step.name,
                    "duration": step.completed_at - step.started_at
                })
                
                return True
                
            except Exception as e:
                step.retry_count = attempt + 1
                step.error = str(e)
                
                self.logger.warning(f"æ­¥éª¤æ‰§è¡Œå¤±è´¥: {step.name}, é”™è¯¯: {e}")
                
                if attempt < step.max_retries:
                    # æŒ‡æ•°é€€é¿é‡è¯•
                    delay = 2 ** attempt
                    self.logger.info(f"ç­‰å¾… {delay} ç§’åé‡è¯•...")
                    await asyncio.sleep(delay)
                else:
                    step.status = SagaStepStatus.FAILED
                    
                    # å‘å¸ƒæ­¥éª¤å¤±è´¥äº‹ä»¶
                    await self._publish_event("step_failed", {
                        "saga_id": self.saga_id,
                        "step_id": step.step_id,
                        "step_name": step.name,
                        "error": str(e),
                        "retry_count": step.retry_count
                    })
                    
                    return False
        
        return False
    
    async def _compensate(self):
        """æ‰§è¡Œè¡¥å¿æ“ä½œ"""
        self.logger.info(f"å¼€å§‹è¡¥å¿Sagaäº‹åŠ¡: {self.saga_id}")
        
        # å‘å¸ƒè¡¥å¿å¼€å§‹äº‹ä»¶
        await self._publish_event("compensation_started", {
            "saga_id": self.saga_id,
            "steps_to_compensate": len(self.completed_steps)
        })
        
        # é€†åºæ‰§è¡Œè¡¥å¿
        for step in reversed(self.completed_steps):
            await self._compensate_step(step)
        
        # å‘å¸ƒè¡¥å¿å®Œæˆäº‹ä»¶
        await self._publish_event("compensation_completed", {
            "saga_id": self.saga_id
        })
    
    async def _compensate_step(self, step: SagaStep):
        """è¡¥å¿å•ä¸ªæ­¥éª¤"""
        step.status = SagaStepStatus.COMPENSATING
        
        try:
            self.logger.info(f"è¡¥å¿æ­¥éª¤: {step.name}")
            await step.compensation()
            step.status = SagaStepStatus.COMPENSATED
            
            # å‘å¸ƒè¡¥å¿æˆåŠŸäº‹ä»¶
            await self._publish_event("step_compensated", {
                "saga_id": self.saga_id,
                "step_id": step.step_id,
                "step_name": step.name
            })
            
        except Exception as e:
            self.logger.error(f"è¡¥å¿æ­¥éª¤å¤±è´¥: {step.name}, é”™è¯¯: {e}")
            
            # å‘å¸ƒè¡¥å¿å¤±è´¥äº‹ä»¶
            await self._publish_event("step_compensation_failed", {
                "saga_id": self.saga_id,
                "step_id": step.step_id,
                "step_name": step.name,
                "error": str(e)
            })
    
    async def _publish_event(self, event_type: str, data: Dict[str, Any]):
        """å‘å¸ƒäº‹ä»¶"""
        if self.event_bus:
            try:
                await self.event_bus.publish({
                    "type": event_type,
                    "saga_id": self.saga_id,
                    "timestamp": time.time(),
                    "data": data
                })
            except Exception as e:
                self.logger.error(f"å‘å¸ƒäº‹ä»¶å¤±è´¥: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–SagaçŠ¶æ€"""
        return {
            "saga_id": self.saga_id,
            "status": self.status,
            "created_at": self.created_at,
            "completed_at": self.completed_at,
            "total_steps": len(self.steps),
            "completed_steps": len(self.completed_steps),
            "steps": [
                {
                    "step_id": step.step_id,
                    "name": step.name,
                    "status": step.status.value,
                    "retry_count": step.retry_count,
                    "error": step.error
                }
                for step in self.steps
            ]
        }

# ä½¿ç”¨ç¤ºä¾‹ï¼šå¥åº·æ•°æ®å½•å…¥Saga
class HealthDataSagaFactory:
    def __init__(self, user_service, health_data_service, blockchain_service, 
                 xiaoai_service, event_bus):
        self.user_service = user_service
        self.health_data_service = health_data_service
        self.blockchain_service = blockchain_service
        self.xiaoai_service = xiaoai_service
        self.event_bus = event_bus
    
    def create_health_data_saga(self, user_id: str, health_data: Dict) -> SagaOrchestrator:
        """åˆ›å»ºå¥åº·æ•°æ®å½•å…¥Saga"""
        saga = SagaOrchestrator(event_bus=self.event_bus)
        
        # æ­¥éª¤1ï¼šéªŒè¯ç”¨æˆ·
        saga.add_step(
            "validate_user",
            lambda: self.user_service.validate_user(user_id),
            lambda: None  # éªŒè¯å¤±è´¥æ— éœ€è¡¥å¿
        )
        
        # æ­¥éª¤2ï¼šä¿å­˜å¥åº·æ•°æ®
        data_id = None
        saga.add_step(
            "save_health_data",
            lambda: self._save_health_data(user_id, health_data),
            lambda: self.health_data_service.delete(user_id, data_id) if data_id else None
        )
        
        # æ­¥éª¤3ï¼šæ›´æ–°åŒºå—é“¾
        blockchain_tx_id = None
        saga.add_step(
            "update_blockchain",
            lambda: self._update_blockchain(user_id, health_data),
            lambda: self.blockchain_service.rollback_record(blockchain_tx_id) if blockchain_tx_id else None
        )
        
        # æ­¥éª¤4ï¼šè§¦å‘æ™ºèƒ½ä½“åˆ†æ
        analysis_id = None
        saga.add_step(
            "trigger_ai_analysis",
            lambda: self._trigger_ai_analysis(user_id, health_data),
            lambda: self.xiaoai_service.cancel_analysis(analysis_id) if analysis_id else None
        )
        
        return saga
    
    async def _save_health_data(self, user_id: str, health_data: Dict):
        """ä¿å­˜å¥åº·æ•°æ®"""
        result = await self.health_data_service.save(user_id, health_data)
        # ä¿å­˜data_idç”¨äºè¡¥å¿
        nonlocal data_id
        data_id = result.get('id')
        return result
    
    async def _update_blockchain(self, user_id: str, health_data: Dict):
        """æ›´æ–°åŒºå—é“¾"""
        result = await self.blockchain_service.record_health_data(user_id, health_data)
        # ä¿å­˜äº¤æ˜“IDç”¨äºè¡¥å¿
        nonlocal blockchain_tx_id
        blockchain_tx_id = result.get('transaction_id')
        return result
    
    async def _trigger_ai_analysis(self, user_id: str, health_data: Dict):
        """è§¦å‘AIåˆ†æ"""
        result = await self.xiaoai_service.analyze_health_data(user_id, health_data)
        # ä¿å­˜åˆ†æIDç”¨äºè¡¥å¿
        nonlocal analysis_id
        analysis_id = result.get('analysis_id')
        return result
```

### Phase 4: å‰ç«¯é›†æˆä¼˜åŒ– (2-3å‘¨)

#### 4.1 æ™ºèƒ½é‡è¯•å’Œç¼“å­˜ç­–ç•¥
```typescript
// src/services/enhancedApiClient.ts
import AsyncStorage from "@react-native-async-storage/async-storage";
import NetInfo from "@react-native-netinfo/";
import { EventEmitter } from 'events';

interface RetryConfig {
  maxAttempts: number;
  baseDelay: number;
  maxDelay: number;
  backoffFactor: number;
  retryableErrors: string[];
}

interface CacheConfig {
  ttl: number;
  maxSize: number;
  strategy: 'memory' | 'storage' | 'both';
}

interface RequestMetrics {
  requestCount: number;
  successCount: number;
  errorCount: number;
  averageResponseTime: number;
  lastRequestTime: number;
}

class EnhancedApiClient extends EventEmitter {
  private cache = new Map<string, any>();
  private metrics = new Map<string, RequestMetrics>();
  private retryConfig: RetryConfig = {
    maxAttempts: 3,
    baseDelay: 1000,
    maxDelay: 10000,
    backoffFactor: 2,
    retryableErrors: ['NETWORK_ERROR', 'TIMEOUT', '500', '502', '503', '504']
  };
  
  private cacheConfig: CacheConfig = {
    ttl: 5 * 60 * 1000, // 5åˆ†é’Ÿ
    maxSize: 100,
    strategy: 'both'
  };

  async requestWithRetry<T>(
    method: string,
    endpoint: string,
    data?: any,
    config?: any
  ): Promise<T> {
    const startTime = Date.now();
    let lastError: Error;
    
    // æ£€æŸ¥ç¼“å­˜ï¼ˆä»…GETè¯·æ±‚ï¼‰
    if (method === 'GET') {
      const cachedData = await this.getCachedResponse(endpoint);
      if (cachedData) {
        this.emit('cacheHit', { endpoint, data: cachedData });
        return { success: true, data: cachedData };
      }
    }
    
    for (let attempt = 1; attempt <= this.retryConfig.maxAttempts; attempt++) {
      try {
        // æ£€æŸ¥ç½‘ç»œçŠ¶æ€
        const netInfo = await NetInfo.fetch();
        if (!netInfo.isConnected) {
          throw new Error('Network not available');
        }

        const response = await this.request(method, endpoint, data, config);
        
        // è®°å½•æˆåŠŸæŒ‡æ ‡
        this.recordMetrics(endpoint, true, Date.now() - startTime);
        
        // æˆåŠŸæ—¶ç¼“å­˜å“åº”
        if (method === 'GET' && response.success) {
          await this.cacheResponse(endpoint, response.data);
        }
        
        this.emit('requestSuccess', { 
          method, 
          endpoint, 
          attempt, 
          responseTime: Date.now() - startTime 
        });
        
        return response;
        
      } catch (error) {
        lastError = error as Error;
        
        // è®°å½•å¤±è´¥æŒ‡æ ‡
        this.recordMetrics(endpoint, false, Date.now() - startTime);
        
        // æ£€æŸ¥æ˜¯å¦åº”è¯¥é‡è¯•
        if (!this.shouldRetry(error, attempt)) {
          break;
        }
        
        // å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œå°è¯•ä»ç¼“å­˜è·å–æ•°æ®
        if (attempt === this.retryConfig.maxAttempts) {
          if (method === 'GET') {
            const cachedData = await this.getCachedResponse(endpoint, true); // å…è®¸è¿‡æœŸç¼“å­˜
            if (cachedData) {
              this.emit('fallbackToCache', { endpoint, error: lastError });
              return { success: true, data: cachedData, fromCache: true };
            }
          }
          break;
        }
        
        // è®¡ç®—å»¶è¿Ÿæ—¶é—´
        const delay = Math.min(
          this.retryConfig.baseDelay * Math.pow(this.retryConfig.backoffFactor, attempt - 1),
          this.retryConfig.maxDelay
        );
        
        this.emit('retryAttempt', { 
          method, 
          endpoint, 
          attempt, 
          maxAttempts: this.retryConfig.maxAttempts,
          delay,
          error: lastError.message
        });
        
        await this.sleep(delay);
      }
    }
    
    this.emit('requestFailed', { 
      method, 
      endpoint, 
      error: lastError,
      totalAttempts: this.retryConfig.maxAttempts
    });
    
    throw lastError!;
  }

  private shouldRetry(error: any, attempt: number): boolean {
    if (attempt >= this.retryConfig.maxAttempts) {
      return false;
    }
    
    const errorCode = error.code || error.status?.toString() || 'UNKNOWN';
    return this.retryConfig.retryableErrors.includes(errorCode);
  }

  private async cacheResponse(key: string, data: any): Promise<void> {
    try {
      const cacheEntry = {
        data,
        timestamp: Date.now(),
        ttl: this.cacheConfig.ttl
      };
      
      // å†…å­˜ç¼“å­˜
      if (this.cacheConfig.strategy === 'memory' || this.cacheConfig.strategy === 'both') {
        // æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
        if (this.cache.size >= this.cacheConfig.maxSize) {
          // åˆ é™¤æœ€æ—§çš„æ¡ç›®
          const oldestKey = this.cache.keys().next().value;
          this.cache.delete(oldestKey);
        }
        this.cache.set(key, cacheEntry);
      }
      
      // æŒä¹…åŒ–ç¼“å­˜
      if (this.cacheConfig.strategy === 'storage' || this.cacheConfig.strategy === 'both') {
        await AsyncStorage.setItem(
          `api_cache_${key}`,
          JSON.stringify(cacheEntry)
        );
      }
      
      this.emit('dataCached', { key, size: JSON.stringify(data).length });
    } catch (error) {
      console.warn('Failed to cache response:', error);
    }
  }

  private async getCachedResponse(key: string, allowExpired: boolean = false): Promise<any> {
    try {
      let cacheEntry = null;
      
      // å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
      if (this.cacheConfig.strategy === 'memory' || this.cacheConfig.strategy === 'both') {
        cacheEntry = this.cache.get(key);
      }
      
      // å¦‚æœå†…å­˜ä¸­æ²¡æœ‰ï¼Œæ£€æŸ¥æŒä¹…åŒ–ç¼“å­˜
      if (!cacheEntry && (this.cacheConfig.strategy === 'storage' || this.cacheConfig.strategy === 'both')) {
        const storageCache = await AsyncStorage.getItem(`api_cache_${key}`);
        if (storageCache) {
          cacheEntry = JSON.parse(storageCache);
          // æ¢å¤åˆ°å†…å­˜ç¼“å­˜
          if (this.cacheConfig.strategy === 'both') {
            this.cache.set(key, cacheEntry);
          }
        }
      }
      
      if (cacheEntry) {
        const isExpired = Date.now() - cacheEntry.timestamp > cacheEntry.ttl;
        if (!isExpired || allowExpired) {
          return cacheEntry.data;
        } else {
          // æ¸…ç†è¿‡æœŸç¼“å­˜
          this.cache.delete(key);
          await AsyncStorage.removeItem(`api_cache_${key}`);
        }
      }
      
      return null;
    } catch (error) {
      console.warn('Failed to get cached response:', error);
      return null;
    }
  }

  private recordMetrics(endpoint: string, success: boolean, responseTime: number): void {
    const current = this.metrics.get(endpoint) || {
      requestCount: 0,
      successCount: 0,
      errorCount: 0,
      averageResponseTime: 0,
      lastRequestTime: 0
    };
    
    current.requestCount++;
    current.lastRequestTime = Date.now();
    
    if (success) {
      current.successCount++;
    } else {
      current.errorCount++;
    }
    
    // è®¡ç®—å¹³å‡å“åº”æ—¶é—´
    current.averageResponseTime = (
      (current.averageResponseTime * (current.requestCount - 1) + responseTime) / 
      current.requestCount
    );
    
    this.metrics.set(endpoint, current);
  }

  getMetrics(): Map<string, RequestMetrics> {
    return new Map(this.metrics);
  }

  clearCache(): void {
    this.cache.clear();
    // æ¸…ç†AsyncStorageä¸­çš„ç¼“å­˜
    AsyncStorage.getAllKeys().then(keys => {
      const cacheKeys = keys.filter(key => key.startsWith('api_cache_'));
      AsyncStorage.multiRemove(cacheKeys);
    });
  }

  private sleep(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

export const enhancedApiClient = new EnhancedApiClient();
```

#### 4.2 å®æ—¶æ•°æ®åŒæ­¥
```typescript
// src/services/realtimeSync.ts
import { EventEmitter } from 'events';
import AsyncStorage from '@react-native-async-storage/async-storage';
import { AppState } from 'react-native';

interface SyncConfig {
  reconnectInterval: number;
  maxReconnectAttempts: number;
  heartbeatInterval: number;
  syncQueueSize: number;
}

interface SyncMessage {
  id: string;
  type: string;
  data: any;
  timestamp: number;
  priority: 'high' | 'medium' | 'low';
}

class RealtimeSync extends EventEmitter {
  private ws: WebSocket | null = null;
  private reconnectAttempts = 0;
  private heartbeatInterval: NodeJS.Timeout | null = null;
  private syncQueue: SyncMessage[] = [];
  private isOnline = true;
  private appState = 'active';
  
  private config: SyncConfig = {
    reconnectInterval: 5000,
    maxReconnectAttempts: 10,
    heartbeatInterval: 30000,
    syncQueueSize: 1000
  };

  constructor() {
    super();
    this.setupAppStateListener();
    this.loadOfflineQueue();
  }

  private setupAppStateListener(): void {
    AppState.addEventListener('change', (nextAppState) => {
      if (this.appState.match(/inactive|background/) && nextAppState === 'active') {
        // åº”ç”¨ä»åå°å›åˆ°å‰å°ï¼Œé‡æ–°è¿æ¥
        this.reconnect();
      }
      this.appState = nextAppState;
    });
  }

  connect(token: string): void {
    if (this.ws?.readyState === WebSocket.OPEN) {
      return;
    }

    const wsUrl = `${API_CONFIG.WEBSOCKET_URL}?token=${token}`;
    
    try {
      this.ws = new WebSocket(wsUrl);
      
      this.ws.onopen = () => {
        console.log('WebSocket connected');
        this.reconnectAttempts = 0;
        this.isOnline = true;
        this.startHeartbeat();
        this.processSyncQueue();
        this.emit('connected');
      };
      
      this.ws.onmessage = (event) => {
        try {
          const message = JSON.parse(event.data);
          this.handleMessage(message);
        } catch (error) {
          console.error('Failed to parse WebSocket message:', error);
        }
      };
      
      this.ws.onclose = (event) => {
        console.log('WebSocket disconnected', event.code, event.reason);
        this.isOnline = false;
        this.stopHeartbeat();
        this.emit('disconnected', { code: event.code, reason: event.reason });
        
        if (!event.wasClean && this.reconnectAttempts < this.config.maxReconnectAttempts) {
          this.attemptReconnect();
        }
      };
      
      this.ws.onerror = (error) => {
        console.error('WebSocket error:', error);
        this.emit('error', error);
      };
      
    } catch (error) {
      console.error('Failed to create WebSocket connection:', error);
      this.attemptReconnect();
    }
  }

  private handleMessage(message: any): void {
    // ç¡®è®¤æ¶ˆæ¯æ¥æ”¶
    if (message.id) {
      this.sendAck(message.id);
    }

    switch (message.type) {
      case 'health_data_update':
        this.emit('healthDataUpdate', message.data);
        this.cacheMessage(message);
        break;
      case 'agent_response':
        this.emit('agentResponse', message.data);
        break;
      case 'diagnosis_result':
        this.emit('diagnosisResult', message.data);
        this.cacheMessage(message);
        break;
      case 'system_notification':
        this.emit('systemNotification', message.data);
        break;
      case 'sync_request':
        this.handleSyncRequest(message.data);
        break;
      case 'pong':
        // å¿ƒè·³å“åº”
        break;
      default:
        console.log('Unknown message type:', message.type);
    }
  }

  private async cacheMessage(message: any): Promise<void> {
    try {
      const cacheKey = `sync_message_${message.type}_${message.timestamp}`;
      await AsyncStorage.setItem(cacheKey, JSON.stringify(message));
    } catch (error) {
      console.error('Failed to cache message:', error);
    }
  }

  private sendAck(messageId: string): void {
    this.send({
      type: 'ack',
      messageId,
      timestamp: Date.now()
    });
  }

  private handleSyncRequest(data: any): void {
    // å¤„ç†æœåŠ¡å™¨è¯·æ±‚çš„æ•°æ®åŒæ­¥
    this.emit('syncRequest', data);
  }

  private attemptReconnect(): void {
    if (this.reconnectAttempts >= this.config.maxReconnectAttempts) {
      console.error('Max reconnection attempts reached');
      this.emit('maxReconnectAttemptsReached');
      return;
    }

    this.reconnectAttempts++;
    const delay = Math.min(
      this.config.reconnectInterval * Math.pow(2, this.reconnectAttempts - 1),
      30000 // æœ€å¤§30ç§’
    );
    
    console.log(`Attempting to reconnect in ${delay}ms (attempt ${this.reconnectAttempts})`);
    
    setTimeout(() => {
      if (this.ws?.readyState !== WebSocket.OPEN) {
        this.reconnect();
      }
    }, delay);
  }

  private reconnect(): void {
    if (this.ws) {
      this.ws.close();
    }
    // é‡æ–°è¿æ¥éœ€è¦tokenï¼Œè¿™é‡Œå‡è®¾ä»å­˜å‚¨ä¸­è·å–
    AsyncStorage.getItem('auth_token').then(token => {
      if (token) {
        this.connect(token);
      }
    });
  }

  private startHeartbeat(): void {
    this.heartbeatInterval = setInterval(() => {
      if (this.ws?.readyState === WebSocket.OPEN) {
        this.ws.send(JSON.stringify({ 
          type: 'ping', 
          timestamp: Date.now() 
        }));
      }
    }, this.config.heartbeatInterval);
  }

  private stopHeartbeat(): void {
    if (this.heartbeatInterval) {
      clearInterval(this.heartbeatInterval);
      this.heartbeatInterval = null;
    }
  }

  send(message: any): void {
    const syncMessage: SyncMessage = {
      id: `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`,
      type: message.type,
      data: message.data || message,
      timestamp: Date.now(),
      priority: message.priority || 'medium'
    };

    if (this.ws?.readyState === WebSocket.OPEN && this.isOnline) {
      this.ws.send(JSON.stringify(syncMessage));
    } else {
      // ç¦»çº¿æ—¶åŠ å…¥åŒæ­¥é˜Ÿåˆ—
      this.addToSyncQueue(syncMessage);
    }
  }

  private addToSyncQueue(message: SyncMessage): void {
    // æŒ‰ä¼˜å…ˆçº§æ’å…¥é˜Ÿåˆ—
    if (message.priority === 'high') {
      this.syncQueue.unshift(message);
    } else {
      this.syncQueue.push(message);
    }

    // é™åˆ¶é˜Ÿåˆ—å¤§å°
    if (this.syncQueue.length > this.config.syncQueueSize) {
      // ç§»é™¤æœ€æ—§çš„ä½ä¼˜å…ˆçº§æ¶ˆæ¯
      const lowPriorityIndex = this.syncQueue.findIndex(msg => msg.priority === 'low');
      if (lowPriorityIndex !== -1) {
        this.syncQueue.splice(lowPriorityIndex, 1);
      } else {
        this.syncQueue.shift(); // ç§»é™¤æœ€æ—§çš„æ¶ˆæ¯
      }
    }

    this.saveOfflineQueue();
  }

  private async processSyncQueue(): Promise<void> {
    while (this.syncQueue.length > 0 && this.ws?.readyState === WebSocket.OPEN) {
      const message = this.syncQueue.shift();
      if (message) {
        try {
          this.ws.send(JSON.stringify(message));
          await new Promise(resolve => setTimeout(resolve, 100)); // é¿å…å‘é€è¿‡å¿«
        } catch (error) {
          console.error('Failed to send queued message:', error);
          // é‡æ–°åŠ å…¥é˜Ÿåˆ—
          this.syncQueue.unshift(message);
          break;
        }
      }
    }
    
    if (this.syncQueue.length === 0) {
      this.clearOfflineQueue();
    }
  }

  private async saveOfflineQueue(): Promise<void> {
    try {
      await AsyncStorage.setItem('sync_queue', JSON.stringify(this.syncQueue));
    } catch (error) {
      console.error('Failed to save sync queue:', error);
    }
  }

  private async loadOfflineQueue(): Promise<void> {
    try {
      const queueData = await AsyncStorage.getItem('sync_queue');
      if (queueData) {
        this.syncQueue = JSON.parse(queueData);
      }
    } catch (error) {
      console.error('Failed to load sync queue:', error);
    }
  }

  private async clearOfflineQueue(): Promise<void> {
    try {
      await AsyncStorage.removeItem('sync_queue');
    } catch (error) {
      console.error('Failed to clear sync queue:', error);
    }
  }

  disconnect(): void {
    this.stopHeartbeat();
    if (this.ws) {
      this.ws.close(1000, 'Client disconnect');
      this.ws = null;
    }
  }

  getConnectionStatus(): {
    connected: boolean;
    reconnectAttempts: number;
    queueSize: number;
  } {
    return {
      connected: this.ws?.readyState === WebSocket.OPEN,
      reconnectAttempts: this.reconnectAttempts,
      queueSize: this.syncQueue.length
    };
  }
}

export const realtimeSync = new RealtimeSync();
```

## ğŸ“Š å®æ–½è®¡åˆ’å’Œé¢„æœŸæ”¶ç›Š

### å®æ–½æ—¶é—´çº¿
- **Phase 1**: æœåŠ¡ç½‘æ ¼é›†æˆ (2-3å‘¨)
- **Phase 2**: åŠ¨æ€æœåŠ¡å‘ç° (1-2å‘¨)  
- **Phase 3**: åˆ†å¸ƒå¼äº‹åŠ¡ç®¡ç† (2-3å‘¨)
- **Phase 4**: å‰ç«¯é›†æˆä¼˜åŒ– (2-3å‘¨)
- **æ€»è®¡**: 7-11å‘¨

### é¢„æœŸæ”¶ç›Š
- **æ€§èƒ½æå‡**: å“åº”æ—¶é—´å‡å°‘40-60%ï¼Œååé‡æå‡3-5å€
- **å¯ç”¨æ€§**: è¾¾åˆ°99.9%å¯ç”¨æ€§
- **ç”¨æˆ·ä½“éªŒ**: ç¦»çº¿æ”¯æŒã€å®æ—¶æ›´æ–°ã€æ™ºèƒ½é‡è¯•
- **å¼€å‘æ•ˆç‡**: ç»Ÿä¸€ç›‘æ§ã€è‡ªåŠ¨åŒ–éƒ¨ç½²ã€å¿«é€Ÿæ•…éšœå®šä½

è¿™ä¸ªä¼˜åŒ–è®¡åˆ’å°†æ˜¾è‘—æå‡ç´¢å…‹ç”Ÿæ´»å¹³å°çš„æŠ€æœ¯æ¶æ„ï¼Œä¸ºå››ä¸ªæ™ºèƒ½ä½“æä¾›æ›´ç¨³å®šã€é«˜æ•ˆçš„æŠ€æœ¯åŸºç¡€ã€‚ 