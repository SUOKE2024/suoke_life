version: '3.8'

services:
  # RAG服务
  rag-service:
    build:
      context: ../..
      dockerfile: deploy/docker/Dockerfile
      args:
        ENVIRONMENT: production
    image: suoke-life/rag-service:latest
    container_name: rag-service
    restart: unless-stopped
    ports:
      - "8000:8000"  # HTTP API
      - "9000:9000"  # gRPC API
      - "8001:8001"  # Metrics
    environment:
      - ENVIRONMENT=production
      - RAG__SERVICE__DEBUG=false
      - RAG__SERVICE__HTTP_HOST=0.0.0.0
      - RAG__SERVICE__HTTP_PORT=8000
      - RAG__SERVICE__GRPC_HOST=0.0.0.0
      - RAG__SERVICE__GRPC_PORT=9000
      
      # 数据库配置
      - RAG__DATABASE__VECTOR_DB_HOST=milvus
      - RAG__DATABASE__VECTOR_DB_PORT=19530
      - RAG__DATABASE__REDIS_HOST=redis
      - RAG__DATABASE__REDIS_PORT=6379
      - RAG__DATABASE__NEO4J_URI=bolt://neo4j:7687
      - RAG__DATABASE__NEO4J_USER=neo4j
      - RAG__DATABASE__NEO4J_PASSWORD=${NEO4J_PASSWORD:-password}
      
      # 模型配置
      - RAG__MODEL__OPENAI_API_KEY=${OPENAI_API_KEY}
      - RAG__MODEL__OPENAI_API_BASE=${OPENAI_API_BASE:-https://api.openai.com/v1}
      - RAG__MODEL__EMBEDDING_MODEL_NAME=text-embedding-ada-002
      - RAG__MODEL__GENERATION_MODEL_NAME=gpt-3.5-turbo
      
      # 缓存配置
      - RAG__CACHE__ENABLE_CACHE=true
      - RAG__CACHE__CACHE_BACKEND=redis
      - RAG__CACHE__DEFAULT_TTL=3600
      
      # 监控配置
      - RAG__MONITORING__ENABLE_METRICS=true
      - RAG__MONITORING__METRICS_PORT=8001
      - RAG__MONITORING__LOG_LEVEL=INFO
      - RAG__MONITORING__ENABLE_TRACING=true
      - RAG__MONITORING__TRACING_ENDPOINT=http://jaeger:14268/api/traces
      
      # 性能配置
      - RAG__PERFORMANCE__MAX_CONCURRENT_REQUESTS=100
      - RAG__PERFORMANCE__REQUEST_TIMEOUT=30
      - RAG__PERFORMANCE__ENABLE_CONNECTION_POOLING=true
      
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
      - ./models:/app/models
    depends_on:
      - redis
      - milvus
      - neo4j
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  # Redis缓存
  redis:
    image: redis:7-alpine
    container_name: rag-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --requirepass ${REDIS_PASSWORD:-redis123}
    volumes:
      - redis-data:/data
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf:ro
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'
        reservations:
          memory: 512M
          cpus: '0.25'

  # Milvus向量数据库
  milvus:
    image: milvusdb/milvus:v2.3.0
    container_name: rag-milvus
    restart: unless-stopped
    ports:
      - "19530:19530"
      - "9091:9091"
    environment:
      - ETCD_ENDPOINTS=etcd:2379
      - MINIO_ADDRESS=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin}
    volumes:
      - milvus-data:/var/lib/milvus
      - ./milvus/milvus.yaml:/milvus/configs/milvus.yaml:ro
    depends_on:
      - etcd
      - minio
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9091/healthz"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: '4.0'
        reservations:
          memory: 4G
          cpus: '2.0'

  # Etcd (Milvus依赖)
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: rag-etcd
    restart: unless-stopped
    environment:
      - ETCD_AUTO_COMPACTION_MODE=revision
      - ETCD_AUTO_COMPACTION_RETENTION=1000
      - ETCD_QUOTA_BACKEND_BYTES=4294967296
      - ETCD_SNAPSHOT_COUNT=50000
    volumes:
      - etcd-data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "etcdctl", "endpoint", "health"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # MinIO (Milvus对象存储)
  minio:
    image: minio/minio:RELEASE.2023-03-20T20-16-18Z
    container_name: rag-minio
    restart: unless-stopped
    ports:
      - "9001:9001"
    environment:
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY:-minioadmin}
    volumes:
      - minio-data:/data
    command: minio server /data --console-address ":9001"
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Neo4j知识图谱
  neo4j:
    image: neo4j:5.11-community
    container_name: rag-neo4j
    restart: unless-stopped
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-password}
      - NEO4J_PLUGINS=["apoc", "graph-data-science"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,gds.*
      - NEO4J_dbms_memory_heap_initial_size=1G
      - NEO4J_dbms_memory_heap_max_size=2G
      - NEO4J_dbms_memory_pagecache_size=1G
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
      - neo4j-import:/var/lib/neo4j/import
      - neo4j-plugins:/plugins
    networks:
      - rag-network
    healthcheck:
      test: ["CMD", "cypher-shell", "-u", "neo4j", "-p", "${NEO4J_PASSWORD:-password}", "RETURN 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # Prometheus监控
  prometheus:
    image: prom/prometheus:v2.40.0
    container_name: rag-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./prometheus/rules:/etc/prometheus/rules:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=30d'
      - '--web.enable-lifecycle'
    networks:
      - rag-network
    depends_on:
      - rag-service
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'

  # Grafana可视化
  grafana:
    image: grafana/grafana:9.2.0
    container_name: rag-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD:-admin123}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    volumes:
      - grafana-data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - rag-network
    depends_on:
      - prometheus
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Jaeger分布式追踪
  jaeger:
    image: jaegertracing/all-in-one:1.39
    container_name: rag-jaeger
    restart: unless-stopped
    ports:
      - "16686:16686"  # UI
      - "14268:14268"  # HTTP collector
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - SPAN_STORAGE_TYPE=memory
    networks:
      - rag-network
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '0.5'

  # Nginx负载均衡器
  nginx:
    image: nginx:1.24-alpine
    container_name: rag-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/conf.d:/etc/nginx/conf.d:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
      - nginx-logs:/var/log/nginx
    depends_on:
      - rag-service
    networks:
      - rag-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'

  # 日志收集器
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.5.0
    container_name: rag-filebeat
    restart: unless-stopped
    user: root
    volumes:
      - ./filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs:/var/log/rag:ro
      - nginx-logs:/var/log/nginx:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      - ELASTICSEARCH_HOSTS=${ELASTICSEARCH_HOSTS:-http://elasticsearch:9200}
    networks:
      - rag-network
    depends_on:
      - rag-service
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.25'

volumes:
  redis-data:
    driver: local
  milvus-data:
    driver: local
  etcd-data:
    driver: local
  minio-data:
    driver: local
  neo4j-data:
    driver: local
  neo4j-logs:
    driver: local
  neo4j-import:
    driver: local
  neo4j-plugins:
    driver: local
  prometheus-data:
    driver: local
  grafana-data:
    driver: local
  nginx-logs:
    driver: local

networks:
  rag-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16 