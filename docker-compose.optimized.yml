# 索克生活闻诊服务 - 优化版Docker Compose配置
# 支持开发、测试和生产环境

version: '3.8'

# 网络配置
networks:
  suoke-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# 卷配置
volumes:
  redis-data:
    driver: local
  postgres-data:
    driver: local
  listen-service-logs:
    driver: local
  listen-service-data:
    driver: local
  listen-service-models:
    driver: local
  ai-models-registry:
    driver: local
  model-cache:
    driver: local
  model-artifacts:
    driver: local

# 服务配置
services:
  # ================================
  # AI模型版本管理服务
  # ================================
  model-registry:
    image: suoke/model-registry:v1.2.0
    container_name: suoke-model-registry
    ports:
      - "8090:8090"
      - "9090:9090"  # Metrics端口
    environment:
      - ENVIRONMENT=production
      - LOG_LEVEL=INFO
      - REGISTRY_STORAGE_TYPE=s3
      - REGISTRY_S3_BUCKET=suoke-ai-models
      - REGISTRY_S3_REGION=us-west-2
      - REGISTRY_DATABASE_URL=postgresql://postgres:password@postgres:5432/model_registry
      - REGISTRY_CACHE_BACKEND=redis
      - REGISTRY_CACHE_URL=redis://redis:6379/1
      - MODEL_VALIDATION_ENABLED=true
      - MODEL_METRICS_ENABLED=true
      - HUGGINGFACE_HUB_CACHE=/app/cache/huggingface
      - PYTORCH_HUB_CACHE=/app/cache/pytorch
    volumes:
      - ai-models-registry:/app/registry
      - model-cache:/app/cache
      - model-artifacts:/app/artifacts
      - ./config/model-registry:/app/config
    depends_on:
      - redis
      - postgres
    networks:
      - suoke-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8090/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - ai-models
      - prod

  # ================================
  # AI模型服务器 - 小艾智能体
  # ================================
  xiaoai-model-server:
    image: suoke/xiaoai-model-server:v2.1.0
    container_name: suoke-xiaoai-model-server
    ports:
      - "8100:8100"
      - "50100:50100"  # gRPC端口
    environment:
      - MODEL_NAME=xiaoai-conversation-llm
      - MODEL_VERSION=v2.1.0
      - MODEL_FRAMEWORK=huggingface
      - MODEL_REGISTRY_URL=http://model-registry:8090
      - INFERENCE_BATCH_SIZE=4
      - INFERENCE_MAX_LENGTH=2048
      - GPU_MEMORY_FRACTION=0.8
      - ENABLE_MODEL_CACHING=true
      - ENABLE_METRICS=true
    volumes:
      - model-cache:/app/cache
      - ./models/xiaoai:/app/models
    depends_on:
      - model-registry
    networks:
      - suoke-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 16G
        reservations:
          cpus: '2.0'
          memory: 8G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8100/health"]
      interval: 30s
      timeout: 15s
      retries: 3
    profiles:
      - ai-models
      - prod

  # ================================
  # AI模型服务器 - 小克智能体
  # ================================
  xiaoke-model-server:
    image: suoke/xiaoke-model-server:v1.5.2
    container_name: suoke-xiaoke-model-server
    ports:
      - "8101:8101"
      - "50101:50101"  # gRPC端口
    environment:
      - MODEL_NAME=xiaoke-health-classifier
      - MODEL_VERSION=v1.5.2
      - MODEL_FRAMEWORK=pytorch
      - MODEL_REGISTRY_URL=http://model-registry:8090
      - INFERENCE_BATCH_SIZE=8
      - ENABLE_MODEL_CACHING=true
      - ENABLE_METRICS=true
    volumes:
      - model-cache:/app/cache
      - ./models/xiaoke:/app/models
    depends_on:
      - model-registry
    networks:
      - suoke-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 4G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8101/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - ai-models
      - prod

  # ================================
  # AI模型服务器 - 老克智能体
  # ================================
  laoke-model-server:
    image: suoke/laoke-model-server:v3.0.1
    container_name: suoke-laoke-model-server
    ports:
      - "8102:8102"
      - "50102:50102"  # gRPC端口
    environment:
      - MODEL_NAME=laoke-tcm-expert
      - MODEL_VERSION=v3.0.1
      - MODEL_FRAMEWORK=tensorflow
      - MODEL_REGISTRY_URL=http://model-registry:8090
      - INFERENCE_BATCH_SIZE=4
      - TCM_KNOWLEDGE_BASE_PATH=/app/knowledge/tcm
      - ENABLE_MODEL_CACHING=true
      - ENABLE_METRICS=true
    volumes:
      - model-cache:/app/cache
      - ./models/laoke:/app/models
      - ./knowledge/tcm:/app/knowledge/tcm
    depends_on:
      - model-registry
    networks:
      - suoke-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '3.0'
          memory: 12G
        reservations:
          cpus: '1.5'
          memory: 6G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8102/health"]
      interval: 30s
      timeout: 15s
      retries: 3
    profiles:
      - ai-models
      - prod

  # ================================
  # AI模型服务器 - 索儿智能体
  # ================================
  soer-model-server:
    image: suoke/soer-model-server:v1.3.0
    container_name: suoke-soer-model-server
    ports:
      - "8103:8103"
      - "50103:50103"  # gRPC端口
    environment:
      - MODEL_NAME=soer-wellness-engine
      - MODEL_VERSION=v1.3.0
      - MODEL_FRAMEWORK=onnx
      - MODEL_REGISTRY_URL=http://model-registry:8090
      - INFERENCE_BATCH_SIZE=16
      - WELLNESS_KNOWLEDGE_BASE_PATH=/app/knowledge/wellness
      - ENABLE_MODEL_CACHING=true
      - ENABLE_METRICS=true
    volumes:
      - model-cache:/app/cache
      - ./models/soer:/app/models
      - ./knowledge/wellness:/app/knowledge/wellness
    depends_on:
      - model-registry
    networks:
      - suoke-network
    restart: unless-stopped
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 2G
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8103/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - ai-models
      - prod

  # ================================
  # 模型版本控制器
  # ================================
  model-version-controller:
    image: suoke/model-version-controller:v1.0.0
    container_name: suoke-model-version-controller
    ports:
      - "8110:8110"
    environment:
      - CONTROLLER_MODE=standalone
      - MODEL_REGISTRY_URL=http://model-registry:8090
      - KUBERNETES_ENABLED=false
      - DOCKER_ENABLED=true
      - DOCKER_SOCKET=/var/run/docker.sock
      - CANARY_DEPLOYMENT_ENABLED=true
      - AUTO_ROLLBACK_ENABLED=true
      - VALIDATION_TIMEOUT=300s
      - PROMOTION_TIMEOUT=600s
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./config/model-controller:/app/config
    depends_on:
      - model-registry
    networks:
      - suoke-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8110/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    profiles:
      - ai-models
      - prod

  # ================================
  # 闻诊服务 - 开发环境
  # ================================
  listen-service-dev:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      target: development
    container_name: suoke-listen-service-dev
    ports:
      - "8000:8000"
      - "50051:50051"
    environment:
      - ENVIRONMENT=development
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - CACHE_BACKEND=redis
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/listen_service_dev
      - MODEL_REGISTRY_URL=http://model-registry:8090
      - XIAOAI_MODEL_URL=http://xiaoai-model-server:8100
      - XIAOKE_MODEL_URL=http://xiaoke-model-server:8101
      - LAOKE_MODEL_URL=http://laoke-model-server:8102
      - SOER_MODEL_URL=http://soer-model-server:8103
    volumes:
      - .:/app
      - listen-service-logs:/app/logs
      - listen-service-data:/app/data
      - listen-service-models:/app/models
    depends_on:
      - redis
      - postgres
      - model-registry
    networks:
      - suoke-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    profiles:
      - dev

  # ================================
  # 闻诊服务 - 生产环境
  # ================================
  listen-service-prod:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      target: production
    container_name: suoke-listen-service-prod
    ports:
      - "8000:8000"
      - "50051:50051"
    environment:
      - ENVIRONMENT=production
      - DEBUG=false
      - LOG_LEVEL=INFO
      - CACHE_BACKEND=redis
      - REDIS_URL=redis://redis:6379
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/listen_service_prod
      - PERFORMANCE_MONITORING=true
      - ENABLE_METRICS=true
      - MODEL_REGISTRY_URL=http://model-registry:8090
      - XIAOAI_MODEL_URL=http://xiaoai-model-server:8100
      - XIAOKE_MODEL_URL=http://xiaoke-model-server:8101
      - LAOKE_MODEL_URL=http://laoke-model-server:8102
      - SOER_MODEL_URL=http://soer-model-server:8103
    volumes:
      - listen-service-logs:/app/logs
      - listen-service-data:/app/data
      - listen-service-models:/app/models
    depends_on:
      - redis
      - postgres
      - model-registry
      - xiaoai-model-server
      - xiaoke-model-server
      - laoke-model-server
      - soer-model-server
    networks:
      - suoke-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    profiles:
      - prod

  # ================================
  # 闻诊服务 - 测试环境
  # ================================
  listen-service-test:
    build:
      context: .
      dockerfile: Dockerfile.optimized
      target: testing
    container_name: suoke-listen-service-test
    environment:
      - ENVIRONMENT=testing
      - DEBUG=true
      - LOG_LEVEL=DEBUG
      - CACHE_BACKEND=memory
      - TEST_MODE=true
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/listen_service_test
      - MODEL_REGISTRY_URL=http://model-registry:8090
    depends_on:
      - postgres
      - model-registry
    networks:
      - suoke-network
    profiles:
      - test

  # ================================
  # Redis缓存服务
  # ================================
  redis:
    image: redis:7-alpine
    container_name: suoke-redis
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      - suoke-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '1.0'
        reservations:
          memory: 1G
          cpus: '0.5'

  # ================================
  # PostgreSQL数据库
  # ================================
  postgres:
    image: postgres:15-alpine
    container_name: suoke-postgres
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB: suoke_life
      - POSTGRES_USER: suoke_user
      - POSTGRES_PASSWORD: suoke_password
      - POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./deploy/init-scripts:/docker-entrypoint-initdb.d
    networks:
      - suoke-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'

  # ================================
  # Nginx反向代理
  # ================================
  nginx:
    image: nginx:alpine
    container_name: suoke-nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./nginx/ssl:/etc/nginx/ssl
    depends_on:
      - listen-service-prod
    networks:
      - suoke-network
    restart: unless-stopped
    profiles:
      - prod
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ================================
  # Prometheus监控
  # ================================
  prometheus:
    image: prom/prometheus:latest
    container_name: suoke-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    networks:
      - suoke-network
    restart: unless-stopped
    profiles:
      - monitoring
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # ================================
  # Grafana可视化
  # ================================
  grafana:
    image: grafana/grafana:latest
    container_name: suoke-grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources
    depends_on:
      - prometheus
    networks:
      - suoke-network
    restart: unless-stopped
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ================================
  # Jaeger链路追踪
  # ================================
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: suoke-jaeger
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_ZIPKIN_HTTP_PORT=9411
    networks:
      - suoke-network
    restart: unless-stopped
    profiles:
      - monitoring
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # ================================
  # ELK日志收集
  # ================================
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: suoke-elasticsearch
    restart: unless-stopped
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms1g -Xmx1g"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - suoke-network
    deploy:
      resources:
        limits:
          memory: 2G
          cpus: '2.0'
        reservations:
          memory: 1G
          cpus: '1.0'

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    container_name: suoke-logstash
    volumes:
      - ./elk/logstash/pipeline:/usr/share/logstash/pipeline
      - ./elk/logstash/config:/usr/share/logstash/config
    ports:
      - "5044:5044"
    depends_on:
      - elasticsearch
    networks:
      - suoke-network
    restart: unless-stopped
    profiles:
      - logging

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: suoke-kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      - elasticsearch
    networks:
      - suoke-network
    restart: unless-stopped
    profiles:
      - logging
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: '1.0'
        reservations:
          memory: 512M
          cpus: '0.5'

  # ================================
  # 消息队列 (RabbitMQ)
  # ================================
  rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: suoke-rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=password
    volumes:
      - ./rabbitmq/data:/var/lib/rabbitmq
    networks:
      - suoke-network
    restart: unless-stopped
    profiles:
      - messaging

  # ================================
  # MinIO对象存储
  # ================================
  minio:
    image: minio/minio:latest
    container_name: suoke-minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=password123
    volumes:
      - ./minio/data:/data
    networks:
      - suoke-network
    restart: unless-stopped
    command: server /data --console-address ":9001"
    profiles:
      - storage

volumes:
  redis_data:
    driver: local
  postgres_data:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  elasticsearch_data:
    driver: local

# 扩展配置
x-common-variables: &common-variables
  PYTHONUNBUFFERED: 1
  PYTHONPATH: /app
  TZ: Asia/Shanghai

x-agent-service: &agent-service
  restart: unless-stopped
  environment:
    <<: *common-variables
    REDIS_URL: redis://redis:6379
    DATABASE_URL: postgresql://suoke_user:suoke_password@postgres:5432/suoke_life
    MAX_WORKERS: 8
    ENABLE_JIT: true
    CACHE_TTL: 300
  depends_on:
    - redis
    - postgres
  networks:
    - suoke-network
  deploy:
    resources:
      limits:
        memory: 4G
        cpus: '4.0'
      reservations:
        memory: 2G
        cpus: '2.0'
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
    interval: 30s
    timeout: 10s
    retries: 3 